{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71169ee8",
   "metadata": {},
   "source": [
    "# Notebook to apply hillshade model correction to Planet images at Wolverine Glacier, AK\n",
    "\n",
    "GEOPH 520: DSP\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "April 2022\n",
    "\n",
    "\n",
    "### Outline\n",
    "\n",
    "1. Initial setup:\n",
    "    - Import packages\n",
    "    - Define paths in directory\n",
    "2. Load WorldView-derived DEM and Planet images\n",
    "3. Loop through images:\n",
    "    - Create hillshade model\n",
    "    - Resample hillshade to image coordinates\n",
    "    - Determine optimal band scalars for correction, apply correction to image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f800b70",
   "metadata": {},
   "source": [
    "## 1. Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bf8353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Import packages\n",
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "from pyproj import Proj, transform, Transformer\n",
    "from functools import partial\n",
    "from functions import sunpos\n",
    "from shapely.geometry import Polygon\n",
    "import subprocess\n",
    "from scipy.interpolate import interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d47576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to DEM\n",
    "DEM_path = '/Users/raineyaberle/Research/PhD/Wolverine/DEMs/WG_20200728-DEM_mosaic_crop_UTM6_resamp_filled.tif'\n",
    "# path to Planet images\n",
    "im_path = '/Users/raineyaberle/Research/PhD/Wolverine/imagery/Planet/2021-04-20_2021-08-25/PSScene4Band/'\n",
    "# path to hillshades directory\n",
    "hs_path = im_path+'hillshades/'\n",
    "# output folder\n",
    "out_path = im_path+'../'\n",
    "# test results output folder (if outputting all scalar tests)\n",
    "results_path = out_path+'hillshade-correction-tests/'\n",
    "# path to Area of Interest (AOI) shapefile, e.g. glacier outline (optional)\n",
    "AOI_path = '/Users/raineyaberle/Research/PhD/Wolverine/GIS_data/wolverine_RGI.shp'\n",
    "\n",
    "# -----Determine whether you would like outputs plotted\n",
    "plot_results = 1 # = 1 to plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0c406a",
   "metadata": {},
   "source": [
    "## 2. Define snow-covered area, load WorldView-derived DEM and Planet images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e0fab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define area of interest (AOI) \n",
    "# Used to minimize standard deviation in hillshade model correction. \n",
    "# Choose a region that where the surface reflectance in each image should be nearly uniform, \n",
    "#     but may be impacted by shadows. \n",
    "AOI = Polygon([(394e3, 6698.5e3), (394e3, 6700.5e3), (396e3, 6700.5e3), (396e3, 6698.5e3), (394e3, 6698.5e3)])\n",
    "\n",
    "# -----Define CRS (EPSG code)\n",
    "crs = 32606\n",
    "\n",
    "# -----Load DEM\n",
    "DEM = rio.open(DEM_path)\n",
    "# coordinates\n",
    "DEM_x = np.linspace(DEM.bounds.left, DEM.bounds.right, num=np.shape(DEM.read(1))[1])\n",
    "DEM_y = np.linspace(DEM.bounds.top, DEM.bounds.bottom, num=np.shape(DEM.read(1))[0])\n",
    "\n",
    "# -----Load images\n",
    "ims = os.chdir(im_path) # change directory\n",
    "im_names = glob.glob('*SR_clip.tif') # load all files with SR_clip.tif extension\n",
    "im_names.sort() # sort file names by date\n",
    "# print image file names\n",
    "# print('Image names from file:')\n",
    "# print(im_names)\n",
    "\n",
    "# -----Print coordinate reference systems to ensure they are the same\n",
    "print('DEM CRS: ',DEM.crs)\n",
    "print('Images CRS:',rio.open(im_names[0]).crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eed648d",
   "metadata": {},
   "source": [
    "## 3. Loop through images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c1db9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start time\n",
    "t1 = time.monotonic()\n",
    "\n",
    "# loop through images\n",
    "for im_name in im_names:\n",
    "    \n",
    "    # -----Load image\n",
    "    print('Image: ',im_name)\n",
    "    im = rio.open(im_name)\n",
    "    # load bands (blue, green, red, near infrared)\n",
    "    im_scalar = 10000\n",
    "    b = im.read(1).astype(float) / im_scalar\n",
    "    g = im.read(2).astype(float) / im_scalar\n",
    "    r = im.read(3).astype(float) / im_scalar\n",
    "    nir = im.read(4).astype(float) / im_scalar \n",
    "    # define coordinates\n",
    "    im_x = np.linspace(im.bounds.left, im.bounds.right, num=np.shape(b)[1])\n",
    "    im_y = np.linspace(im.bounds.top, im.bounds.bottom, num=np.shape(b)[0])\n",
    "\n",
    "    # -----Extract image information for sun position calculation\n",
    "    # location: grab center image coordinate, convert to lat lon\n",
    "    xmid = ((im.bounds.right - im.bounds.left)/2 + im.bounds.left)\n",
    "    ymid = ((im.bounds.top - im.bounds.bottom)/2 + im.bounds.bottom)\n",
    "    transformer = Transformer.from_crs(\"epsg:\"+str(crs), \"epsg:4326\")\n",
    "    location = transformer.transform(xmid, ymid)\n",
    "    # when: year, month, day, hour, minute, second\n",
    "    when = (float(im_name[0:4]), float(im_name[4:6]), float(im_name[6:8]), \n",
    "            float(im_name[9:11]), float(im_name[11:13]), float(im_name[13:15]))\n",
    "    # sun azimuth and elevation\n",
    "    azimuth, elevation = sunpos(when, location, refraction=1)\n",
    "    print('    location:',location)\n",
    "    print('    when:',when)\n",
    "    print('    azimuth: ',azimuth)\n",
    "    print('    elevation:',elevation)\n",
    "\n",
    "    # -----Create hillshade model (if it does not already exist in file)\n",
    "    hs_fn = out_path+'hillshades/'+str(azimuth)+'-az_'+str(elevation)+'-z_hillshade.tif'\n",
    "    if os.path.exists(hs_fn):\n",
    "        print('    hillshade model already exists in directory... loading')\n",
    "    else:\n",
    "        print('    creating hillshade model...')\n",
    "        # construct the gdal_merge command\n",
    "        # modified from: https://github.com/clhenrick/gdal_hillshade_tutorial\n",
    "        # gdaldem hillshade -az aximuth -z elevation dem.tif hillshade.tif\n",
    "        cmd = 'gdaldem hillshade -az '+str(azimuth)+' -z '+str(elevation)+' '+str(DEM_path)+' '+hs_fn\n",
    "        # run the command \n",
    "        p = subprocess.run(cmd, shell=True, capture_output=True) \n",
    "        print(p)\n",
    "\n",
    "    # -----load hillshade model from file\n",
    "    hs = rio.open(hs_fn)\n",
    "    print('    hillshade model loaded from file')\n",
    "    # coordinates\n",
    "    hs_x = np.linspace(hs.bounds.left, hs.bounds.right, num=np.shape(hs.read(1))[1])\n",
    "    hs_y = np.linspace(hs.bounds.top, hs.bounds.bottom, num=np.shape(hs.read(1))[0])\n",
    "\n",
    "    # -----Resample hillshade to image coordinates\n",
    "    # resampled hillshade file name\n",
    "    hs_resamp_fn = out_path+'hillshades/'+str(azimuth)+'-az_'+str(elevation)+'-z_hillshade_resamp.tif'\n",
    "    # check if file already exists in directory\n",
    "    if os.path.exists(hs_resamp_fn):\n",
    "        print('    resampled hillshade model already exists in directory... loading')\n",
    "    # resample if it doesn't exist\n",
    "    else:\n",
    "        print('    resampling hillshade...')\n",
    "        # create interpolation object\n",
    "        f = interp2d(hs_x, hs_y, hs.read(1))\n",
    "        hs_resamp = f(im_x, im_y)\n",
    "        # save to file\n",
    "        with rio.open(hs_resamp_fn,'w',\n",
    "                      driver='GTiff',\n",
    "                      height=hs_resamp.shape[0],\n",
    "                      width=hs_resamp.shape[1],\n",
    "                      dtype=hs_resamp.dtype,\n",
    "                      count=1,\n",
    "                      crs=im.crs,\n",
    "                      transform=im.transform) as dst:\n",
    "            dst.write(hs_resamp, 1)\n",
    "        print('    resampled hillshade model saved to file:',hs_resamp_fn)\n",
    "\n",
    "    # -----load resampled hillshade\n",
    "    hs_resamp = rio.open(hs_resamp_fn).read(1)\n",
    "    print('    resampled hillshade model loaded from file')\n",
    "    \n",
    "    # -----clip image and hillshade to AOI\n",
    "    Ix = np.where((im_x >= AOI.bounds[0]) & (im_x <= AOI.bounds[2]))[0]\n",
    "    Iy = np.where((im_y >= AOI.bounds[1]) & (im_y <= AOI.bounds[3]))[0]\n",
    "    b_AOI = np.zeros((np.shape(Ix)[0], np.shape(Iy)[0]))\n",
    "    g_AOI = np.zeros((np.shape(Ix)[0], np.shape(Iy)[0]))\n",
    "    r_AOI = np.zeros((np.shape(Ix)[0], np.shape(Iy)[0]))\n",
    "    nir_AOI = np.zeros((np.shape(Ix)[0], np.shape(Iy)[0]))\n",
    "    hs_AOI = np.zeros((np.shape(Ix)[0], np.shape(Iy)[0]))\n",
    "    print(Iy,Ix)\n",
    "    for i in np.arange(0,np.shape(Ix)[0]-1):\n",
    "        for j in np.arange(0, np.shape(Iy)[0]-1):\n",
    "            b_AOI[j,i] = b[Iy[j], Ix[i]]\n",
    "            g_AOI[j,i] = g[Iy[j], Ix[i]]\n",
    "            r_AOI[j,i] = r[Iy[j], Ix[i]]\n",
    "            nir_AOI[j,i] = nir[Iy[j], Ix[i]]\n",
    "            hs_AOI[j,i] = hs_resamp[Iy[j], Ix[i]]\n",
    "            \n",
    "    # -----normalize hillshade model\n",
    "    hs_norm = (hs_resamp_smooth - np.min(hs_resamp_smooth)) / (np.max(hs_resamp_smooth) - np.min(hs_resamp_smooth))\n",
    "    hs_AOI_norm = (hs_AOI - np.min(hs_AOI)) / (np.max(hs_AOI) - np.min(hs_AOI))\n",
    "    \n",
    "    # -----loop through hillshade scalar multipliers\n",
    "    print('    solving for optimal band scalars')\n",
    "    # define scalars to test\n",
    "    hs_scalars = np.linspace(0,0.5,num=21)\n",
    "    # blue\n",
    "    b_AOI_mu = [] # mean \n",
    "    b_AOI_sigma = [] # std\n",
    "    # green\n",
    "    g_AOI_mu = [] # mean \n",
    "    g_AOI_sigma = [] # std\n",
    "    # red\n",
    "    r_AOI_mu = [] # mean \n",
    "    r_AOI_sigma = [] # std\n",
    "    # nir\n",
    "    nir_AOI_mu = [] # mean \n",
    "    nir_AOI_sigma = [] # std\n",
    "    for hs_scalar in hs_scalars:\n",
    "        # full image\n",
    "        b_adj = b - (hs_norm * hs_scalar)\n",
    "        g_adj = g - (hs_norm * hs_scalar)\n",
    "        r_adj = r - (hs_norm * hs_scalar)\n",
    "        nir_adj = nir - (hs_norm * hs_scalar)\n",
    "        # AOI\n",
    "        b_AOI_mu = b_AOI_mu + [np.nanmean(b_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        b_AOI_sigma = b_AOI_sigma + [np.nanstd(b_AOI - (hs_AOI_norm * hs_scalar))] \n",
    "        g_AOI_mu = g_AOI_mu + [np.nanmean(g_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        g_AOI_sigma = g_AOI_sigma + [np.nanstd(g_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        r_AOI_mu = r_AOI_mu + [np.nanmean(r_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        r_AOI_sigma = r_AOI_sigma + [np.nanstd(r_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        nir_AOI_mu = nir_AOI_mu + [np.nanmean(nir_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "        nir_AOI_sigma = nir_AOI_sigma + [np.nanstd(nir_AOI - (hs_AOI_norm * hs_scalar))]\n",
    "    \n",
    "    # -----Determine optimal scalar for each image band\n",
    "    Ib = np.where(b_AOI_sigma==np.min(b_AOI_sigma))[0][0]\n",
    "    b_scalar = hs_scalars[Ib]\n",
    "    Ig = np.where(g_AOI_sigma==np.min(g_AOI_sigma))[0][0]\n",
    "    g_scalar = hs_scalars[Ig]    \n",
    "    Ir = np.where(r_AOI_sigma==np.min(r_AOI_sigma))[0][0]\n",
    "    r_scalar = hs_scalars[Ir]    \n",
    "    Inir = np.where(nir_AOI_sigma==np.min(nir_AOI_sigma))[0][0]\n",
    "    nir_scalar = hs_scalars[Inir]\n",
    "    \n",
    "    # -----Apply optimal hillshade model correction\n",
    "    b_corrected = b - (hs_norm * hs_scalars[Ib])\n",
    "    g_corrected = g - (hs_norm * hs_scalars[Ig])\n",
    "    r_corrected = r - (hs_norm * hs_scalars[Ir])\n",
    "    nir_corrected = nir - (hs_norm * hs_scalars[Inir])\n",
    "    \n",
    "    # -----Plot original and corrected images and band histograms\n",
    "    if plot_results==1:\n",
    "        fig1, ((ax1, ax2),(ax3,ax4)) = plt.subplots(2,2, figsize=(16,16), gridspec_kw={'height_ratios': [3, 1]})\n",
    "        plt.rcParams.update({'font.size': 14, 'font.serif': 'Arial'})\n",
    "        # original image\n",
    "        ax1.imshow(np.dstack([r, g, b]), \n",
    "                   extent=(np.min(im_x)/1000, np.max(im_x)/1000, np.min(im_y)/1000, np.max(im_y)/1000))\n",
    "        ax1.set_ylabel('Northing [km]')\n",
    "        ax1.set_ylabel('Easting [km]')\n",
    "        ax1.set_title('Original image')\n",
    "        # corrected image\n",
    "        ax2.imshow(np.dstack([r_corrected, g_corrected, b_corrected]), \n",
    "                   extent=(np.min(im_x)/1000, np.max(im_x)/1000, np.min(im_y)/1000, np.max(im_y)/1000))\n",
    "        ax2.set_ylabel('Easting [km]')\n",
    "        ax2.set_title('Corrected image')\n",
    "        # band histograms\n",
    "        ax3.hist(nir.flatten(), bins=100, color='purple', alpha=0.5, label='NIR')\n",
    "        ax3.hist(b.flatten(), bins=100, color='blue', alpha=0.5, label='Blue')\n",
    "        ax3.hist(g.flatten(), bins=100, color='green', alpha=0.5, label='Green')\n",
    "        ax3.hist(r.flatten(), bins=100, color='red', alpha=0.5, label='Red')\n",
    "        ax4.hist(nir_corrected.flatten(), bins=100, color='purple', alpha=0.5, label='NIR')\n",
    "        ax4.hist(b_corrected.flatten(), bins=100, color='blue', alpha=0.5, label='Blue')\n",
    "        ax4.hist(g_corrected.flatten(), bins=100, color='green', alpha=0.5, label='Green')\n",
    "        ax4.hist(r_corrected.flatten(), bins=100, color='red', alpha=0.5, label='Red')        \n",
    "        plt.show()\n",
    "        \n",
    "    print('----------')\n",
    "    print(' ')\n",
    "    \n",
    "# end time\n",
    "t2 = time.monotonic()\n",
    "print('time elapsed:',str(np.round(t2-t1,2)),'s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ff3a8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:planet-snow]",
   "language": "python",
   "name": "conda-env-planet-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
