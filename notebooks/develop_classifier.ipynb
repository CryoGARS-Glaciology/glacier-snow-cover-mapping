{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c53b019d",
   "metadata": {},
   "source": [
    "## Notebook to develop supervised classifier for identifying snow in PlanetScope 4-band imagery\n",
    "Rainey Aberle\n",
    "\n",
    "Adapted from the [SciKit Learn Classifier comparison tutorial](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html)\n",
    "\n",
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3837b29f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text, plot_tree \n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_moons, make_circles\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "from sklearn import metrics \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2794212f",
   "metadata": {},
   "source": [
    "### Define paths to directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791e0eb1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# base directory\n",
    "base_path = '/Users/raineyaberle/Research/PhD/study-sites/Wolverine/'\n",
    "# image directory\n",
    "im_path = base_path+'imagery/Planet/2021-04-20_2021-08-25/adjusted-radiometry/'\n",
    "# classifier output folder (where best classifier will be saved)\n",
    "out_path = base_path+'../../planet-snow/inputs-outputs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef04c4",
   "metadata": {},
   "source": [
    "### Load image and snow/non-snow classified points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105961c1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----Define EPSG code\n",
    "epsg = 32606\n",
    "\n",
    "# -----Load image\n",
    "im_fn = im_path+'20210815_202055_60_2459_3B_AnalyticMS_SR_clip_PSB.SD_adj.tif'\n",
    "im = rio.open(im_fn)\n",
    "# read bands\n",
    "b = im.read(1).astype(float)\n",
    "r = im.read(2).astype(float)\n",
    "g = im.read(3).astype(float)\n",
    "nir = im.read(4).astype(float)\n",
    "# define coordinates grid\n",
    "im_x = np.linspace(im.bounds.left, im.bounds.right, num=np.shape(b)[1])\n",
    "im_y = np.linspace(im.bounds.top, im.bounds.bottom, num=np.shape(b)[0])\n",
    "print('Image CRS:',im.crs)\n",
    "\n",
    "# -----Load snow training points\n",
    "data_snow_pts_fn = base_path+'classified-points/snow_points.shp'\n",
    "data_snow_pts = gpd.read_file(data_snow_pts_fn)\n",
    "# reproject to defined CRS\n",
    "data_snow_pts = data_snow_pts.to_crs(epsg)\n",
    "print('Snow points CRS:', data_snow_pts.crs)\n",
    "\n",
    "# -----Load non-snow points\n",
    "data_non_snow_pts_fn = base_path+'classified-points/non_snow_points.shp'\n",
    "data_non_snow_pts = gpd.read_file(data_non_snow_pts_fn)\n",
    "# Reproject to defined CRS\n",
    "data_non_snow_pts = data_non_snow_pts.to_crs(epsg)\n",
    "print('Non-snow points CRS:', data_non_snow_pts.crs)\n",
    "\n",
    "# -----Plot RGB image, data point locations, and band histograms\n",
    "fig, (ax1,ax2) = plt.subplots(2, 1, figsize=(8,16), gridspec_kw={'height_ratios': [4,1]})\n",
    "plt.rcParams.update({'font.size': 14, 'font.sans-serif': 'Arial'})\n",
    "# image and point locations\n",
    "ax1.imshow(np.dstack([r, g, b]), \n",
    "           extent=(np.min(im_x), np.max(im_x), np.min(im_y), np.max(im_y)))\n",
    "data_snow_pts.plot(ax=ax1, markersize=15, color='cyan', label='snow')\n",
    "data_non_snow_pts.plot(ax=ax1, markersize=15, color='orange', label='non-snow')\n",
    "ax1.legend(loc='lower right')\n",
    "ax1.set_xlabel('Easting [m]')\n",
    "ax1.set_ylabel('Northing [m]')\n",
    "# histograms\n",
    "h_b = ax2.hist(b.flatten(), color='blue', histtype='step', linewidth=2, bins=100, label='blue')\n",
    "h_g = ax2.hist(g.flatten(), color='green', histtype='step', linewidth=2, bins=100, label='green')\n",
    "h_r = ax2.hist(r.flatten(), color='red', histtype='step', linewidth=2, bins=100, label='red')\n",
    "h_nir = ax2.hist(nir.flatten(), color='brown', histtype='step', linewidth=2, bins=100, label='NIR')\n",
    "ax2.set_xlabel('Surface reflectance')\n",
    "ax2.set_ylabel('Pixel counts')\n",
    "ax2.set_ylim(0,np.max([h_nir[0][1:], h_g[0][1:], h_r[0][1:], h_b[0][1:]])+5000)\n",
    "ax2.grid()\n",
    "ax2.legend(loc='right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e87403",
   "metadata": {},
   "source": [
    "### Set up training data\n",
    "#### Add 'snow' classification column, merge snow and non-snow points, sample band values at points, and add NDSI column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b929942",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----Add snow classification column to data points\n",
    "data_snow_pts['snow'] = 1\n",
    "data_non_snow_pts['snow'] = 0\n",
    "\n",
    "# -----Merge snow and non-snow points\n",
    "data_pts = data_snow_pts.append(data_non_snow_pts, ignore_index=True)\n",
    "# Add coords column\n",
    "data_pts['coords'] = [(pt.bounds[0], pt.bounds[1]) for pt in data_pts['geometry']]\n",
    "# remove \"id\" and \"geometry\" columns\n",
    "data_pts = data_pts.drop(columns=['id', 'geometry'])\n",
    "\n",
    "# -----Sample band values at points\n",
    "data_pts['blue'] = [x[0] for x in im.sample(data_pts['coords'])]\n",
    "data_pts['green'] = [x[1] for x in im.sample(data_pts['coords'])]\n",
    "data_pts['red'] = [x[2] for x in im.sample(data_pts['coords'])]\n",
    "data_pts['NIR'] = [x[3] for x in im.sample(data_pts['coords'])]\n",
    "\n",
    "# -----Add NDSI column\n",
    "data_pts['NDSI'] = (data_pts['red'] - data_pts['NIR']) / (data_pts['red'] + data_pts['NIR'])\n",
    "\n",
    "print(data_pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be3cc6b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Test classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2940d4f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t1 = time.time() # start timer\n",
    "test_train = True # = True to split training points into testing and training points\n",
    "\n",
    "# -----Split data points\n",
    "into features (band values) and target variable (snow)\n",
    "feature_cols = ['red', 'NIR', 'NDSI'] #['blue', 'green', 'red', 'NIR', 'NDSI']\n",
    "X = data_pts[feature_cols] # features\n",
    "y = data_pts['snow'] # target variable\n",
    "\n",
    "# -----Split data points into testing and training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# -----Save image band values in GeoDataFrame\n",
    "im_x_mesh, im_y_mesh = np.meshgrid(im_x, im_y)\n",
    "im_pts = gpd.GeoDataFrame()\n",
    "im_pts['x'] = im_x_mesh[~np.isnan(b)].flatten()\n",
    "im_pts['y'] = im_y_mesh[~np.isnan(b)].flatten()\n",
    "im_pts['blue'] = b[~np.isnan(b)].flatten()\n",
    "im_pts['green'] = g[~np.isnan(g)].flatten()\n",
    "im_pts['red'] = r[~np.isnan(r)].flatten()\n",
    "im_pts['NIR'] = nir[~np.isnan(nir)].flatten()\n",
    "im_pts['NDSI'] = (im_pts['red'] - im_pts['NIR']) / (im_pts['red'] + im_pts['NIR'])\n",
    "\n",
    "# -----Classifier names\n",
    "names = [\n",
    "    \"Nearest Neighbors\",\n",
    "    \"Linear SVM\",\n",
    "    \"RBF SVM\",\n",
    "    \"Gaussian Process\",\n",
    "    \"Decision Tree\",\n",
    "    \"Random Forest\",\n",
    "    \"Neural Net\",\n",
    "    \"AdaBoost\",\n",
    "    \"Naive Bayes\",\n",
    "    \"QDA\",\n",
    "]\n",
    "\n",
    "# -----Classifiers\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB(),\n",
    "    QuadraticDiscriminantAnalysis(),\n",
    "]\n",
    "    \n",
    "# -----Set up figures\n",
    "# plot RGB image\n",
    "fig1 = plt.figure(figsize=(8,8))\n",
    "plt.imshow(np.dstack([r, g, b]), \n",
    "            extent=(np.min(im_x)/1000, np.max(im_x)/1000, np.min(im_y)/1000, np.max(im_y)/1000))\n",
    "plt.title('RGB Image')\n",
    "plt.ylabel('Northing [km]')\n",
    "plt.xlabel('Easting [km]')\n",
    "# classifiers figure\n",
    "fig, ax = plt.subplots(10,1, figsize=(6,50))\n",
    "plt.rcParams.update({'font.size': 14, 'font.sans-serif': 'Arial'})\n",
    "\n",
    "# -----Iterate over classifiers\n",
    "i=0 # loop counter\n",
    "accuracy = [] # classifier accuracy\n",
    "x, y = np.array(im_pts['x']), np.array(im_pts['y']) # image grid numpy arrays (flat)\n",
    "for name, clf in zip(names, classifiers):\n",
    "    \n",
    "    # train classifier\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # calculate accuracy\n",
    "    y_pred = clf.predict(X_test)\n",
    "    accuracy = accuracy + [metrics.accuracy_score(y_test, y_pred)]\n",
    "    \n",
    "    # predict snow classification for the full image \n",
    "    snow_pred = clf.predict(im_pts[feature_cols])\n",
    "\n",
    "    # plot results\n",
    "    ax[i].scatter(x[snow_pred==1]/1000, y[snow_pred==1]/1000, s=0.1, color='cyan', label='snow')\n",
    "    ax[i].scatter(x[snow_pred==0]/1000, y[snow_pred==0]/1000, s=0.1, color='brown', label='non-snow')\n",
    "    ax[i].set_title(name + ' | Accuracy: ' + str(np.round(accuracy[i]*100,2)))\n",
    "    ax[i].set_ylabel('Northing [km]')\n",
    "    if i==9:\n",
    "        ax[i].set_xlabel('Easting [km]')\n",
    "\n",
    "    i+=1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----Determine best classifier based on score and accuracy\n",
    "results = pd.DataFrame()\n",
    "results['Classifier'], results['Accuracy'] = names, accuracy\n",
    "clf_best_name = names[np.where(accuracy==np.max(accuracy))[0][0]]\n",
    "clf_best = classifiers[np.where(accuracy==np.max(accuracy))[0][0]]\n",
    "print(results)\n",
    "print('')\n",
    "print('Best accuracy classifier: ' + clf_best_name)\n",
    "\n",
    "# -----Save optimal classifier\n",
    "clf_fn = out_path+'best_classifier.sav'\n",
    "pickle.dump(clf_best, open(clf_fn, 'wb'))\n",
    " \n",
    "# load the model from disk\n",
    "# loaded_model = pickle.load(open(filename, 'rb'))\n",
    "# result = loaded_model.score(X_test, Y_test)\n",
    "# print(result)\n",
    "\n",
    "# -----Display time elapsed\n",
    "t2 = time.time() # stop timer\n",
    "print('')\n",
    "print('Time elapsed: ',str((t2-t1)/60),' minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91438fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Save optimal classifier\n",
    "clf_fn = out_path+'best_classifier.sav'\n",
    "pickle.dump(clf_best, open(clf_fn, 'wb'))\n",
    "print('classifier saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ffeace",
   "metadata": {},
   "source": [
    "### Apply best classifier to other images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73071540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load Planet image file names from directory\n",
    "ims = os.chdir(im_path) # change directory\n",
    "im_names = glob.glob('*SR_clip.tif') # load all .tif file names\n",
    "im_names.sort() # sort file names by date\n",
    "\n",
    "# -----Loop through images\n",
    "for im_name in im_names:\n",
    "    \n",
    "     # open image\n",
    "    im = rio.open(im_name)\n",
    "\n",
    "    # extract date from image name\n",
    "    date = im_name[0:4] + '-' + im_name[4:6] + '-' + im_name[6:8]\n",
    "    dates = dates + [np.datetime64(date)]\n",
    "\n",
    "    # define bands \n",
    "    b = im.read(1).astype(float) \n",
    "    g = im.read(2).astype(float) \n",
    "    r = im.read(3).astype(float) \n",
    "    nir = im.read(4).astype(float) \n",
    "    # compute MNDSI\n",
    "    mndsi = es.normalized_diff(r, nir) \n",
    "    \n",
    "    # define coordinates grid\n",
    "    x = np.linspace(im.bounds.left, im.bounds.right, num=np.shape(b)[1])\n",
    "    y = np.linspace(im.bounds.top, im.bounds.bottom, num=np.shape(b)[0])\n",
    "    \n",
    "    # predict snow-covered pixels with classifier\n",
    "    snow_pred = clf.predict(im_pts[feature_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
