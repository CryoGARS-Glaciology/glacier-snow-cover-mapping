{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13171dd0-8bd1-46b6-a56f-3ddaa4225061",
   "metadata": {},
   "source": [
    "# Notebook to compare automatically detected snowline elevations to USGS ELA estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f152df-5c49-4d22-b33b-468ae3d59bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----Import packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from scipy.stats import iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca53d4d-aa42-4591-ad55-5839240069f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to USGS mass balance data\n",
    "usgs_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "# path to study-sites/\n",
    "study_sites_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/snow_cover_mapping/study-sites/'\n",
    "# path to snow-cover-mapping/\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f0f0a2-36fb-4693-b3ed-70526c874572",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry']\n",
    "\n",
    "# set up figure\n",
    "fig, ax = plt.subplots(len(site_names), 1, figsize=(10,24))\n",
    "plt.rcParams.update({'font.size':14, 'font.sans-serif':'Arial'})\n",
    "\n",
    "# initialize stats dataframe\n",
    "results = pd.DataFrame()\n",
    "\n",
    "# loop through sites\n",
    "for i, site_name in enumerate(site_names):\n",
    "    \n",
    "    print(site_name)\n",
    "    \n",
    "    # load estimated snow lines  \n",
    "    sl_est_fns = glob.glob(study_sites_path + site_name + '/imagery/snowlines/*snowline.csv')\n",
    "    sl_ests = gpd.GeoDataFrame()\n",
    "    for sl_est_fn in sl_est_fns:\n",
    "        sl_est = pd.read_csv(sl_est_fn)\n",
    "        sl_ests = pd.concat([sl_ests, sl_est])\n",
    "    sl_ests.reset_index(drop=True, inplace=True)\n",
    "    sl_ests['datetime'] = sl_ests['datetime'].astype('datetime64[ns]')\n",
    "    \n",
    "    # load USGS data\n",
    "    usgs_fn = usgs_path + site_name + '/Output_' + site_name + '_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs = pd.read_csv(usgs_fn)\n",
    "    usgs['Ba_Date'] = usgs['Ba_Date'].astype('datetime64[ns]')\n",
    "    \n",
    "    # grab unique years in snowline time series\n",
    "    unique_years = np.unique(sl_ests['datetime'].values.astype('datetime64[Y]'))\n",
    "    # loop through unique years\n",
    "    labeled=False # whether label has been added to axis legend\n",
    "    for unique_year in unique_years:\n",
    "        # grab USGS ELAs\n",
    "        usgs_year = usgs.iloc[usgs['Ba_Date'].values.astype('datetime64[Y]')==unique_year]\n",
    "        # grab all snowlines within 1 week of USGS observation\n",
    "        threshold = np.timedelta64(7, 'D')\n",
    "        sl_ests_year = sl_ests.loc[np.abs(sl_ests['datetime'].values.astype('datetime64[D]')\n",
    "                                   - usgs_year['Ba_Date'].values.astype('datetime64[D]')[0]) < threshold]\n",
    "            \n",
    "        # calculate difference statistics, add to dataframe\n",
    "        if len(sl_ests_year) > 1:\n",
    "            result = pd.DataFrame({'Site name': [site_name],\n",
    "                                   'Year': [str(unique_year)],\n",
    "                                   'USGS Ba Date': [str(usgs_year['Ba_Date'].values[0])[0:10]],\n",
    "                                   'USGS ELA [m]': [usgs_year['ELA'].values[0]],\n",
    "                                   'Snowline date(s)': [sl_ests_year['datetime'].values],\n",
    "                                   'Snowline median elevations [m]': [sl_ests_year['snowlines_elevs_median_m'].values],\n",
    "                                   'Median snowline median elevations [m]': [np.nanmedian(sl_ests_year['snowlines_elevs_median_m'].values)],\n",
    "                                   'Difference median [m]': [np.nanmedian(sl_ests_year['snowlines_elevs_median_m'].values - usgs_year['ELA'].values)],\n",
    "                                   'Difference IQR [m]': [iqr(sl_ests_year['snowlines_elevs_median_m'].values - np.nanmedian(usgs_year['ELA'].values), nan_policy='omit')],\n",
    "                                   'Difference mean [m]': [np.nanmean(sl_ests_year['snowlines_elevs_median_m'].values - np.nanmedian(usgs_year['ELA'].values))],\n",
    "                                   'Difference std. [m]': [np.nanstd(sl_ests_year['snowlines_elevs_median_m'].values - np.nanmedian(usgs_year['ELA'].values))],\n",
    "                                   'N': [len(sl_ests_year)]\n",
    "                                  })\n",
    "            # plot\n",
    "            if labeled==False:\n",
    "                ax[i].plot(usgs_year['Ba_Date'], usgs_year['ELA'], linestyle='None', marker='s', markerfacecolor='None', markeredgecolor='k', label='USGS ELAs')\n",
    "                ax[i].plot(sl_ests_year['datetime'], sl_ests_year['snowlines_elevs_median_m'], '.b', label='Automated snowline timeseries')\n",
    "                labeled=True # don't add any more labels to legend\n",
    "            else:\n",
    "                ax[i].plot(usgs_year['Ba_Date'], usgs_year['ELA'], linestyle='None', marker='s', markerfacecolor='None', markeredgecolor='k')\n",
    "                ax[i].plot(sl_ests_year['datetime'], sl_ests_year['snowlines_elevs_median_m'], '.b')\n",
    "        else:\n",
    "            result = pd.DataFrame({'Site name': [site_name],\n",
    "                                   'Year': [str(unique_year)],\n",
    "                                   'USGS Ba Date': [str(usgs_year['Ba_Date'].values[0])[0:10]],\n",
    "                                   'USGS ELA [m]': [usgs_year['ELA'].values[0]],\n",
    "                                   'Snowline date(s)': [np.datetime64('NaT')],\n",
    "                                   'Snowline median elevations [m]': np.nan,\n",
    "                                   'Median snowline median elevations [m]': np.nan,\n",
    "                                   'Difference median [m]': np.nan,\n",
    "                                   'Difference IQR [m]': np.nan,\n",
    "                                   'Difference mean [m]': np.nan,\n",
    "                                   'Difference std. [m]': np.nan,\n",
    "                                   'N': [0]\n",
    "                                  })\n",
    "        results = pd.concat([results, result])\n",
    "        # add column for average stats for all years\n",
    "        if unique_year==unique_years[-1]:\n",
    "            result = pd.DataFrame({'Site name': [site_name + ' AVERAGE'],\n",
    "                                   'Year': 'N/A',\n",
    "                                   'USGS Ba Date': 'N/A',\n",
    "                                   'USGS ELA [m]': 'N/A',\n",
    "                                   'Snowline date(s)': 'N/A',\n",
    "                                   'Snowline median elevations [m]': 'N/A',\n",
    "                                   'Median snowline median elevations [m]': 'N/A',\n",
    "                                   'Difference median [m]': [np.nanmean(results.loc[results['Site name']==site_name]['Difference median [m]'].values)],\n",
    "                                   'Difference IQR [m]': [np.nanmean(results.loc[results['Site name']==site_name]['Difference IQR [m]'].values)],\n",
    "                                   'Difference mean [m]': [np.nanmean(results.loc[results['Site name']==site_name]['Difference mean [m]'].values)],\n",
    "                                   'Difference std. [m]': [np.nanmean(results.loc[results['Site name']==site_name]['Difference std. [m]'].values)],\n",
    "                                   'N': 'N/A'\n",
    "                                  })\n",
    "            results = pd.concat([results, result])\n",
    "        \n",
    "    ax[i].grid()\n",
    "    ax[i].set_title(site_name)\n",
    "    ax[i].legend(loc='lower left')\n",
    "    if i==2:\n",
    "        ax[i].set_ylabel('Elevation [m]')\n",
    "    ax[i].set_xlim(np.datetime64('2013-01-01'), np.datetime64('2022-11-01'))\n",
    "    \n",
    "    \n",
    "plt.show()\n",
    "\n",
    "# add column for average of all sites\n",
    "result = pd.DataFrame({'Site name': ['ALL SITES AVERAGE'],\n",
    "                       'Year': 'N/A',\n",
    "                       'USGS Ba Date': 'N/A',\n",
    "                       'USGS ELA [m]': 'N/A',\n",
    "                       'Snowline date(s)': 'N/A',\n",
    "                       'Snowline median elevations [m]': 'N/A',\n",
    "                       'Median snowline median elevations [m]': 'N/A',\n",
    "                       'Difference median [m]': [np.nanmean(results['Difference median [m]'].values)],\n",
    "                       'Difference IQR [m]': [np.nanmean(results['Difference IQR [m]'].values)],\n",
    "                       'Difference mean [m]': [np.nanmean(results['Difference mean [m]'].values)],\n",
    "                       'Difference std. [m]': [np.nanmean(results['Difference std. [m]'].values)],\n",
    "                       'N': 'N/A'\n",
    "                      })\n",
    "results = pd.concat([results, result])\n",
    "\n",
    "# save results and figure to file\n",
    "fig_fn = 'USGS_ELA_comparison.png'\n",
    "fig.savefig(base_path + 'figures/' + fig_fn, dpi=200, facecolor='w', edgecolor='none', bbox_inches='tight')\n",
    "print('figure saved to file: ' + base_path + 'figures/' + fig_fn)\n",
    "results_fn = 'USGS_ELA_comparison_stats.csv'\n",
    "results.to_csv(base_path + 'inputs-outputs/' + results_fn, index=False)\n",
    "print('results stats saved to file: ' + base_path + 'inputs-outputs/' + results_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02413a8-0353-4e4a-ad70-fa93f975ad06",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a1e70d-1a42-4987-a1cd-3a695523b47c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
