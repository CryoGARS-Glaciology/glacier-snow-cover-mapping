{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bab1b699",
   "metadata": {},
   "source": [
    "# Classify snow-covered area (SCA) in Sentinel-2 surface reflectance imagery: full pipeline\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "Department of Geosciences, Boise State University\n",
    "\n",
    "2022\n",
    "\n",
    "### Requirements:\n",
    "- Area of Interest (AOI) shapefile: where snow will be classified in all available images. \n",
    "- Google Earth Engine (GEE) account: used to pull DEM over the AOI. Sign up for a free account [here](https://earthengine.google.com/new_signup/). \n",
    "- Digital elevation model (DEM) (_optional_): used to extract elevations over the AOI and for each snowline. If no DEM is provided, the ASTER Global DEM will be loaded through GEE. \n",
    "\n",
    "### Outline:\n",
    "__0. Setup__ paths in directory, file locations, authenticate GEE - _modify this section!_\n",
    "\n",
    "__1. Load images__ over the AOI \n",
    "\n",
    "__2. Classify SCA__ and use the snow elevations distribution to estimate the seasonal snowline\n",
    "\n",
    "__3. Delineate snowlines__ using classified images. \n",
    "\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e4e890",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "\n",
    "#### Define paths in directory and desired settings. \n",
    "Modify lines located within the following:\n",
    "\n",
    "`#### MODIFY HERE ####`  \n",
    "\n",
    "`#####################`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a86c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "\n",
    "# -----Paths in directory\n",
    "site_name = 'SouthCascade'\n",
    "# path to snow-cover-mapping/\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# path to AOI including the name of the shapefile\n",
    "AOI_fn = base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp'\n",
    "# path to DEM including the name of the tif file\n",
    "# Note: set DEM_fn=None if you want to use the ASTER GDEM on Google Earth Engine\n",
    "DEM_fn = base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif'\n",
    "# path for output images\n",
    "out_path = base_path + '../study-sites/' + site_name + '/imagery/Sentinel-2/'\n",
    "# path for output figures\n",
    "figures_out_path = base_path + '../study-sites/' + site_name + '/figures/'\n",
    "\n",
    "# -----Define image search filters\n",
    "date_start = '2022-07-01'\n",
    "date_end = '2022-12-01'\n",
    "month_start = 5\n",
    "month_end = 10\n",
    "cloud_cover_max = 50\n",
    "\n",
    "# -----Determine settings\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "skip_clipped = False # = True to skip images where bands appear \"clipped\", i.e. max blue SR < 0.8\n",
    "crop_to_AOI = True # = True to crop images to AOI before calculating SCA\n",
    "save_outputs = True # = True to save SCA images to file\n",
    "save_figures = True # = True to save SCA output figures to file\n",
    "\n",
    "#######################\n",
    "\n",
    "# -----Import packages\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import wxee as wx\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from osgeo import gdal\n",
    "import matplotlib\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Polygon, shape\n",
    "import shapely.geometry\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geemap\n",
    "import math\n",
    "import sys\n",
    "import ee\n",
    "import fiona\n",
    "import pickle\n",
    "import wxee as wx\n",
    "import time\n",
    "\n",
    "# -----Add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils_PlanetScope as pf\n",
    "import pipeline_utils_Landsat as lf\n",
    "\n",
    "# -----Load dataset dictionary\n",
    "with open(base_path + 'inputs-outputs/datasets_characteristics.pkl', 'rb') as fn:\n",
    "    dataset_dict = pickle.load(fn)\n",
    "dataset = 'Sentinel2'\n",
    "ds_dict = dataset_dict[dataset]\n",
    "ds_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7e78f7",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize Google Earth Engine (GEE). \n",
    "\n",
    "__Note:__ The first time you run the following cell, you will be asked to authenticate your GEE account for use in this notebook. This will send you to an external web page, where you will walk through the GEE authentication workflow and copy an authentication code back in this notebook when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d23d4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ca0891",
   "metadata": {},
   "source": [
    "#### Load AOI and DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4807ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load AOI as gpd.GeoDataFrame\n",
    "AOI_fn = glob.glob(AOI_fn)[0]\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "# reproject the AOI to WGS to solve for the optimal UTM zone\n",
    "AOI_WGS = AOI.to_crs(4326)\n",
    "AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "epsg_UTM = lf.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "    \n",
    "# -----Load DEM as Xarray DataSet\n",
    "if DEM_fn==None:\n",
    "    \n",
    "    # query GEE for DEM\n",
    "    DEM, AOI_UTM = sf.query_GEE_for_DEM(AOI)\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # reproject AOI to UTM\n",
    "    AOI_UTM = AOI.to_crs(str(epsg_UTM))\n",
    "    # load DEM as xarray DataSet\n",
    "    DEM_fn = glob.glob(DEM_fn)[0]\n",
    "    DEM_rio = rio.open(DEM_fn) # open using rasterio to access the transform\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "    # reproject the DEM to the optimal UTM zone\n",
    "    DEM = DEM.rio.reproject(str('EPSG:'+epsg_UTM))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5b99f6",
   "metadata": {},
   "source": [
    "## 1. Load images over the AOI and mask cloudy pixels using the `QA_PIXEL` band\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7f8995",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Check if masked surface reflectance images already exist in file\n",
    "S2_masked_fn = dataset + '_' + site_name + '_' + date_start.replace('-','') + '_' + date_end.replace('-','') + '_masked.nc'\n",
    "if len(glob.glob(out_path + S2_masked_fn)) > 0:\n",
    "    \n",
    "    # load masked image collection from file\n",
    "    print('Sentinel-2 masked SR image collection already exists in file, loading...')\n",
    "    S2_masked = xr.open_dataset(out_path + S2_masked_fn)\n",
    "                             \n",
    "else:\n",
    "\n",
    "    # query GEE for SR images\n",
    "    print('Querying GEE for SR image...')\n",
    "    S2_masked = lf.query_GEE_for_Sentinel2_SR(AOI, date_start, date_end, month_start, month_end, cloud_cover_max, ds_dict)\n",
    "    \n",
    "    # save masked image collection\n",
    "    S2_masked.to_netcdf(out_path + S2_masked_fn)\n",
    "    print('Sentinel-2 masked SR image collection saved to file: ' + out_path + S2_masked_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8226b3a7",
   "metadata": {},
   "source": [
    "## 2. Classify images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ec9df6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load trained classifier and feature columns\n",
    "clf_fn = base_path+'inputs-outputs/S2_classifier_all_sites.sav'\n",
    "clf = pickle.load(open(clf_fn, 'rb'))\n",
    "feature_cols_fn = base_path+'inputs-outputs/S2_feature_cols.pkl'\n",
    "feature_cols = pickle.load(open(feature_cols_fn,'rb'))\n",
    "\n",
    "# classify images\n",
    "S2_masked_classified, S2_masked_classified_fn, fig = lf.classify_image_collection(S2_masked, clf, feature_cols, \n",
    "                                                                                  crop_to_AOI, AOI_UTM, ds_dict, \n",
    "                                                                                  dataset, site_name, out_path, \n",
    "                                                                                  date_start, date_end, plot_results, \n",
    "                                                                                  figures_out_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f6b74a",
   "metadata": {},
   "source": [
    "## 3. Delineate snowlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0acce25",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "snowlines_df = lf.Landsat_delineate_snow_line(S2_masked, S2_masked_classified, date_start, \n",
    "                                              date_end, site_name, AOI_UTM, DEM, ds_dict, \n",
    "                                              dataset, out_path, figures_out_path, plot_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce54968-e9c8-4f12-a131-288bce826952",
   "metadata": {},
   "source": [
    "#### Optional: compile figures into .gif, delete individual figures "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cfc854-a1f0-4ed2-9510-11798a94ec80",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Modify the strings below according to your file names ###\n",
    "\n",
    "# identify the string that is present in all filenames of the figures that you want to compile\n",
    "fig_fns_str = 'Sentinel2_' + site_name + '_*SCA.png'\n",
    "# define the output .gif filename\n",
    "gif_fn = 'Sentinel2_' + site_name + '_' + date_start.replace('-','') + '_' + date_end.replace('-','') + '_SCA.gif' \n",
    "\n",
    "# -----Make a .gif of output images\n",
    "from PIL import Image as PIL_Image\n",
    "from IPython.display import Image as IPy_Image\n",
    "os.chdir(figures_out_path)\n",
    "fig_fns = glob.glob(fig_fns_str) # load all output figure file names\n",
    "fig_fns = sorted(fig_fns) # sort chronologically\n",
    "\n",
    "# grab figures date range for .gif file name\n",
    "frames = [PIL_Image.open(im) for im in fig_fns]\n",
    "frame_one = frames[0]\n",
    "frame_one.save(figures_out_path + gif_fn, format=\"GIF\", append_images=frames, save_all=True, duration=2000, loop=0)\n",
    "print('GIF saved to file:' + figures_out_path + gif_fn)\n",
    "\n",
    "\n",
    "# -----Clean up: delete individual figure files\n",
    "for fn in fig_fns:\n",
    "    os.remove(os.path.join(figures_out_path, fn))\n",
    "print('Individual figure files deleted.')\n",
    "\n",
    "# -----Display .gif\n",
    "IPy_Image(filename = figures_out_path + gif_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d3593-db2a-40c0-9676-02c05aaf3fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
