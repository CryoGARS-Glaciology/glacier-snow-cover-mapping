{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc47efcf",
   "metadata": {},
   "source": [
    "# Filter snowlines using monthly median and IQR of full timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c83a09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# specify site name\n",
    "site_name = 'LemonCreek'\n",
    "# path where figures will be saved\n",
    "figures_out_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/snow_cover_mapping/study-sites/' + site_name + '/figures/' \n",
    "# path to snowline files\n",
    "sl_est_path = figures_out_path +'../imagery/snowlines/' \n",
    "# path where filtered snowlines will be saved\n",
    "out_path = sl_est_path \n",
    "# path to USGS mass balance data/ELA csvs \n",
    "# If no USGS files, set usgs_path=None\n",
    "usgs_path = None #'/Users/raineyaberle/Google Drive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "#######################\n",
    "\n",
    "# import packages\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy.stats import iqr\n",
    "from time import mktime\n",
    "import seaborn as sns\n",
    "from scipy.stats import median_abs_deviation as mad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842f2c24",
   "metadata": {},
   "source": [
    "### Stack observations by month, filter points using the monthly distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02aed4f7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Compile snowline files\n",
    "sl_est_fns = glob.glob(sl_est_path + '*snowline.csv')\n",
    "# compile all snowline files into one DataFrame\n",
    "sl_est_full = pd.DataFrame()\n",
    "for fn in sl_est_fns:\n",
    "    # read file\n",
    "    if 'csv' in fn:\n",
    "        sl_est = pd.read_csv(fn)\n",
    "    elif 'pkl' in fn:\n",
    "        sl_est = pickle.load(open(fn, 'rb'))\n",
    "    # concatenate to df\n",
    "    sl_est_full = pd.concat([sl_est_full, sl_est])\n",
    "sl_est_full = sl_est_full.reset_index(drop=True).sort_values(by=['datetime']) # renumber, sort by date\n",
    "\n",
    "# -----Reformat snowlines dataframes\n",
    "# unify datetime datatypes\n",
    "sl_est_full['datetime'] = sl_est_full['datetime'].astype('datetime64[ns]')\n",
    "# add month column\n",
    "sl_est_full['month'] = [x.month for x in sl_est_full['datetime']]\n",
    "# extract all unique months\n",
    "months = np.unique(sl_est_full['month'])\n",
    "# set datetime as index\n",
    "sl_est_full.index = sl_est_full['datetime']\n",
    "\n",
    "# ----Set up figure\n",
    "fig = plt.figure(figsize=(20, 6))\n",
    "plt.rcParams.update({'font.size':18, 'font.sans-serif':'Arial'})\n",
    "spec = fig.add_gridspec(ncols=2, nrows=1, width_ratios=[1, 2.5])\n",
    "ax1 = fig.add_subplot(spec[0, 0])\n",
    "ax1.set_xlabel('Month')\n",
    "ax1.set_ylabel('Median snowline elevations [m]')\n",
    "ax1.grid()\n",
    "ax2 = fig.add_subplot(spec[0, 1])\n",
    "ax2.set_xlabel('Date')\n",
    "ax2.grid()\n",
    "\n",
    "# -----Filter points using median and IQR trend\n",
    "med = np.array([np.nanmedian(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m']) for month in months])\n",
    "# mean = np.array([np.nanmean(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m']) for month in months])\n",
    "# std = np.array([np.nanstd(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m']) for month in months])\n",
    "# MAD = np.array([mad(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m'], nan_policy='omit') for month in months])\n",
    "IQR_min = np.array([iqr(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m'],\n",
    "                        rng=(25,50), nan_policy='omit') for month in months])\n",
    "# if minimum goes below the glacier elevation range, make it the minimum elevation\n",
    "IQR_min[IQR_min < np.nanmin(sl_est_full['snowlines_elevs_median_m'])]== np.nanmin(sl_est_full['snowlines_elevs_median_m'])\n",
    "IQR_max = np.array([iqr(sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m'],\n",
    "                        rng=(50,75), nan_policy='omit')*3 for month in months])\n",
    "# if the IQR_max = IQR_min, increase the max value by 10% the elevation range\n",
    "IQR_max[IQR_max==IQR_min] = (np.nanmax(sl_est_full['snowlines_elevs_median_m']) - np.nanmin(sl_est_full['snowlines_elevs_median_m']))*0.1\n",
    "\n",
    "sl_est_full_filt = sl_est_full.copy() # filtered dataframe\n",
    "n_filt = 0 # count number of filtered points\n",
    "for j, month in enumerate(months):\n",
    "    Ifilt = np.ravel(np.argwhere((sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m'] > med[j]+IQR_max[j]).values |\n",
    "                    ((sl_est_full.loc[sl_est_full['month']==month]['snowlines_elevs_median_m'] < med[j]-IQR_min[j]).values)))\n",
    "    n_filt = n_filt + len(Ifilt)\n",
    "    if len(Ifilt)>0:\n",
    "        sl_est_full_filt = sl_est_full_filt.mask((sl_est_full_filt['month']==month) & (sl_est_full_filt['snowlines_elevs_median_m'] > med[j]+IQR_max[j]))\n",
    "        sl_est_full_filt = sl_est_full_filt.mask((sl_est_full_filt['month']==month) & (sl_est_full_filt['snowlines_elevs_median_m'] < med[j]-IQR_min[j]))\n",
    "\n",
    "    # removed points\n",
    "    ax1.plot(sl_est_full.loc[sl_est_full['month']==month].iloc[Ifilt]['month'],\n",
    "             sl_est_full.loc[sl_est_full['month']==month].iloc[Ifilt]['snowlines_elevs_median_m'],\n",
    "             'x', markersize=5, color='#969696', label='_nolegend_')\n",
    "    ax2.plot(sl_est_full.loc[sl_est_full['month']==month].iloc[Ifilt]['datetime'],\n",
    "             sl_est_full.loc[sl_est_full['month']==month].iloc[Ifilt]['snowlines_elevs_median_m'],\n",
    "             'x', markersize=5, color='#969696')\n",
    "\n",
    "# -----Determine annual ELAs\n",
    "# add years column\n",
    "sl_est_full_filt['year'] = [x.year for x in sl_est_full_filt['datetime']]\n",
    "# grab all unique years\n",
    "years = np.unique(sl_est_full_filt['year'].dropna())\n",
    "# initialize dataframe for ELAs\n",
    "ELAs_df = pd.DataFrame()\n",
    "# loop through years, save maximum median snowline elevation and date of observation\n",
    "for year in years:\n",
    "    sl_est_year = sl_est_full_filt.loc[sl_est_full_filt['year']==year]\n",
    "    ELA, dt = sl_est_year.loc[sl_est_year['snowlines_elevs_median_m']==np.max(sl_est_year['snowlines_elevs_median_m'])][['snowlines_elevs_median_m', 'datetime']].values[0]\n",
    "    df = pd.DataFrame({'ELA_m': ELA,\n",
    "                       'datetime':dt},\n",
    "                      index=[0])\n",
    "    ELAs_df = pd.concat([ELAs_df, df])\n",
    "ELAs_df = ELAs_df.reset_index(drop=True)\n",
    "\n",
    "# -----Plot\n",
    "ax1.set_xlim(np.min(months)-0.5, np.max(months)+0.5)\n",
    "ax2.set_xlim(np.nanmin(sl_est_full['datetime']), np.nanmax(sl_est_full['datetime']))\n",
    "# plot minimum elevation\n",
    "elev_min = np.nanmin(sl_est_full['snowlines_elevs_median_m'])\n",
    "ax1.plot([ax1.get_xlim()[0], ax1.get_xlim()[1]],\n",
    "         [elev_min, elev_min], '-', color='#d95f02', label='_nolegend_')\n",
    "ax2.plot([ax2.get_xlim()[0], ax2.get_xlim()[1]],\n",
    "         [elev_min, elev_min], '-', color='#d95f02', label='_nolegend_')\n",
    "# range of acceptable values\n",
    "ax1.fill_between(months, med-IQR_min, med+IQR_max, color='#4eb3d3', label='Acceptable range')\n",
    "# monthly median\n",
    "ax1.plot(months, med, '-b', label='Monthly median')\n",
    "# filtered time series\n",
    "ax1.plot(sl_est_full_filt['month'], sl_est_full_filt['snowlines_elevs_median_m'], '.k', markersize=10, label='Filtered time series')\n",
    "ax2.plot(sl_est_full_filt['datetime'], sl_est_full_filt['snowlines_elevs_median_m'], '.k', markersize=10)\n",
    "# ELAs\n",
    "ax2.plot(ELAs_df['datetime'], ELAs_df['ELA_m'], 's', color='b', markersize=10)\n",
    "# dummy points for legend\n",
    "ax1.plot(0, 0, 'x', markersize=5, color='#969696', label='Removed points')\n",
    "ax1.plot(0, 0,  's', color='b', markersize=10, label='ELA')\n",
    "# optional: plot USGS ELA estimates\n",
    "if usgs_path:\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA_m']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype(np.datetime64)\n",
    "    ax1.plot(0,0, 's', markerfacecolor='None', markeredgecolor='orange',\n",
    "             ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "    ax2.plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='orange',\n",
    "             ms=10, markeredgewidth=2, label='_nolegend_')\n",
    "# set axis limits\n",
    "ax1.set_xticks(np.linspace(months[0], months[-1], num=months[-1]-months[0]+1))\n",
    "ax1.set_xlim(np.min(months)-0.5, np.max(months)+0.5)\n",
    "ax2.set_xlim(np.nanmin(sl_est_full['datetime']), np.nanmax(sl_est_full['datetime']))\n",
    "ymin, ymax = (np.nanmin(np.concatenate([sl_est_full['snowlines_elevs_median_m'].values, np.array(med-IQR_min)]))-25,\n",
    "              np.nanmax(np.concatenate([sl_est_full['snowlines_elevs_median_m'].values, np.array(med+IQR_max)]))+25)\n",
    "ax1.set_ylim(ymin, ymax)\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "# add legend to figure\n",
    "handles, labels = ax1.get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc='upper center', ncol=len(labels))\n",
    "\n",
    "plt.show()\n",
    "print('Number of removed points = '+str(n_filt))\n",
    "\n",
    "# -----Save figure\n",
    "min_date = str(np.nanmin(sl_est_full['datetime']))[0:10].replace('-','')\n",
    "max_date = str(np.nanmax(sl_est_full['datetime']))[0:10].replace('-','')\n",
    "fig_fn = figures_out_path + min_date + '_'+ max_date + '_' + site_name + '_filtered_snowlines_automated.png'\n",
    "fig.savefig(fig_fn, dpi=300, facecolor='w')\n",
    "print('figure saved to file: ' + fig_fn)\n",
    "\n",
    "# -----Save filtered snowline time series\n",
    "sl_fn = min_date + '_' + max_date + '_' + site_name + '_filtered_snowlines.csv'\n",
    "sl_est_full_filt = sl_est_full_filt.dropna().drop(['datetime', 'month'], axis=1)\n",
    "sl_est_full_filt.to_csv(out_path + sl_fn)\n",
    "print('filtered snowlines saved to file: ' + out_path + sl_fn)\n",
    "\n",
    "# -----Save ELA times series\n",
    "ELAs_fn = min_date + '_' + max_date + '_' + site_name + '_ELAs.csv'\n",
    "ELAs_df.to_csv(out_path + ELAs_fn)\n",
    "print('ELAs saved to file: ' + out_path + ELAs_fn)\n",
    "print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a72fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
