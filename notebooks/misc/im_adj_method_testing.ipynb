{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95fffd60-f933-4e95-a50d-129b1121c3c0",
   "metadata": {},
   "source": [
    "# Test using top and bottom elevations polygons to determine image adjustment method\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "October 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0e7740-b30c-41a9-9ecd-0e2fa6c94ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ee\n",
    "import os\n",
    "import rasterio as rio\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import glob\n",
    "from shapely.geometry import Polygon, MultiPolygon, shape, Point, LineString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b8ff99-0ceb-4f36-8713-f34e03e6a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "\n",
    "# -----Paths in directory\n",
    "site_name = 'Wolverine'\n",
    "# path to images\n",
    "im_path = base_path + '../study-sites/' + site_name + '/imagery/PlanetScope/2016-2021/'\n",
    "# path to AOI including the name of the shapefile\n",
    "AOI_fn = base_path + '../../GIS_data/RGI_outlines/' + site_name + '_RGI.shp'\n",
    "# path for output images\n",
    "out_path = im_path + '../'\n",
    "# path for output figures\n",
    "figures_out_path = im_path + '../../../figures/'\n",
    "\n",
    "# -----Set paths for output files\n",
    "im_mosaic_path = out_path + 'mosaics/'\n",
    "im_adj_path = out_path + 'adjusted-filtered/'\n",
    "im_classified_path = out_path + 'classified/'\n",
    "\n",
    "# -----Image file extensions (for mosaicing)\n",
    "ext = 'SR_clip'\n",
    "\n",
    "# -----Determine settings\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "skip_clipped = False # = True to skip images where bands appear \"clipped\", i.e. max blue SR < 0.8\n",
    "crop_to_AOI = True # = True to crop images to AOI before calculating SCA\n",
    "save_outputs = True # = True to save SCA images to file\n",
    "save_figures = True # = True to save SCA output figures to file\n",
    "\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import ps_pipeline_utils as f\n",
    "\n",
    "# Authenticate Google Earth Engine (GEE)\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()\n",
    "    \n",
    "# -----Load AOI as geopandas.GeoDataFrame\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "\n",
    "# -----Query GEE for DEM\n",
    "DEM, AOI_UTM = f.query_GEE_for_DEM(AOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cb7444-cfe9-49ad-b9d6-194a238fe137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_AOI_elev_polys(AOI, im_path, im_fns, DEM):\n",
    "    '''\n",
    "    Function to generate a polygon of the top 20th and bottom percentile elevations \n",
    "    within the defined Area of Interest (AOI).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    AOI: geopandas.geodataframe.GeoDataFrame\n",
    "        Area of interest used for masking images. Must be in same coordinate reference system (CRS) as the image\n",
    "    im_path: str\n",
    "        path in directory to the input images\n",
    "    im_fns: list of str\n",
    "        image file names located in im_path.\n",
    "    DEM: xarray.DataSet\n",
    "        digital elevation model\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    polygons: list\n",
    "        list of shapely.geometry.Polygons representing the top and bottom 20th percentiles of elevations in the AOI. \n",
    "        Median value in each polygon will be used to adjust images, depending on the difference. \n",
    "    im: xarray.DataArray\n",
    "        image\n",
    "    '''\n",
    "\n",
    "    # -----Read one image that contains AOI to create polygon\n",
    "    os.chdir(im_path)\n",
    "    for i in range(0,len(im_fns)):\n",
    "        # define image filename\n",
    "        im_fn = im_fns[i]\n",
    "        # open image\n",
    "        im = rio.open(im_fn)\n",
    "        # mask the image using AOI geometry\n",
    "        mask = rio.features.geometry_mask(AOI.geometry,\n",
    "                                       im.read(1).shape,\n",
    "                                       im.transform,\n",
    "                                       all_touched=False,\n",
    "                                       invert=False)\n",
    "        # check if any image values exist within AOI\n",
    "        if (0 in mask.flatten()):\n",
    "            break\n",
    "\n",
    "    # -----Open image as xarray.DataArray\n",
    "    im_rxr = rxr.open_rasterio(im_fn)\n",
    "    # account for image scalar\n",
    "    if np.nanmean(im_rxr.data[2]) > 1e3:\n",
    "        im_rxr = im_rxr / 10000\n",
    "\n",
    "    # -----Mask the DEM outside the AOI exterior\n",
    "    mask_AOI = rio.features.geometry_mask(AOI.geometry,\n",
    "                                  out_shape=(len(DEM.y), len(DEM.x)),\n",
    "                                  transform=DEM.transform,\n",
    "                                  invert=True)\n",
    "    # convert maskto xarray DataArray\n",
    "    mask_AOI = xr.DataArray(mask_AOI , dims=(\"y\", \"x\"))\n",
    "    # mask DEM values outside the AOI\n",
    "    DEM_AOI = DEM.where(mask_AOI == True)\n",
    "\n",
    "    # -----Interpolate DEM to the image coordinates\n",
    "    band, x, y = im_rxr.indexes.values() # grab indices of image\n",
    "    DEM_AOI_interp = DEM_AOI.interp(x=x, y=y, method=\"nearest\") # interpolate DEM to image coordinates\n",
    "\n",
    "    # -----Top elevations polygon\n",
    "    # mask the bottom percentile of elevations in the DEM\n",
    "    DEM_bottom_P = np.nanpercentile(DEM_AOI_interp.elevation.data.flatten(), 80)\n",
    "    mask = xr.where(DEM_AOI_interp > DEM_bottom_P, 1, 0).elevation.data[0]\n",
    "    # convert mask to polygon\n",
    "    # adapted from: https://rocreguant.com/convert-a-mask-into-a-polygon-for-images-using-shapely-and-rasterio/1786/\n",
    "    polygons_top = []\n",
    "    for s, value in rio.features.shapes(mask.astype(np.int16), mask=(mask >0), transform=im.transform):\n",
    "        polygons_top.append(shape(s))\n",
    "    polygons_top = MultiPolygon(polygons_top)\n",
    "    \n",
    "    # -----Bottom elevations polygon\n",
    "    # mask the top 80th percentile of elevations in the DEM\n",
    "    DEM_bottom_P = np.nanpercentile(DEM_AOI_interp.elevation.data.flatten(), 20)\n",
    "    mask = xr.where(DEM_AOI_interp < DEM_bottom_P, 1, 0).elevation.data[0]\n",
    "    # convert mask to polygon\n",
    "    # adapted from: https://rocreguant.com/convert-a-mask-into-a-polygon-for-images-using-shapely-and-rasterio/1786/\n",
    "    polygons_bottom = []\n",
    "    for s, value in rio.features.shapes(mask.astype(np.int16), mask=(mask >0), transform=im.transform):\n",
    "        polygons_bottom.append(shape(s))\n",
    "    polygons_bottom = MultiPolygon(polygons_bottom)\n",
    "        \n",
    "    return polygons_top, polygons_bottom, im_fn, im_rxr\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debc970f-2f2d-48de-a48a-ef047d85b543",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Read image mosaic file names\n",
    "os.chdir(im_mosaic_path)\n",
    "im_mosaic_fns = glob.glob('*.tif')\n",
    "im_mosaic_fns.sort()\n",
    "\n",
    "# -----Create a polygon(s) of the top 20th percentile elevations within the AOI\n",
    "polygon_top, polygon_bottom, im_fn, im = create_AOI_elev_polys(AOI_UTM, im_mosaic_path, im_mosaic_fns, DEM)\n",
    "# plot\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(np.dstack([im.data[2], im.data[1], im.data[0]]), \n",
    "          extent=(np.min(im.x), np.max(im.x), np.min(im.y), np.max(im.y)))\n",
    "AOI_UTM.plot(ax=ax, facecolor='none', edgecolor='black', linewidth=2, label='AOI')\n",
    "for geom, count in list(zip(polygon_top.geoms, np.arange(0,len(polygon_top.geoms)))):\n",
    "    xs, ys = geom.exterior.xy\n",
    "    if count==0:\n",
    "        ax.plot([x for x in xs], [y for y in ys], color='orange', label='top polygon(s)')\n",
    "    else:\n",
    "        ax.plot([x for x in xs], [y for y in ys], color='orange', label='_nolegend_')\n",
    "for geom, count in list(zip(polygon_bottom.geoms, np.arange(0,len(polygon_bottom.geoms)))):\n",
    "    xs, ys = geom.exterior.xy\n",
    "    if count==0:\n",
    "        ax.plot([x for x in xs], [y for y in ys], color='cyan', label='bottom polygon(s)')\n",
    "    else:\n",
    "        ax.plot([x for x in xs], [y for y in ys], color='cyan', label='_nolegend_')\n",
    "ax.set_xlabel('Easting [m]')\n",
    "ax.set_ylabel('Northing [m]')\n",
    "ax.set_title(im_fn)\n",
    "fig.legend(loc='upper right')\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "# -----Loop through images\n",
    "im_dts = []\n",
    "SR_top_medians = np.zeros(len(im_mosaic_fns))\n",
    "SR_bottom_medians = np.zeros(len(im_mosaic_fns))\n",
    "differences = np.zeros(len(im_mosaic_fns))\n",
    "for count, im_mosaic_fn in enumerate(im_mosaic_fns):\n",
    "    \n",
    "    print(im_mosaic_fn)\n",
    "    \n",
    "    im_dts = im_dts + [np.datetime64(str(im_mosaic_fn[0:4]) + '-' + str(im_mosaic_fn[4:6]) + '-' \n",
    "                      + str(im_mosaic_fn[6:8]) + 'T' + str(im_mosaic_fn[9:11]) + ':00')]\n",
    "            \n",
    "    # -----Load input image\n",
    "    im_rxr = rxr.open_rasterio(im_mosaic_path + im_mosaic_fn)\n",
    "    im_rio = rio.open(im_mosaic_path + im_mosaic_fn)\n",
    "    # set no data values to NaN\n",
    "    im_rxr = xr.where(im_rxr!=-9999)\n",
    "    # account for image scalar multiplier if necessary\n",
    "    im_scalar = 10000\n",
    "    if np.nanmean(im_rxr.data[2]) > 1e3:\n",
    "        im_rxr = im_rxr / im_scalar\n",
    "    # define bands\n",
    "    b = im_rxr.data[0]\n",
    "    g = im_rxr.data[1]\n",
    "    r = im_rxr.data[2]\n",
    "    nir = im_rxr.data[3]\n",
    "            \n",
    "    # -----Return if image does not contain polygon\n",
    "    # mask the image using polygon geometries\n",
    "    mask_top = rio.features.geometry_mask([polygon_top],\n",
    "                                   np.shape(b),\n",
    "                                   im_rio.transform,\n",
    "                                   all_touched=False,\n",
    "                                   invert=False)\n",
    "    mask_bottom = rio.features.geometry_mask([polygon_bottom],\n",
    "                                   np.shape(b),\n",
    "                                   im_rio.transform,\n",
    "                                   all_touched=False,\n",
    "                                   invert=False)\n",
    "    # skip if image does not contain polygon\n",
    "    if (0 not in mask_top.flatten()) or (0 not in mask_bottom.flatten()):\n",
    "        print('image does not contain polygons... skipping.')\n",
    "        continue \n",
    "            \n",
    "    # -----Return if no real values exist within the SCA\n",
    "    if (np.nanmean(b)==0) or (np.isnan(np.nanmean(b))):\n",
    "        print('image does not contain any real values within the polygon... skipping.')\n",
    "        continue\n",
    "        \n",
    "    # -----Filter image points outside the top polygon\n",
    "    b_top_polygon = b[mask_top==0]\n",
    "    g_top_polygon = g[mask_top==0]\n",
    "    r_top_polygon = r[mask_top==0]\n",
    "    nir_top_polygon = nir[mask_top==0]\n",
    "    \n",
    "    # -----Filter image points outside the bottom polygon\n",
    "    b_bottom_polygon = b[mask_bottom==0]\n",
    "    g_bottom_polygon = g[mask_bottom==0]\n",
    "    r_bottom_polygon = r[mask_bottom==0]\n",
    "    nir_bottom_polygon = nir[mask_bottom==0]\n",
    "    \n",
    "    # -----Calculate median value for each polygon and the mean difference between the two\n",
    "    SR_top_median = np.mean([np.nanmedian(b_top_polygon), np.nanmedian(g_top_polygon),\n",
    "                               np.nanmedian(r_top_polygon), np.nanmedian(nir_top_polygon)])\n",
    "    SR_bottom_median = np.mean([np.nanmedian(b_bottom_polygon), np.nanmedian(g_bottom_polygon),\n",
    "                               np.nanmedian(r_bottom_polygon), np.nanmedian(nir_bottom_polygon)])\n",
    "    difference = np.mean([np.nanmedian(b_top_polygon) - np.nanmedian(b_bottom_polygon),\n",
    "                            np.nanmedian(g_top_polygon) - np.nanmedian(g_bottom_polygon),\n",
    "                            np.nanmedian(r_top_polygon) - np.nanmedian(r_bottom_polygon),\n",
    "                            np.nanmedian(nir_top_polygon) - np.nanmedian(nir_bottom_polygon)])\n",
    "    print('Mean value: Top=' + str(SR_top_median) + ', Bottom = ' + str(SR_bottom_median))\n",
    "    print('Mean difference:'+str(difference))\n",
    "    if (SR_top_median < 0.45) and (difference < 0.1):\n",
    "        im_adj_method = 'ICE'\n",
    "    else:\n",
    "        im_adj_method = 'SNOW'\n",
    "        \n",
    "    differences[count] = difference\n",
    "    SR_top_medians[count] = SR_top_median\n",
    "    SR_bottom_medians[count] = SR_bottom_median\n",
    "                   \n",
    "    # -----Adjust SR \n",
    "    if im_adj_method=='SNOW':\n",
    "        \n",
    "        print('im_adj_method = SNOW')\n",
    "\n",
    "        # define desired SR values at the bright area and darkest point for each band\n",
    "        # bright area\n",
    "        bright_b_adj = 0.94\n",
    "        bright_g_adj = 0.95\n",
    "        bright_r_adj = 0.94\n",
    "        bright_nir_adj = 0.78\n",
    "        # dark point\n",
    "        dark_adj = 0.0\n",
    "        \n",
    "        # band_adjusted = band*A - B\n",
    "        # A = (bright_adjusted - dark_adjusted) / (bright - dark)\n",
    "        # B = (dark*bright_adjusted - bright*dark_adjusted) / (bright - dark)\n",
    "        # blue band\n",
    "        bright_b = np.nanmedian(b_top_polygon) # SR at bright point\n",
    "        dark_b = np.nanmin(b) # SR at darkest point\n",
    "        A = (bright_b_adj - dark_adj) / (bright_b - dark_b)\n",
    "        B = (dark_b*bright_b_adj - bright_b*dark_adj) / (bright_b - dark_b)\n",
    "        b_adj = (b * A) - B\n",
    "        b_adj = np.where(b==0, np.nan, b_adj) # replace no data values with nan\n",
    "        # green band\n",
    "        bright_g = np.nanmedian(g_top_polygon) # SR at bright point\n",
    "        dark_g = np.nanmin(g) # SR at darkest point\n",
    "        A = (bright_g_adj - dark_adj) / (bright_g - dark_g)\n",
    "        B = (dark_g*bright_g_adj - bright_g*dark_adj) / (bright_g - dark_g)\n",
    "        g_adj = (g * A) - B\n",
    "        g_adj = np.where(g==0, np.nan, g_adj) # replace no data values with nan\n",
    "        # red band\n",
    "        bright_r = np.nanmedian(r_top_polygon) # SR at bright point\n",
    "        dark_r = np.nanmin(r) # SR at darkest point\n",
    "        A = (bright_r_adj - dark_adj) / (bright_r - dark_r)\n",
    "        B = (dark_r*bright_r_adj - bright_r*dark_adj) / (bright_r - dark_r)\n",
    "        r_adj = (r * A) - B\n",
    "        r_adj = np.where(r==0, np.nan, r_adj) # replace no data values with nan\n",
    "        # nir band\n",
    "        bright_nir = np.nanmedian(nir_top_polygon) # SR at bright point\n",
    "        dark_nir = np.nanmin(nir) # SR at darkest point\n",
    "        A = (bright_nir_adj - dark_adj) / (bright_nir - dark_nir)\n",
    "        B = (dark_nir*bright_nir_adj - bright_nir*dark_adj) / (bright_nir - dark_nir)\n",
    "        nir_adj = (nir * A) - B\n",
    "        nir_adj = np.where(nir==0, np.nan, nir_adj) # replace no data values with nan\n",
    "        \n",
    "    elif im_adj_method=='ICE':\n",
    "        \n",
    "        print('im_adj_method = ICE')\n",
    "        \n",
    "        # define desired SR values at the bright area and darkest point for each band\n",
    "        # bright area\n",
    "        bright_b_adj = 0.58\n",
    "        bright_g_adj = 0.59\n",
    "        bright_r_adj = 0.57\n",
    "        bright_nir_adj = 0.40\n",
    "        # dark point\n",
    "        dark_adj = 0.0\n",
    "        \n",
    "        # band_adjusted = band*A - B\n",
    "        # A = (bright_adjusted - dark_adjusted) / (bright - dark)\n",
    "        # B = (dark*bright_adjusted - bright*dark_adjusted) / (bright - dark)\n",
    "        # blue band\n",
    "        bright_b = np.nanmedian(b_top_polygon) # SR at bright point\n",
    "        dark_b = np.nanmin(b) # SR at darkest point\n",
    "        A = (bright_b_adj - dark_adj) / (bright_b - dark_b)\n",
    "        B = (dark_b*bright_b_adj - bright_b*dark_adj) / (bright_b - dark_b)\n",
    "        b_adj = (b * A) - B\n",
    "        b_adj = np.where(b==0, np.nan, b_adj) # replace no data values with nan\n",
    "        # green band\n",
    "        bright_g = np.nanmedian(g_top_polygon) # SR at bright point\n",
    "        dark_g = np.nanmin(g) # SR at darkest point\n",
    "        A = (bright_g_adj - dark_adj) / (bright_g - dark_g)\n",
    "        B = (dark_g*bright_g_adj - bright_g*dark_adj) / (bright_g - dark_g)\n",
    "        g_adj = (g * A) - B\n",
    "        g_adj = np.where(g==0, np.nan, g_adj) # replace no data values with nan\n",
    "        # red band\n",
    "        bright_r = np.nanmedian(r_top_polygon) # SR at bright point\n",
    "        dark_r = np.nanmin(r) # SR at darkest point\n",
    "        A = (bright_r_adj - dark_adj) / (bright_r - dark_r)\n",
    "        B = (dark_r*bright_r_adj - bright_r*dark_adj) / (bright_r - dark_r)\n",
    "        r_adj = (r * A) - B\n",
    "        r_adj = np.where(r==0, np.nan, r_adj) # replace no data values with nan\n",
    "        # nir band\n",
    "        bright_nir = np.nanmedian(nir_top_polygon) # SR at bright point\n",
    "        dark_nir = np.nanmin(nir) # SR at darkest point\n",
    "        A = (bright_nir_adj - dark_adj) / (bright_nir - dark_nir)\n",
    "        B = (dark_nir*bright_nir_adj - bright_nir*dark_adj) / (bright_nir - dark_nir)\n",
    "        nir_adj = (nir * A) - B\n",
    "        nir_adj = np.where(nir==0, np.nan, nir_adj) # replace no data values with nan\n",
    "        \n",
    "    # -----Plot results\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(8, 16))\n",
    "    ax[0].imshow(np.dstack([r, g, b]), extent=(np.min(im_rxr.x.data)/1e3, np.max(im_rxr.x.data)/1e3, \n",
    "                                              np.min(im_rxr.y.data)/1e3, np.max(im_rxr.y.data)/1e3))\n",
    "    ax[0].set_ylabel('Northing [km]')\n",
    "    ax[0].set_xlabel('Easting [km]')\n",
    "    ax[0].set_title('Raw image')\n",
    "    ax[1].imshow(np.dstack([r_adj, g_adj, b_adj]), extent=(np.min(im_rxr.x.data)/1e3, np.max(im_rxr.x.data)/1e3, \n",
    "                                              np.min(im_rxr.y.data)/1e3, np.max(im_rxr.y.data)/1e3))\n",
    "    ax[1].set_xlabel('Easting [km]')\n",
    "    ax[1].set_title('Adjusted image')\n",
    "    plt.show()\n",
    "    \n",
    "    print('-----')\n",
    "    print(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba21292-5717-4e53-b137-2076810c8c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.dates import DateFormatter\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "lim = (np.datetime64('2016-05'), np.datetime64('2021-10'))\n",
    "ax.plot(im_dts, differences, '.m', markersize=5)\n",
    "ax.plot(im_dts, SR_top_medians, '.c', markersize=5)\n",
    "ax.plot(im_dts, SR_bottom_medians, '.', color='orange', markersize=5)\n",
    "date_form = DateFormatter(\"%y-%m\")\n",
    "ax.xaxis.set_major_formatter(date_form)\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fae097-6f3d-4cf9-8a8e-a98d0131aa67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['SR_top_median', 'SR_bottom_median', 'difference'])\n",
    "df['SR_top_median'] = SR_top_medians\n",
    "df['SR_bottom_median'] = SR_bottom_medians\n",
    "df['difference'] = differences\n",
    "df.index = im_dts\n",
    "\n",
    "df.groupby(by=[df.index.year]).plot(marker='.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf4bd29-236d-4472-9da7-92a26a31aa4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
