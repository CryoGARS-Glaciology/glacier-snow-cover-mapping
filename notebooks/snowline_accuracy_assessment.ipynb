{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a738ee4d-62e5-4e1d-aee5-68dc7f494617",
   "metadata": {},
   "source": [
    "# Conduct snowline accuracy assessment\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "October 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809a61d-618f-44f7-a82c-7946104a000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import ee\n",
    "import wxee as wx\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "from scipy import stats\n",
    "import skimage.io\n",
    "from skimage import feature\n",
    "from shapely.geometry import Point, LineString, shape, MultiPolygon, Polygon\n",
    "from shapely.ops import split, unary_union, polygonize, nearest_points\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc578f-bec3-4e6f-930d-633b083db83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# names of study sites\n",
    "site_names = ['Gulkana'] #['Gulkana', 'SCascade', 'Sperry', 'Wolverine']\n",
    "# path for output figures\n",
    "figures_out_path = base_path+'figures/'\n",
    "\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import ps_pipeline_utils as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffc3d5e-98b1-4ab5-b5c6-a8c1da57eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate Google Earth Engine (GEE)\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ff3d-0006-46c9-8f89-3d2a7ae6734d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Loop through sites\n",
    "results_df = pd.DataFrame(columns=['study_site', 'datetime', 'snowline_obs', 'snowline_est', 'distances'])\n",
    "for site_name in site_names:    \n",
    "\n",
    "    # define path to classified snow images\n",
    "    im_path = base_path + '../study-sites/' + site_name + '/imagery/PlanetScope/'\n",
    "\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "\n",
    "    # load AOI as gpd.GeoDataFrame\n",
    "    AOI_fn = base_path + '../../GIS_data/RGI_outlines/' + site_name + '_RGI.shp'\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "\n",
    "    # query GEE for DEM\n",
    "    DEM, AOI_UTM = f.query_GEE_for_DEM(AOI)\n",
    "\n",
    "    # load observed snow line shapefile names\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    sl_obs_fns.sort() # sort chronologically\n",
    "\n",
    "    # load estimated snowlines\n",
    "    sl_est_fn = im_path + 'snowlines/' + site_name + '_sl_elevs_old.pkl'\n",
    "    sl_ests = pd.read_pickle(sl_est_fn)\n",
    "\n",
    "    # initialize variables\n",
    "    sl_obs_elevs = [None]*len(sl_obs_fns) # observed snow elevations\n",
    "    datetimes = [None]*len(sl_obs_fns) # image datetimes\n",
    "\n",
    "    # loop through observed snow lines\n",
    "    for sl_obs_fn in sl_obs_fns:\n",
    "\n",
    "        # -----Load datasets\n",
    "        # load observed snow line\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:11]\n",
    "        datetime = np.datetime64(date[0:4]+ '-' + date[4:6] + '-' + date[6:8] + ' ' + date[9:11] + ':00:00')\n",
    "        # load estimated snowline\n",
    "        sl_est = sl_ests.loc[sl_ests.datetime==datetime]\n",
    "        # reproject snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs(str(AOI_UTM.crs.to_epsg()))\n",
    "        # open adjusted image of the same date\n",
    "        im_adj_fn = glob.glob(im_path + 'adjusted-filtered/*' + date + '*.tif')[0] # define file name\n",
    "        im_adj = rxr.open_rasterio(im_adj_fn) # open image as xarray.DataArray\n",
    "        im_adj = im_adj.where(im_adj!=-9999) # remove no data values\n",
    "        im_adj = im_adj / 1e4\n",
    "         # open classified image from the same date\n",
    "        im_classified_fn = glob.glob(im_path + 'classified/*' + date + '*.tif')[0] # define file name\n",
    "        im_classified = rxr.open_rasterio(im_classified_fn) # open image as xarray.DataArray\n",
    "        im_classified = im_classified.where(im_classified!=-9999)\n",
    "        \n",
    "        # -----Split line depending on distance between points\n",
    "        max_dist = 100 # m\n",
    "        line = sl_obs_UTM.geometry[0]\n",
    "        first_point = Point(line.coords.xy[0][0], line.coords.xy[1][0])\n",
    "        points = [Point(line.coords.xy[0][i], line.coords.xy[1][i]) for i in np.arange(0,len(line.coords.xy[0]))]\n",
    "        isplit = [0] # point indices where to split the line\n",
    "        for i, p in enumerate(points):\n",
    "            if i!=0:\n",
    "                dist = p.distance(points[i-1])\n",
    "                if dist > max_dist:\n",
    "                    isplit.append(i)\n",
    "        isplit.append(len(points)) # add ending point to complete the last line\n",
    "        line_split = [] # initialize split lines\n",
    "        # loop through split indices\n",
    "        if isplit:\n",
    "            for i, p in enumerate(isplit[:-1]):\n",
    "                if isplit[i+1]-isplit[i] > 1: # must have at least two points to make a line\n",
    "                    line_split = line_split + [LineString(points[isplit[i]:isplit[i+1]])]\n",
    "        else:\n",
    "            line_split = line\n",
    "    \n",
    "        # -----Regrid the observed snowlines to equal spacing\n",
    "        dx = 30 # point spacing\n",
    "        points_regrid = []\n",
    "        for line in line_split:\n",
    "            distances = np.arange(0, line.length, dx)\n",
    "            line_points = [line.interpolate(distance) for distance in distances] + [first_point]\n",
    "            # filter points outside the AOI\n",
    "            IAOI = np.where(np.array([p.within(AOI_UTM.geometry[0]) for p in line_points], dtype=int) ==1)[0]\n",
    "            points_AOI = [line_points[i] for i in IAOI]\n",
    "            points_regrid = points_regrid + [p for p in points_AOI]\n",
    "\n",
    "        # -----Calculate distance between each observed snowline point and the closest estimated snowline point\n",
    "        distances = np.zeros(len(points_regrid))\n",
    "        for i, p in enumerate(points_regrid):\n",
    "            # find nearest point\n",
    "            nearest_point = nearest_points(sl_est.snowlines_coords[0][0], p)[0]\n",
    "            # calculate distance between points\n",
    "            distances[i] = p.distance(nearest_point)\n",
    "            \n",
    "        # -----Display results\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(np.dstack([im_adj.data[2], im_adj.data[1], im_adj.data[0]]), \n",
    "                   extent=(np.min(im_adj.x.data), np.max(im_adj.x.data), np.min(im_adj.y.data), np.max(im_adj.y.data)))\n",
    "        plt.plot([p.coords.xy[0][0] for p in points_regrid], \n",
    "                 [p.coords.xy[1][0] for p in points_regrid], '.c', label='observed')\n",
    "        plt.plot(*sl_est.snowlines_coords[0][0].coords.xy, '.m', label='estimated')\n",
    "        plt.grid()\n",
    "        plt.title(datetime)\n",
    "        plt.show()\n",
    "        \n",
    "        # compile results in df\n",
    "        result_df = pd.DataFrame({'study_site': site_name, \n",
    "                                  'datetime': datetime, \n",
    "                                  'snowline_obs': [points_regrid], \n",
    "                                  'snowline_est': [sl_est.snowlines_coords[0][0]], \n",
    "                                  'distances': [distances]})\n",
    "        # concatenate to results_df\n",
    "        results_df = pd.concat([results_df, result_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09551cab-9733-4f40-8c67-510a0870006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.imshow(np.dstack([im_adj.data[2], im_adj.data[1], im_adj.data[0]]), \n",
    "                   extent=(np.min(im_adj.x.data), np.max(im_adj.x.data), np.min(im_adj.y.data), np.max(im_adj.y.data)))\n",
    "AOI_UTM.plot(ax=ax, facecolor='none', edgecolor='m')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca80d90-fefb-43a2-abaf-15a0bd0d8762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
