{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a0b599d",
   "metadata": {},
   "source": [
    "# Classify snow-covered area (SCA) in PlanetScope iamgery: full pipeline\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "Department of Geosciences, Boise State University\n",
    "\n",
    "2022\n",
    "\n",
    "### Requirements:\n",
    "- Planet account with access to PlanetScope imagery through the NASA CSDA contract. Sign up __[here](https://www.planet.com/markets/nasa/)__.\n",
    "- Area of Interest (AOI) shapefile: where snow will be classified in each image. \n",
    "- PlanetScope 4-band image collection over the AOI. Download images using `planetAPI_image_download.ipynb` or through [PlanetExplorer](https://www.planet.com/explorer/). \n",
    "- Google Earth Engine (GEE) account: used to pull DEM over the AOI. Sign up for a free account [here](). \n",
    "\n",
    "\n",
    "### Outline:\n",
    "__0. Setup__ paths in directory, AOI file location - _modify this section!_\n",
    "\n",
    "__1. Mosaic images__ captured in the same hour\n",
    "\n",
    "__2. Adjust image radiometry__ using median surface reflectance at the top perentile of elevations\n",
    "\n",
    "__3. Classify SCA__ and use the snow elevations distribution to estimate the seasonal snowline\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1054ad9",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "\n",
    "#### Define paths in directory, image file extensions, and desired settings. \n",
    "Modify lines located within the following:\n",
    "\n",
    "`#### MODIFY HERE ####`  \n",
    "\n",
    "`#####################`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c59b1a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "# -----Path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "\n",
    "# -----Paths in directory\n",
    "site_name = 'Sperry'\n",
    "# path to images\n",
    "im_path = base_path+'../study-sites/'+site_name+'/imagery/PlanetScope/2016-2021/'\n",
    "# path to AOI including the name of the shapefile\n",
    "AOI_fn = base_path+'../../GIS_data/RGI_outlines/'+site_name+'_RGI.shp'\n",
    "# path for output images\n",
    "out_path = im_path+'../'\n",
    "# path for output figures\n",
    "figures_out_path = im_path+'../../../figures/'\n",
    "\n",
    "# -----Image file extensions (for mosaicing)\n",
    "ext = 'SR_clip'\n",
    "\n",
    "# -----Determine settings\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "skip_clipped = False # = True to skip images where bands appear \"clipped\", i.e. max blue SR < 0.8\n",
    "crop_to_AOI = True # = True to crop images to AOI before calculating SCA\n",
    "save_outputs = True # = True to save SCA images to file\n",
    "save_figures = True # = True to save SCA output figures to file\n",
    "\n",
    "#######################\n",
    "\n",
    "# -----Import packages\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import subprocess\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import rasterio as rio\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "import time\n",
    "import ee\n",
    "import pickle\n",
    "\n",
    "# -----Add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import ps_pipeline_utils as f\n",
    "\n",
    "# -----Load AOI as geopandas.GeoDataFrame\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "\n",
    "# -----Set paths for output files\n",
    "im_mosaic_path = out_path+'mosaics/'\n",
    "im_adj_path = out_path+'adjusted-filtered/'\n",
    "im_classified_path = out_path+'classified/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e18812",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize Google Earth Engine (GEE). \n",
    "\n",
    "__Note:__ The first time you run the following cell, you will be asked to authenticate your GEE account for use in this notebook. This will send you to an external web page, where you will walk through the GEE authentication workflow and copy an authentication code back in this notebook when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d32926fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc29573",
   "metadata": {},
   "source": [
    "### 1. Mosaic images by date\n",
    "\n",
    "Mosaic all images captured within the same hour to increase area coverage of each image over the AOI. Images captured in different hours are more likely to have drastic variations in illumination. Adapted from code developed by Jukes Liu. \n",
    "\n",
    "If you have `plot_results` set to `True`, I suggest using the output figures to filter out images, such as those that are completely saturated (some small regions of saturation are okay), barely cover the AOI, or have thick cloud cover over a large portion of the AOI. Place unusable images into a separate folder (e.g., `unusable_images`) or otherwise remove them from the `mosaics/` folder before proceeding to step __2.__ below. This takes extra time, but will help to improve the resulting SCA and snow line elevation time series. \n",
    "\n",
    "Note that images with no data over the AOI are skipped in this step. Issues with illumination or radiometry will be further filtered and adjusted in the next step.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6fe592",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load file names with proper extension\n",
    "os.chdir(im_path)\n",
    "im_fns = glob.glob('*' + ext + '*')\n",
    "im_fns.sort() # sort chronologically\n",
    "\n",
    "# ----Mosaic images by date\n",
    "f.mosaic_ims_by_date(im_path, im_fns, ext, im_mosaic_path, AOI, plot_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c9a56c",
   "metadata": {},
   "source": [
    "### 2. Adjust image radiometry\n",
    "\n",
    "Here, we will mitigate issues related to varying illumination and general radiometry by first creating a polygon(s) representing the of an area within the AOI that is likely covered with snow year-round using the upper 30th percentile of elevations. The polygon(s) will then be used to stretch the image, assuming the median surface reflectance value within the polygon is equal to that predicted for snow, and that the darkest point in the image has a surface reflectance of 0. Images with no real data values within the AOI or in the polygon(s) will be skipped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff28bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Read image mosaic file names\n",
    "os.chdir(im_mosaic_path)\n",
    "im_mosaic_fns = glob.glob('*.tif')\n",
    "im_mosaic_fns.sort()\n",
    "\n",
    "# -----Query GEE for DEM\n",
    "DEM, DEM_x, DEM_y, AOI_UTM = f.query_GEE_for_DEM(AOI, im_mosaic_path, im_mosaic_fns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40156eed",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Create a polygon(s) of the top 20th percentile elevations within the AOI\n",
    "polygon, im_fn, im, r, g, b, im_x, im_y = f.create_top_elev_AOI_poly(AOI_UTM, im_mosaic_path, im_mosaic_fns, DEM, DEM_x, DEM_y)\n",
    "# plot\n",
    "if plot_results:\n",
    "    fig = plt.figure(figsize=(8,8))\n",
    "    plt.imshow(np.dstack([r, g, b]), extent=(np.min(im_x), np.max(im_x), np.min(im_y), np.max(im_y)))\n",
    "    plt.plot(*AOI_UTM.geometry[0].exterior.xy, color='black', linewidth=2, label='AOI')\n",
    "    count=0 # count used to only display one polygon in legend\n",
    "    for geom in polygon.geoms:\n",
    "        xs, ys = geom.exterior.xy\n",
    "        if count==0:\n",
    "            plt.plot([x for x in xs], [y for y in ys], color='orange', label='polygon(s)')\n",
    "        else:\n",
    "            plt.plot([x for x in xs], [y for y in ys], color='orange', label='_nolegend_')\n",
    "        count+=1            \n",
    "    plt.xlabel('Easting [m]')\n",
    "    plt.ylabel('Northing [m]')\n",
    "    plt.title(im_fn)\n",
    "    fig.legend(loc='upper right')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# -----Loop through images\n",
    "# for im_mosaic_fn in im_mosaic_fns:\n",
    "    \n",
    "#     # load image\n",
    "#     print(im_mosaic_fn)\n",
    "#     im = rio.open(im_mosaic_fn)\n",
    "    \n",
    "#     # adjust radiometry\n",
    "#     im_adj_fn = f.adjust_image_radiometry(im, im_mosaic_fn, im_mosaic_path, polygon, im_adj_path, skip_clipped, plot_results)\n",
    "                     \n",
    "#     print('----------')\n",
    "#     print(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb82e08",
   "metadata": {},
   "source": [
    "### 3. Classify SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3df01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Read adjusted image file names\n",
    "os.chdir(im_adj_path)\n",
    "im_adj_fns = glob.glob('*.tif')\n",
    "im_adj_fns.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694164b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# start timer\n",
    "t1 = time.time()\n",
    "\n",
    "# -----Load image classifier and feature columns\n",
    "clf_fn = base_path+'inputs-outputs/PS_classifier_all_sites.sav'\n",
    "clf = pickle.load(open(clf_fn, 'rb'))\n",
    "feature_cols_fn = base_path+'inputs-outputs/PS_feature_cols.pkl'\n",
    "feature_cols = pickle.load(open(feature_cols_fn,'rb'))\n",
    "        \n",
    "# -----Create figure for snow elevations box plot\n",
    "fig2, ax = plt.subplots(figsize=(16,8))\n",
    "ax.set_ylabel('Snow elevations [m a.s.l.]')\n",
    "ax.xaxis.set_major_formatter(dates.DateFormatter('%Y'))\n",
    "\n",
    "# -----Loop through images\n",
    "# image datetimes\n",
    "im_dts = [] \n",
    "# DataFrame to hold stats summary\n",
    "df = pd.DataFrame(columns=('site_name', 'datetime', 'im_elev_min', 'im_elev_max', 'snow_elev_min', 'snow_elev_max', \n",
    "                           'snow_elev_median', 'snow_elev_10th_perc', 'snow_elev_90th_perc'))\n",
    "for im_adj_fn in im_adj_fns:\n",
    "\n",
    "    # extract datetime from image name\n",
    "    im_dt = np.datetime64(im_adj_fn[0:4] + '-' + im_adj_fn[4:6] + '-' + im_adj_fn[6:8]\n",
    "                          + 'T' + im_adj_fn[9:11] + ':00:00')\n",
    "    im_dts = im_dts + [im_dt]\n",
    "\n",
    "    # open image\n",
    "    im = rio.open(im_adj_path + im_adj_fn)\n",
    "\n",
    "    # classify snow\n",
    "    im_x, im_y, im_classified = f.classify_image(im, im_adj_fn, clf, feature_cols, crop_to_AOI, AOI_UTM, im_classified_path)  \n",
    "    \n",
    "    # determine snow elevations\n",
    "    if im_classified is not np.nan:\n",
    "        plot_output = True\n",
    "        im_elev_min, im_elev_max, snow_elev, fig = f.determine_snow_elevs(DEM, DEM_x, DEM_y, im, im_classified, im_dt, im_x, im_y, plot_output)\n",
    "\n",
    "        # calculate and plot stats\n",
    "        iqr = stats.iqr(snow_elev, rng=(10, 90))\n",
    "        med = np.median(snow_elev)\n",
    "        ax.add_patch(Rectangle((im_dt-np.timedelta64(1, 'D'), med-iqr/2), \n",
    "                               width=2*np.timedelta64(1, 'D'), height=iqr, color='blue'))\n",
    "        ax.scatter([im_dt, im_dt], [np.min(snow_elev), np.max(snow_elev)], color='blue', s=10)\n",
    "        ax.scatter(im_dt, med, facecolor='white', edgecolor='black', s=20)\n",
    "\n",
    "        # save stats in pandas DataFrame\n",
    "        df_row = pd.DataFrame({'site_name':site_name, 'datetime':im_dt, 'im_elev_min':im_elev_min, 'im_elev_min':im_elev_max, \n",
    "                               'snow_elev_min':np.min(snow_elev), 'snow_elev_min':np.max(snow_elev), 'snow_elev_median':med,  \n",
    "                               'snow_elev_10th_perc':med-iqr/2, 'snow_elev_90th_perc':med+iqr/2}, index=[0])\n",
    "        df = pd.concat([df, df_row], ignore_index=True)\n",
    "\n",
    "        # save figure\n",
    "        if save_figures==True:\n",
    "            fig.savefig(figures_out_path+'PS_'+im_adj_fn[0:15]+'_SCA.png', dpi=200, facecolor='white', edgecolor='none')\n",
    "            print('figure saved to file')\n",
    "\n",
    "# -----Save figure and data table\n",
    "# Create directory for output figures if it does not exist\n",
    "if save_figures and os.path.exists(figures_out_path)==False:\n",
    "    os.mkdir(figures_out_path)\n",
    "    print('made directory for output figures:' + figures_out_path)\n",
    "# save figures\n",
    "if plot_output and save_figures:\n",
    "    fig2.savefig(figures_out_path+site_name+'_snow_elevs.png', dpi=200, facecolor='white', edgecolor='none')\n",
    "    print('snow elevations figure saved to file')\n",
    "# Create directory for output images if it does not exist\n",
    "im_classified_path = out_path+'classified/'\n",
    "if save_outputs and os.path.exists(im_classified_path)==False:\n",
    "    os.mkdir(im_classified_path)\n",
    "    print('made directory for output images:' + im_classified_path)\n",
    "# save classified image stats\n",
    "if save_outputs:\n",
    "    df.to_csv(path_or_buf=im_classified_path+site_name+'_snow_elevs_stats.csv', sep=',', na_rep='', header=True)\n",
    "    print('data table saved to file')\n",
    "\n",
    "# -----Stop timer\n",
    "print('Time elapsed: '+str(np.round((time.time()-t1)/60, 2))+' minutes')\n",
    "\n",
    "# -----Display complete figure 2\n",
    "fig2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cdd2cf2",
   "metadata": {},
   "source": [
    "### _Optional:_ Compile individual figures into a .gif and delete individual figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3818de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as PIL_Image\n",
    "from IPython.display import Image as IPy_Image\n",
    "\n",
    "# -----Make a .gif of output images\n",
    "os.chdir(figures_out_path)\n",
    "fig_fns = glob.glob('PS_*_SCA.png') # load all output figure file names\n",
    "fig_fns.sort() # sort chronologically\n",
    "# grab figures date range for .gif file name\n",
    "fig_start_date = fig_fns[0][3:-15] # first figure date\n",
    "fig_end_date = fig_fns[-1][3:-15] # final figure date\n",
    "frames = [PIL_Image.open(im) for im in fig_fns]\n",
    "frame_one = frames[0]\n",
    "gif_fn = ('PS_' + fig_start_date[0:8] + '_' + fig_end_date[0:8] + '_SCA.gif' )\n",
    "frame_one.save(figures_out_path + gif_fn, format=\"GIF\", append_images=frames, save_all=True, duration=2000, loop=0)\n",
    "print('GIF saved to file:' + figures_out_path + gif_fn)\n",
    "\n",
    "# -----Display .gif\n",
    "IPy_Image(filename=figures_out_path+gif_fn)\n",
    "\n",
    "# -----Clean up: delete individual figure files\n",
    "files = os.listdir(figures_out_path)\n",
    "for file in files:\n",
    "    if ('PS_' in file) and ('_SCA.png' in file):\n",
    "        os.remove(os.path.join(figures_out_path, file))\n",
    "print('Individual figure files deleted.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
