{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1eb620",
   "metadata": {},
   "source": [
    "# Notebook to make figures for conferences and manuscripts\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from skimage.measure import find_contours\n",
    "import ee\n",
    "import sys\n",
    "from shapely.geometry import Point, LineString\n",
    "import rasterio as rio\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, LightSource\n",
    "import matplotlib\n",
    "import glob\n",
    "import wxee as wx\n",
    "import geemap\n",
    "import matplotlib\n",
    "import pickle\n",
    "from scipy.signal import medfilt\n",
    "import os\n",
    "import glob\n",
    "import operator\n",
    "\n",
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "\n",
    "# determine whether to save output figures\n",
    "save_figures = 0\n",
    "\n",
    "# path for saving output figures\n",
    "out_path = base_path+'figures/'\n",
    "\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b11cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate GEE\n",
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430d0c4",
   "metadata": {},
   "source": [
    "## Snow cover products comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1083e7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # -----Load Landsat fSCA\n",
    "# LS_fn = base_path+'../study-sites/Wolverine/imagery/Landsat/fSCA/LC08_AK_016008_20210829_20210913_02_SNOW/LC08_AK_016008_20210829_20210913_02_VIEWABLE_SNOW_UTM.TIF'\n",
    "# LS = rxr.open_rasterio(LS_fn)\n",
    "# # remove no-data values\n",
    "# LS = LS.where(LS != -9999)\n",
    "# # account for image multiplier\n",
    "# LS_scalar = 0.001\n",
    "# LS = LS * LS_scalar\n",
    "# crs = LS.rio.crs.to_string()\n",
    "\n",
    "# # -----Load MODIS fSCA\n",
    "# M_fn = base_path+'../study-sites/Wolverine/imagery/MODIS/Terra_fSCA/2021_08_15.tif'\n",
    "# M = rxr.open_rasterio(M_fn)\n",
    "# # grab snow cover band\n",
    "# M_fSCA = M.isel(band=0)\n",
    "# # remove no data values\n",
    "# M_fSCA = M_fSCA.where(M_fSCA != -3.2768e04)\n",
    "# # reproject \n",
    "# M_fSCA= M_fSCA.rio.reproject(crs)\n",
    "\n",
    "# # -----Load PlanetScope image and snow\n",
    "# # RGB image\n",
    "# PS_path = base_path+'../study-sites/Wolverine/imagery/PlanetScope/adjusted-filtered/'\n",
    "# PS_fn = '20210815_20_adj.tif'\n",
    "# PS = rxr.open_rasterio(PS_path + PS_fn)\n",
    "# PS = PS / 1e4\n",
    "# # classify image\n",
    "# clf_fn = base_path+'/inputs-outputs/PS_classifier_all_sites.sav'\n",
    "# clf = pickle.load(open(clf_fn, 'rb'))\n",
    "# feature_cols_fn = base_path+'inputs-outputs/PS_feature_cols.pkl'\n",
    "# feature_cols = pickle.load(open(feature_cols_fn,'rb'))\n",
    "# sys.path.insert(1, base_path+'functions/')\n",
    "# from ps_pipeline_utils import classify_image\n",
    "# im_classified_fn, im = classify_image(PS_fn, PS_path, clf, feature_cols, False, None, out_path)\n",
    "# # load classified image\n",
    "# im_classified = rxr.open_rasterio(out_path + im_classified_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180d701",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # -----Create snow colormap\n",
    "# color_snow = '#4eb3d3'\n",
    "# color_no_snow = 'w'\n",
    "# # create colormap\n",
    "# colors = [color_no_snow, color_snow]\n",
    "# cmp = cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "# # -----Plot\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10,10))\n",
    "# ax = ax.flatten()\n",
    "# plt.rcParams.update({'font.size':16, 'font.sans-serif':'Arial'})\n",
    "# xmin, xmax, ymin, ymax = 391, 399, 6694, 6702\n",
    "# # MODIS\n",
    "# M_im = ax[0].imshow(M_fSCA.data, cmap=cmp, clim=(0,100),\n",
    "#                     extent=(np.min(M_fSCA.x.data)/1000, np.max(M_fSCA.x.data)/1000, \n",
    "#                             np.min(M_fSCA.y.data)/1000, np.max(M_fSCA.y.data)/1000))\n",
    "# ax[0].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[0].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_xlim(xmin, xmax)\n",
    "# ax[0].set_ylim(ymin, ymax)\n",
    "# ax[0].set_ylabel('Northing [km]')\n",
    "# ax[0].set_title('a) MODIS f$_{SCA}$')\n",
    "# # LS\n",
    "# LS_im = ax[1].imshow(LS_fSCA, cmap=cmp, clim=(0,1),\n",
    "#                    extent=(np.min(LS_x)/1000, np.max(LS_x)/1000, np.min(LS_y)/1000, np.max(LS_y)/1000))\n",
    "# ax[1].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[1].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[1].set_xticklabels([])\n",
    "# ax[1].set_yticklabels([])\n",
    "# ax[1].set_xlim(xmin, xmax)\n",
    "# ax[1].set_ylim(ymin, ymax)\n",
    "# ax[1].set_title('b) Landsat 8 f$_{SCA}$')\n",
    "# # PS RGB\n",
    "# ax[2].imshow(np.dstack([PS.data[2], PS.data[1], PS.data[0]]),\n",
    "#            extent=(np.min(PS.x.data)/1000, np.max(PS.x.data)/1000, np.min(PS.y.data)/1000, np.max(PS.y.data)/1000))\n",
    "# ax[2].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[2].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[2].set_xlim(xmin, xmax)\n",
    "# ax[2].set_ylim(ymin, ymax)\n",
    "# ax[2].set_ylabel('Northing [km]')\n",
    "# ax[2].set_xlabel('Easting [km]')\n",
    "# ax[2].set_title('c) PlanetScope RGB')\n",
    "# # PS snow\n",
    "# im_classified = im_classified.where(im_classified!=-9999)\n",
    "# im_binary = xr.where(im_classified<=2, 1, 0)\n",
    "# PS_snow_im = ax[3].imshow(im_binary.data[0], cmap=cmp, clim=(0,1),\n",
    "#                    extent=(np.min(PS.x.data)/1000, np.max(PS.x.data)/1000, np.min(PS.y.data)/1000, np.max(PS.y.data)/1000))\n",
    "# ax[3].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[3].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[3].set_yticklabels([])\n",
    "# ax[3].set_xlim(xmin, xmax)\n",
    "# ax[3].set_ylim(ymin, ymax)\n",
    "# ax[3].set_xlabel('Easting [km]')\n",
    "# ax[3].set_title('d) PlanetScope SCA')\n",
    "# # colorbar\n",
    "# cbar_ax = fig.add_axes([0.92, 0.35, 0.02, 0.3])\n",
    "# fig.colorbar(M_im, cax=cbar_ax)\n",
    "# plt.show()\n",
    "\n",
    "# if save_figures:\n",
    "#     fig.savefig(out_path+'comparing_SCA_products.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "#     print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f951a",
   "metadata": {},
   "source": [
    "## Study sites: USGS Benchmark Glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209a3d9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry']\n",
    "site_names_display = ['Wolverine', 'Gulkana', 'Lemon Creek', 'South Cascade', 'Sperry']\n",
    "site_colors = ['#1f78b4', '#33a02c', '#fec44f', '#cc4c02', '#984ea3']\n",
    "text_labels = ['a)', 'b)', 'c)', 'd)', 'e)']\n",
    "\n",
    "# define colormap for elevations\n",
    "cmap_elev = plt.cm.terrain(np.linspace(0, 1, 100))\n",
    "cmap_elev = ListedColormap(cmap_elev[25:, :])\n",
    "\n",
    "# -----Set up figure\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 12), layout='constrained')\n",
    "plt.rcParams.update({'font.size':18, 'font.sans-serif':'Arial'})\n",
    "ax = ax.flatten()\n",
    "# -----Loop through sites\n",
    "i=0\n",
    "epsg_A = 32610\n",
    "for site_name, site_color, site_name_display, text_label in list(zip(site_names, site_colors, site_names_display, text_labels)):\n",
    "    ### AOI\n",
    "    # load file\n",
    "    AOI_fn = glob.glob(base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs(4326)\n",
    "    # solve for optimal UTM zone\n",
    "    AOI_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    epsg_UTM = pf.convert_wgs_to_utm(AOI_centroid[0], AOI_centroid[1])\n",
    "    # reproject\n",
    "    AOI_UTM = AOI_WGS.to_crs(epsg_UTM)\n",
    "    AOI_A = AOI.to_crs(epsg_A)\n",
    "    ### DEM\n",
    "    DEM_fn = glob.glob(base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif')[0]\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "    # reproject \n",
    "    # DEM = DEM.rio.reproject(str('EPSG:'+epsg_UTM))\n",
    "    ### Plot\n",
    "    # A) Study sites map\n",
    "    ax[0].plot(AOI_A.geometry[0].centroid.xy[0][0], AOI_A.geometry[0].centroid.xy[1][0], \n",
    "            '.', markerfacecolor=site_color, markeredgecolor='k', markersize=5)\n",
    "    ax[0].text(AOI_A.geometry[0].centroid.xy[0][0], AOI_A.geometry[0].centroid.xy[1][0],\n",
    "               text_labels[i], bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "    # Individual glacier plot\n",
    "    AOI_UTM.plot(ax=ax[i+1], edgecolor='k', facecolor='none', linewidth=2)\n",
    "    ls = LightSource(azdeg=315, altdeg=45) # shade from the northwest, with the sun 45 degrees from horizontal\n",
    "    x, y = DEM.x.data, DEM.y.data\n",
    "    dx, dy = x[1]-x[0], y[1]-y[0]\n",
    "    ax[i+1].imshow(ls.hillshade(DEM.elevation.data[0], vert_exag=1, dx=dx, dy=dy), cmap='Greys', extent=(x[0], x[-1], y[-1], y[0]))\n",
    "    DEM_im = ax[i+1].imshow(DEM.elevation.data[0], cmap=cmap_elev, clim=(500, 3500), alpha=0.8, extent=(x[0], x[-1], y[-1], y[0]))\n",
    "    if AOI.geometry[0].geom_type=='MultiPolygon':\n",
    "        xmin_AOI = np.min([np.min(geom.exterior.coords.xy[0]) for geom in AOI.geometry[0].geoms])\n",
    "        xmax_AOI = np.max([np.max(geom.exterior.coords.xy[0]) for geom in AOI.geometry[0].geoms])\n",
    "        ymin_AOI = np.min([np.min(geom.exterior.coords.xy[1]) for geom in AOI.geometry[0].geoms])\n",
    "        ymax_AOI = np.max([np.max(geom.exterior.coords.xy[1]) for geom in AOI.geometry[0].geoms])      \n",
    "    else:\n",
    "        xmin_AOI = np.min(AOI.geometry[0].exterior.coords.xy[0])\n",
    "        xmax_AOI = np.max(AOI.geometry[0].exterior.coords.xy[0])\n",
    "        ymin_AOI = np.min(AOI.geometry[0].exterior.coords.xy[1])\n",
    "        ymax_AOI = np.max(AOI.geometry[0].exterior.coords.xy[1])  \n",
    "    xmin = xmin_AOI - 0.1*(xmax_AOI - xmin_AOI)\n",
    "    xmax = xmax_AOI + 0.1*(xmax_AOI - xmin_AOI)\n",
    "    ymin = ymin_AOI - 0.1*(ymax_AOI - ymin_AOI)\n",
    "    ymax = ymax_AOI + 0.1*(ymax_AOI - ymin_AOI) \n",
    "    # change x and y tick labels to km\n",
    "    ax[i+1].set_xlim(xmin, xmax)\n",
    "    ax[i+1].set_ylim(ymin, ymax)\n",
    "    if i < 3:\n",
    "        ax[i+1].set_xticks(np.arange(np.round(xmin,-3), np.round(xmax,-3), 2e3))\n",
    "        ax[i+1].set_yticks(np.arange(np.round(ymin,-3), np.round(ymax,-3), 2e3)) \n",
    "    else:\n",
    "        ax[i+1].set_xticks(np.arange(np.round(xmin,-3), np.round(xmax,-3), 1e3))\n",
    "        ax[i+1].set_yticks(np.arange(np.round(ymin,-3), np.round(ymax,-3), 1e3)) \n",
    "    ax[i+1].set_xticklabels([str(int(x/1e3)) for x in ax[i+1].get_xticks()])\n",
    "    ax[i+1].set_yticklabels([str(int(y/1e3)) for y in ax[i+1].get_yticks()])\n",
    "    ax[i+1].set_title(text_label + ' ' + site_name_display + ' Glacier')\n",
    "    ax[i+1].grid()\n",
    "    # add axes labels\n",
    "    if (i==1) or (i==3):\n",
    "        ax[i].set_ylabel('Northing [km]')\n",
    "    if i > 1:\n",
    "        ax[i+1].set_xlabel('Easting [km]')\n",
    "    \n",
    "    # increase loop counter\n",
    "    i+=1\n",
    "\n",
    "# A: study sites map\n",
    "ax[0].set_xlim(-1100000, 1500000)\n",
    "ax[0].set_ylim(5000000, 7800000)\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "cx.add_basemap(ax[0], crs='EPSG:'+str(epsg_A), source=cx.providers.Esri.WorldGrayCanvas, attribution=False)\n",
    "fig.colorbar(DEM_im, ax=[ax[2], ax[5]], shrink=0.5, label='Elevation [m]')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    fig.savefig(out_path+'study_sites.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215bd39-59b9-4a53-be64-0c5db99554fc",
   "metadata": {},
   "source": [
    "## Study sites: RGI regions 1 and 2 (Alaska, the Western U.S. and Canada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d55f3-12d3-4b55-aef0-f04546239ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to RGI data\n",
    "RGI_path = '/Volumes/GoogleDrive/My Drive/Research/PhD/GIS_data/RGI/'\n",
    "# RGI shapefile names\n",
    "RGI_fns = ['01_rgi60_Alaska/01_rgi60_Alaska.shp', \n",
    "           '02_rgi60_WesternCanadaUS/02_rgi60_WesternCanadaUS.shp']\n",
    "\n",
    "# -----Load, format, filter, plot RGI glacier outlines\n",
    "# Create geopandas.DataFrame for storing RGIs\n",
    "RGI = gpd.GeoDataFrame()\n",
    "# Read RGI files\n",
    "for RGI_fn in RGI_fns:\n",
    "    file = gpd.read_file(RGI_path + RGI_fn)\n",
    "    RGI = pd.concat([RGI, file])\n",
    "# subset to glaciers with area > 5 km^2\n",
    "RGI_gt5 = RGI.loc[RGI['Area'] > 5].reset_index(drop=True)\n",
    "# change int data types to float for saving\n",
    "RGI_gt5[['Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect', 'Lmax', 'Status', 'Connect', \n",
    "         'Form', 'TermType', 'Surging', 'Linkages']] = RGI_gt5[['Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect', 'Lmax', \n",
    "                                                            'Status', 'Connect', 'Form', 'TermType', 'Surging', 'Linkages']].astype(float)\n",
    "\n",
    "# -----Grab list of all unique regions and subregions in dataset\n",
    "regions_subregions = sorted(RGI_gt5[['O1Region', 'O2Region']].drop_duplicates().values,\n",
    "                            key=operator.itemgetter(0, 1))\n",
    "subregions_names = ['Brooks Range', 'Alaska Range', 'Aleutians', 'W. Chugach Mtns.', 'St. Elias Mtns.', \n",
    "                    'N. Coast Ranges', 'N. Rockies', 'N. Cascades', 'S. Rockies', 'S. Cascades']\n",
    "subregions_colors = ['c', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', \n",
    "                     '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a']\n",
    "\n",
    "# -----Plot all sites with color distinguishing subregions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "crs = 'EPSG:9822' # Albers Equal Conic projection\n",
    "i=0\n",
    "for region, subregion in regions_subregions:\n",
    "    RGI_gt5_subregion = RGI_gt5.loc[(RGI_gt5['O1Region']==region) & (RGI_gt5['O2Region']==subregion)]\n",
    "    RGI_gt5_subregion_reproj = RGI_gt5_subregion.to_crs(crs)\n",
    "    for j in range(0, len(RGI_gt5_subregion)):\n",
    "        polygon = RGI_gt5_subregion_reproj.iloc[j]['geometry']\n",
    "        if j==0:\n",
    "            label=subregions_names[i]\n",
    "        else:\n",
    "            label='_nolegend_'\n",
    "        ax.plot(*polygon.exterior.xy, label=label, color=subregions_colors[i])\n",
    "    i+=1\n",
    "cx.add_basemap(ax, crs=crs, source=cx.providers.Esri.WorldShadedRelief, attribution=False)\n",
    "ax.legend(loc='center right', title='RGI Subregions', bbox_to_anchor=[1.25, 0.5, 0.2, 0.2])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.grid()\n",
    "plt.show()\n",
    "\n",
    "# -----Save figure\n",
    "fig.savefig(out_path + 'RGI_regions_1+2.png', dpi=300, facecolor='w')\n",
    "print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c3a2",
   "metadata": {},
   "source": [
    "## Methods workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00177f0c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "font_size = 24\n",
    "save_figures = 1\n",
    "\n",
    "# -----Image settings\n",
    "# site name\n",
    "site_name = 'SouthCascade'\n",
    "# define colors for classified image\n",
    "color_snow = '#4eb3d3'\n",
    "color_ice = '#084081'\n",
    "color_rock = '#fdbb84'\n",
    "color_water = '#bdbdbd'\n",
    "# create colormap\n",
    "colors = [color_snow, color_snow, color_ice, color_rock, color_water]\n",
    "cmp = ListedColormap(colors)\n",
    "\n",
    "# -----Load AOI as gpd.GeoDataFrame\n",
    "AOI_fn = base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp'\n",
    "AOI_fn = glob.glob(AOI_fn)[0]\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "# reproject the AOI to WGS to solve for the optimal UTM zone\n",
    "AOI_WGS = AOI.to_crs(4326)\n",
    "AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "    \n",
    "# -----Load DEM as Xarray DataSet\n",
    "DEM_fn = base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif'\n",
    "# reproject AOI to UTM\n",
    "AOI_UTM = AOI.to_crs(str(epsg_UTM))\n",
    "# load DEM as xarray DataSet\n",
    "DEM_fn = glob.glob(DEM_fn)[0]\n",
    "DEM = xr.open_dataset(DEM_fn)\n",
    "DEM = DEM.rename({'band_data': 'elevation'})\n",
    "# reproject the DEM to the optimal UTM zone\n",
    "DEM = DEM.rio.reproject(str('EPSG:'+epsg_UTM))\n",
    "\n",
    "# -----Load dataset dictionary\n",
    "with open(base_path + 'inputs-outputs/datasets_characteristics.pkl', 'rb') as fn:\n",
    "    dataset_dict = pickle.load(fn)\n",
    "dataset = 'PlanetScope'\n",
    "    \n",
    "# -----1. Raw image\n",
    "im_path = base_path + '../study-sites/' + site_name + '/imagery/PlanetScope/mosaics/'\n",
    "im_fn = '20210924_18.tif'\n",
    "im = rxr.open_rasterio(im_path + im_fn)\n",
    "im = im / im_scalar\n",
    "xmin, xmax, ymin, ymax = np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)\n",
    "# plot\n",
    "fig1, ax1 = plt.subplots(figsize=(8,8))\n",
    "ax1.imshow(np.dstack([im.data[2], im.data[1], im.data[0]]), \n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI.plot(ax=ax1, facecolor='none', edgecolor='k', linewidth=3)\n",
    "ax1.set_xlim(xmin, xmax)\n",
    "ax1.set_ylim(ymin, ymax)\n",
    "ax1.axis('off')\n",
    "\n",
    "# -----2. Adjusted image\n",
    "im_mosaic_fns = glob.glob(im_path+'*.tif')\n",
    "polygon_top, polygon_bottom, im_mosaic_fn, im_mosaic = f.create_AOI_elev_polys(AOI_UTM, im_path, im_mosaic_fns, DEM)\n",
    "plot_results = False\n",
    "skip_clipped = False\n",
    "im_adj, im_adj_method = f.PS_adjust_image_radiometry(im_fn, im_path, polygon_top, polygon_bottom,\n",
    "    AOI_UTM, dataset_dict, dataset, site_name, skip_clipped, plot_results)\n",
    "# plot\n",
    "fig2, ax2 = plt.subplots(figsize=(8,8))\n",
    "ax2.imshow(np.dstack([im_adj.red[0], im_adj.green[0], im_adj.blue[0]]), \n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI_UTM.plot(ax=ax2, facecolor='none', edgecolor='k', linewidth=3)\n",
    "ax2.set_xlim(xmin, xmax)\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "ax2.axis('off')\n",
    "\n",
    "# -----3. Classified image\n",
    "im_classified_path = base_path + '../study-sites/' + site_name + '/imagery/classified/'\n",
    "im_classified_fn = '20210924T180000_SouthCascade_PlanetScope_classified.nc'\n",
    "im_classified = xr.open_dataset(im_classified_path + im_classified_fn)\n",
    "im_classified = im_classified.where(im_classified!=-9999) # remove no data values\n",
    "# plot\n",
    "fig3, ax3 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "ax3.imshow(im_classified.classified[0].data, cmap=cmp, vmin=1, vmax=5,\n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI.plot(ax=ax3, facecolor='none', edgecolor='k', linewidth=3)\n",
    "# plot dummy points for legend\n",
    "ax3.scatter(0, 0, color=color_snow, s=50, label='Snow')\n",
    "ax3.scatter(0, 0, color=color_ice, s=50, label='Ice')\n",
    "ax3.scatter(0, 0, color=color_rock, s=50, label='Rock')\n",
    "ax3.scatter(0, 0, color=color_water, s=50, label='Water')\n",
    "ax3.set_xlim(xmin, xmax+300)\n",
    "ax3.set_ylim(ymin, ymax)\n",
    "ax3.legend(loc='upper right')\n",
    "ax3.axis('off')\n",
    "\n",
    "# -----4. Snow edges\n",
    "# create binary snow matrix\n",
    "im_binary = xr.where(im_classified.classified.data[0] <=2, 1, 0)\n",
    "# Find contours at a constant value of 0.5 (between 0 and 1)\n",
    "contours = find_contours(im_binary, 0.5)\n",
    "# convert contour points to image coordinates\n",
    "contours_coords = []\n",
    "for contour in contours: \n",
    "    ix = np.round(contour[:,1]).astype(int)\n",
    "    iy = np.round(contour[:,0]).astype(int)\n",
    "    coords = (im_adj.isel(x=ix, y=iy).x.data, # image x coordinates\n",
    "              im_adj.isel(x=ix, y=iy).y.data) # image y coordinates\n",
    "    # zip points together\n",
    "    xy = list(zip([x for x in coords[0]], \n",
    "                  [y for y in coords[1]]))\n",
    "    contours_coords = contours_coords + [xy]\n",
    "# plot\n",
    "fig4, ax4 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "binary_plt = ax4.imshow(im_binary, cmap='Greys')\n",
    "for i, contour in list(zip(np.arange(0,len(contours)), contours)):\n",
    "    if i==0:\n",
    "        plt.plot(contour[:,1], contour[:,0], '-m', label='Edges', linewidth=2)\n",
    "    else:\n",
    "        plt.plot(contour[:,1], contour[:,0], '-m', label='_nolegend', linewidth=2)\n",
    "# plot dummy points for legend\n",
    "ax4.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='k', s=100, label='Snow')\n",
    "ax4.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='w', s=100, label='No snow')\n",
    "ax4.set_xlim(0,len(im.x.data)+300)\n",
    "ax4.set_ylim(len(im.y.data), 0)\n",
    "ax4.legend(loc='upper right')\n",
    "ax4.axis('off')\n",
    "\n",
    "# -----5. Snow line\n",
    "snowlines_fn = base_path + '../study-sites/' + site_name + '/imagery/snowlines/20210924T180000_SouthCascade_PlanetScope_snowline.pkl'\n",
    "snowlines = pd.read_pickle(snowlines_fn)\n",
    "snowline = snowlines['snowlines_coords'][0]\n",
    "# plot\n",
    "fig5, ax5 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "binary_plt = ax5.imshow(im_binary, \n",
    "                        extent=(xmin, xmax, ymin, ymax),\n",
    "                        cmap='Greys')\n",
    "ax5.plot(*snowline.coords.xy, '.m', label='_nolegend', markersize=15)\n",
    "ax5.plot(-20, -20, '.m', label='Snowline', markersize=15)\n",
    "# plot dummy points for legend\n",
    "ax5.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='k', s=100, label='snow')\n",
    "ax5.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='w', s=100, label='no snow')\n",
    "ax5.set_xlim(xmin, xmax+300)\n",
    "ax5.set_ylim(ymin, ymax)\n",
    "ax5.legend(loc='upper right')\n",
    "ax5.axis('off')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    fig1.savefig(out_path+'methods_workflow_1.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    fig2.savefig(out_path+'methods_workflow_2.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    fig3.savefig(out_path+'methods_workflow_3.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    fig4.savefig(out_path+'methods_workflow_4.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    fig5.savefig(out_path+'methods_workflow_5.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    print('figures saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e224916",
   "metadata": {},
   "source": [
    "## Median snow line elevations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3bd100-7d3e-42ba-a6cc-0c48e967baf0",
   "metadata": {},
   "source": [
    "### One site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf63bb-73e1-437b-b3c8-7b9e98c16148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Settings and display parameters\n",
    "site_name = 'Gulkana' # as shown in folder name\n",
    "# site_name_display = 'Gulkana' # how to display on figure\n",
    "dataset_colors = {'Landsat': '#33a02c',\n",
    "                  'Sentinel2_TOA': '#1f78b4',\n",
    "                  'Sentinel2_SR': '#1f78b4',\n",
    "                  'PlanetScope': '#a6cee3'\n",
    "                 }\n",
    "\n",
    "# -----Path to USGS mass balance data\n",
    "usgs_path = '/Volumes/GoogleDrive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "    \n",
    "# -----Load estimated snow lines  \n",
    "sl_est_fns = glob.glob(base_path + '../study-sites/' + site_name + '/imagery/snowlines/*snowline.pkl')\n",
    "sl_ests = pd.DataFrame()\n",
    "for sl_est_fn in sl_est_fns:\n",
    "    sl_est = pd.read_pickle(sl_est_fn)\n",
    "    sl_ests = pd.concat([sl_ests, sl_est])\n",
    "sl_ests = sl_ests.reset_index(drop=True)\n",
    "sl_ests['datetime'] = sl_ests['datetime'].astype(np.datetime64)\n",
    "\n",
    "# -----Plot\n",
    "# Set up figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "plt.rcParams.update({'font.size':16, 'font.sans-serif':'Arial'})\n",
    "fmt_month = matplotlib.dates.MonthLocator(bymonth=(5, 11)) # minor ticks every month\n",
    "fmt_year = matplotlib.dates.YearLocator() # minor ticks every year\n",
    "# PlanetScope\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "           '.', markeredgecolor='w', markerfacecolor=dataset_colors['PlanetScope'], \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Sentinel-2 TOA\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel2_TOA'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Sentinel2_TOA'], \n",
    "           '*', markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2_TOA'], \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Sentinel-2 SR\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel2_SR'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Sentinel2_SR'], \n",
    "           '*', markeredgecolor=dataset_colors['Sentinel2_SR'], markerfacecolor='None', \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Landsat\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Landsat'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Landsat'], \n",
    "           '^', markeredgecolor='w', markerfacecolor=dataset_colors['Landsat'], \n",
    "           markersize=15, markeredgewidth=1, label='_nolegend_')                \n",
    "        \n",
    "# -----Dummy points for legend\n",
    "# observed\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, 'xk', \n",
    "           markersize=15, markeredgewidth=3, label='observed')\n",
    "# USGS\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "# Landsat\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '^', \n",
    "           markeredgecolor=dataset_colors['Landsat'], markerfacecolor=dataset_colors['Landsat'], \n",
    "           markersize=12, label='Landsat 8/9')\n",
    "# Sentinel-2 TOA\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2_TOA'], \n",
    "           markersize=18, label='Sentinel-2 TOA')\n",
    "# Sentinel-2 SR\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor=dataset_colors['Sentinel2_SR'], markerfacecolor='None', \n",
    "           markersize=18, label='Sentinel-2 SR')\n",
    "# PlanetScope\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '.', \n",
    "       markeredgecolor=dataset_colors['PlanetScope'], markerfacecolor=dataset_colors['PlanetScope'], \n",
    "       markersize=20, label='PlanetScope')\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.5, 1.05), ncol=6)\n",
    "\n",
    "# -----Observed snow lines\n",
    "# define path to digitized snow lines\n",
    "sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "# load AOI as gpd.GeoDataFrame\n",
    "AOI_fn = base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp'\n",
    "AOI_fn = glob.glob(AOI_fn)[0]\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "# load DEM from GEE\n",
    "DEM, AOI_UTM = pf.query_GEE_for_DEM(AOI)\n",
    "# loop through observed snow lines\n",
    "for j, sl_obs_fn in enumerate(sl_obs_fns):\n",
    "    # load observed snow line\n",
    "    sl_obs = gpd.read_file(sl_obs_fn)\n",
    "    # extract date from filename\n",
    "    date = sl_obs_fn.split('/'+site_name+'_')[1][0:8]\n",
    "    datetime = np.datetime64(date[0:4] + '-' + date[4:6] + '-' + date[6:8]\n",
    "                             + 'T00:00:00')\n",
    "    # reproject snow line to UTM\n",
    "    sl_obs_UTM = sl_obs.to_crs(str(AOI_UTM.crs.to_epsg()))\n",
    "    # interpolate elevation at snow line points\n",
    "    if len(sl_obs_UTM) > 1:\n",
    "        sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                            for x, y in list(zip(sl_obs_UTM.geometry[1].xy[0], \n",
    "                                                 sl_obs_UTM.geometry[1].xy[1]))])\n",
    "    else:\n",
    "        sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                            for x, y in list(zip(sl_obs_UTM.geometry[0].xy[0], \n",
    "                                                 sl_obs_UTM.geometry[0].xy[1]))])\n",
    "    # calculate median snow line elevation\n",
    "    sl_obs_elev_median = np.nanmedian(sl_obs_elev)\n",
    "    # plot\n",
    "    ax.plot(datetime, sl_obs_elev_median, 'xk', markersize=10, markeredgewidth=2, label='_nolegend_')   \n",
    "            \n",
    "    # load USGS ELA estimates\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype(np.datetime64)\n",
    "    ax.plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='_nolegend_')\n",
    "\n",
    "# -----Adjust axes\n",
    "# axis limits\n",
    "xmin, xmax = np.datetime64('2017-05-01T00:00:00'), np.datetime64('2023-01-01T00:00:00')\n",
    "sl_elev_median_min = np.min(sl_ests['snowlines_elevs_median'])\n",
    "sl_elev_median_max = np.max(sl_ests['snowlines_elevs_median'])\n",
    "ymin = sl_elev_median_min - 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "ymax = sl_elev_median_max + 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.grid()\n",
    "# x-labels\n",
    "ax.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "ax.xaxis.set_major_locator(fmt_month)\n",
    "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "sec_xaxis = ax.secondary_xaxis(-0.1)\n",
    "sec_xaxis.xaxis.set_major_locator(fmt_year)\n",
    "sec_xaxis.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "# Hide the second x-axis spines and ticks\n",
    "sec_xaxis.spines['bottom'].set_visible(False)\n",
    "sec_xaxis.tick_params(length=0, pad=10)\n",
    "# y-label\n",
    "ax.set_ylabel('Elevation [m]')\n",
    "plt.show()\n",
    "    \n",
    "# -----Save figure\n",
    "fig_fn = 'median_snowline_elevs_' + site_name + '.png'\n",
    "fig.savefig(out_path + fig_fn, facecolor='w', dpi=300)\n",
    "print('figure saved to file: '+out_path+fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895354ac-2809-4d9a-b6a2-67109ce26397",
   "metadata": {},
   "source": [
    "### Multiple sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161f1d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Settings and display parameters\n",
    "site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry']\n",
    "site_names_display = ['Wolverine',  'Gulkana', 'Lemon Creek', 'South Cascade', 'Sperry']\n",
    "dataset_colors = {'Landsat': '#33a02c',\n",
    "                  'Sentinel2': '#1f78b4',\n",
    "                  'PlanetScope': '#a6cee3'\n",
    "                 }\n",
    "text_labels = ['a)', 'b)', 'c)', 'd)', 'e)']\n",
    "\n",
    "# -----Path to USGS mass balance data\n",
    "usgs_path = '/Volumes/GoogleDrive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "\n",
    "# -----Set up figures\n",
    "# sall sites\n",
    "fig, ax = plt.subplots(5, 1, figsize=(20, 24))\n",
    "ax = ax.flatten()\n",
    "plt.rcParams.update({'font.size':20, 'font.sans-serif':'Arial'})\n",
    "fmt_month = matplotlib.dates.MonthLocator(bymonth=(5, 11)) # minor ticks every month\n",
    "fmt_year = matplotlib.dates.YearLocator() # minor ticks every year\n",
    "# South Cascade\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(20, 8))\n",
    "plt.rcParams.update({'font.size':20, 'font.sans-serif':'Arial'})\n",
    "fmt_month = matplotlib.dates.MonthLocator(bymonth=(5, 11)) # minor ticks every month\n",
    "fmt_year = matplotlib.dates.YearLocator() # minor ticks every year\n",
    "\n",
    "# -----Loop through sites\n",
    "for site_name, site_name_display, text_label, i in list(zip(site_names, site_names_display, text_labels, np.arange(0,len(site_names)))):\n",
    "    \n",
    "    print(site_name)\n",
    "    print('----------')\n",
    "    \n",
    "    # load estimated snow lines  \n",
    "    sl_est_path = glob.glob(base_path + '../study-sites/' + site_name + '/imagery/*snowlines.pkl')[0]\n",
    "    sl_est = pd.read_pickle(sl_est_path)\n",
    "    \n",
    "    # load snowlines linear model\n",
    "    sl_est_linear_mod_fn = glob.glob(base_path + '../study-sites/' + site_name + '/imagery/*snowlines_linear_model.pkl')[0]\n",
    "    sl_est_linear_mod = pd.read_pickle(sl_est_linear_mod_fn)\n",
    "    \n",
    "    # plot\n",
    "    # PlanetScope\n",
    "    ax[i].plot(sl_est['datetime'].loc[sl_est['dataset']=='PlanetScope'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='PlanetScope'], \n",
    "               '.', markeredgecolor='w', markerfacecolor=dataset_colors['PlanetScope'], \n",
    "               markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "        \n",
    "    # Sentinel-2\n",
    "    ax[i].plot(sl_est['datetime'].loc[sl_est['dataset']=='Sentinel2'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='Sentinel2'], \n",
    "               '*', markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2'], \n",
    "               markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "    # Landsat\n",
    "    ax[i].plot(sl_est['datetime'].loc[sl_est['dataset']=='Landsat'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='Landsat'], \n",
    "               '^', markeredgecolor='w', markerfacecolor=dataset_colors['Landsat'], \n",
    "               markersize=15, markeredgewidth=1, label='_nolegend_')\n",
    "    # linear trendlines\n",
    "    for j in np.arange(0,len(sl_est_linear_mod)):\n",
    "        ax[i].plot(sl_est_linear_mod.iloc[j]['X_mod'], sl_est_linear_mod.iloc[j]['y_mod_best'], \n",
    "                   '-k', linewidth=3)                  \n",
    "        \n",
    "    # axis limits\n",
    "    xmin, xmax = np.datetime64('2016-05-01T00:00:00'), np.datetime64('2022-12-01T00:00:00')\n",
    "    sl_elev_median_min = np.min(sl_est['snowlines_elevs_median'])\n",
    "    sl_elev_median_max = np.max(sl_est['snowlines_elevs_median'])\n",
    "    ymin = sl_elev_median_min - 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "    ymax = sl_elev_median_max + 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "    ax[i].set_xlim(xmin, xmax)\n",
    "    ax[i].set_ylim(ymin, ymax)\n",
    "    ax[i].grid()\n",
    "    # x-labels\n",
    "    ax[i].xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "    ax[i].xaxis.set_major_locator(fmt_month)\n",
    "    ax[i].xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "    sec_xaxis = ax[4].secondary_xaxis(-0.1)\n",
    "    sec_xaxis.xaxis.set_major_locator(fmt_year)\n",
    "    sec_xaxis.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "    # Hide the second x-axis spines and ticks\n",
    "    sec_xaxis.spines['bottom'].set_visible(False)\n",
    "    sec_xaxis.tick_params(length=0, pad=10)\n",
    "    if i<5:\n",
    "        ax[i].set_xticklabels([])\n",
    "        sec_xaxis.set_xticklabels([])\n",
    "    # y-label\n",
    "    ax[i].set_ylabel('Elevation [m]')\n",
    "    # text label\n",
    "    ax[i].text((xmax-xmin)*0.015 + xmin, (ymax-ymin)*0.87 + ymin, \n",
    "               text_label + ' ' + site_name_display, \n",
    "               bbox=dict(facecolor='white', edgecolor='black', pad=5))\n",
    "\n",
    "    # -----Observed snow lines\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    # load AOI as gpd.GeoDataFrame\n",
    "    AOI_fn = base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp'\n",
    "    AOI_fn = glob.glob(AOI_fn)[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    # load DEM from GEE\n",
    "    DEM, AOI_UTM = pf.query_GEE_for_DEM(AOI)\n",
    "    # loop through observed snow lines\n",
    "    for j, sl_obs_fn in enumerate(sl_obs_fns):\n",
    "        # load observed snow line\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:8]\n",
    "        datetime = np.datetime64(date[0:4] + '-' + date[4:6] + '-' + date[6:8]\n",
    "                                 + 'T00:00:00')\n",
    "        # reproject snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs(str(AOI_UTM.crs.to_epsg()))\n",
    "        # interpolate elevation at snow line points\n",
    "        if len(sl_obs_UTM) > 1:\n",
    "            sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                                for x, y in list(zip(sl_obs_UTM.geometry[1].xy[0], \n",
    "                                                     sl_obs_UTM.geometry[1].xy[1]))])\n",
    "        else:\n",
    "            sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                                for x, y in list(zip(sl_obs_UTM.geometry[0].xy[0], \n",
    "                                                     sl_obs_UTM.geometry[0].xy[1]))])\n",
    "        # calculate median snow line elevation\n",
    "        sl_obs_elev_median = np.nanmedian(sl_obs_elev)\n",
    "        # plot\n",
    "        ax[i].plot(datetime, sl_obs_elev_median, 'xk', markersize=10, markeredgewidth=2, label='_nolegend_')   \n",
    "            \n",
    "    # load USGS ELA estimates\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype(np.datetime64)\n",
    "    ax[i].plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='_nolegend_')\n",
    "        \n",
    "    # -----South Cascade figure\n",
    "    if site_name=='SouthCascade':\n",
    "        # PlanetScope\n",
    "        ax2.plot(sl_est['datetime'].loc[sl_est['dataset']=='PlanetScope'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='PlanetScope'], \n",
    "               '.', markeredgecolor='w', markerfacecolor=dataset_colors['PlanetScope'], \n",
    "               markersize=20, markeredgewidth=1, label='PlanetScope')\n",
    "        # Sentinel-2\n",
    "        ax2.plot(sl_est['datetime'].loc[sl_est['dataset']=='Sentinel2'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='Sentinel2'], \n",
    "               '*', markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2'], \n",
    "               markersize=20, markeredgewidth=1, label='Sentinel-2')\n",
    "        # Landsat\n",
    "        ax2.plot(sl_est['datetime'].loc[sl_est['dataset']=='Landsat'], \n",
    "               sl_est['snowlines_elevs_median'].loc[sl_est['dataset']=='Landsat'], \n",
    "               '^', markeredgecolor='w', markerfacecolor=dataset_colors['Landsat'], \n",
    "               markersize=15, markeredgewidth=1, label='Landsat 8/9')\n",
    "        # linear trendlines\n",
    "        for j in np.arange(0,len(sl_est_linear_mod)):\n",
    "            if j==0:\n",
    "                ax2.plot(sl_est_linear_mod.iloc[j]['X_mod'], sl_est_linear_mod.iloc[j]['y_mod_best'], \n",
    "                     '-k', linewidth=3, label='linear trendline') \n",
    "            else:\n",
    "                ax2.plot(sl_est_linear_mod.iloc[j]['X_mod'], sl_est_linear_mod.iloc[j]['y_mod_best'], \n",
    "                     '-k', linewidth=3, label='_nolegend_')\n",
    "        # USGS ELAs\n",
    "        ax2.plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "                   ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "        ax2.legend(loc='center', bbox_to_anchor=(0.5, 1.1), ncol=5)\n",
    "            \n",
    "# -----Dummy points for legend\n",
    "# observed\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, 'xk', \n",
    "           markersize=15, markeredgewidth=3, label='observed')\n",
    "# USGS\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "# Landsat\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '^', \n",
    "           markeredgecolor=dataset_colors['Landsat'], markerfacecolor=dataset_colors['Landsat'], \n",
    "           markersize=12, label='Landsat 8/9')\n",
    "# Sentinel-2\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor=dataset_colors['Sentinel2'], markerfacecolor=dataset_colors['Sentinel2'], \n",
    "           markersize=18, label='Sentinel-2')\n",
    "# PlanetScope\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '.', \n",
    "       markeredgecolor=dataset_colors['PlanetScope'], markerfacecolor=dataset_colors['PlanetScope'], \n",
    "       markersize=20, label='PlanetScope')\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(0.5, 1.15), ncol=5)\n",
    "\n",
    "# -----Date label formatting\n",
    "ax2.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "ax2.xaxis.set_major_locator(fmt_month)\n",
    "ax2.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "# create a second x-axis beneath the first x-axis to show the year in YYYY format\n",
    "sec_xaxis = ax2.secondary_xaxis(-0.05)\n",
    "sec_xaxis.xaxis.set_major_locator(fmt_year)\n",
    "sec_xaxis.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "# Hide the second x-axis spines and ticks\n",
    "sec_xaxis.spines['bottom'].set_visible(False)\n",
    "sec_xaxis.tick_params(length=0, pad=10)\n",
    "ax2.set_xlim(np.datetime64('2016-05-01T00:00:00'), np.datetime64('2022-12-01T00:00:00'))\n",
    "ax2.set_ylabel('Elevation [m]')\n",
    "ax2.grid()\n",
    "plt.show()\n",
    "    \n",
    "# -----Save figure\n",
    "# if save_figures:\n",
    "fig_fn = 'median_snowline_elevs.png'\n",
    "fig.savefig(out_path + fig_fn, facecolor='w', dpi=300)\n",
    "fig2_fn = 'median_snowline_elevs_SouthCascade.png'\n",
    "fig2.savefig(out_path + fig2_fn, facecolor='w', dpi=300)\n",
    "print('figures saved to file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607833a-3dbd-4102-be1e-0753029b842d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "col = plt.cm.viridis\n",
    "for i, site_name in enumerate(site_names):\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype(np.datetime64)\n",
    "    plt.plot(ELA_date, ELA, '.-', color=col((i+1)/len(site_names)), label=site_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdacd23-947f-426b-8cb0-6fc48d3c4dba",
   "metadata": {},
   "source": [
    "## Training data characteristics by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953ef42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load dataset dictionary\n",
    "with open(base_path + 'inputs-outputs/datasets_characteristics.pkl', 'rb') as fn:\n",
    "    dataset_dict = pickle.load(fn)\n",
    "\n",
    "# -----Define band ranges\n",
    "L8_dict = dataset_dict['Landsat']\n",
    "L8_dict['bands'] = {'SR_B2': {'name': 'blue',\n",
    "                              'min_nm': 450,\n",
    "                              'max_nm': 510},\n",
    "                    'SR_B3': {'name': 'green',\n",
    "                              'min_nm': 530,\n",
    "                              'max_nm': 590},\n",
    "                    'SR_B4': {'name': 'red',\n",
    "                              'min_nm': 640,\n",
    "                              'max_nm': 670},\n",
    "                    'SR_B5': {'name': 'NIR',\n",
    "                              'min_nm': 850,\n",
    "                              'max_nm': 880},\n",
    "                    'SR_B6': {'name': 'SWIR1',\n",
    "                              'min_nm': 1570,\n",
    "                              'max_nm': 1650},\n",
    "                    'SR_B7': {'name': 'SWIR2',\n",
    "                              'min_nm': 2110,\n",
    "                              'max_nm': 2290}\n",
    "                   }\n",
    "\n",
    "S2_dict = dataset_dict['Sentinel-2']\n",
    "S2_dict['bands'] = {'B2': {'name': 'blue',\n",
    "                           'wavelength_min_nm': 459,\n",
    "                           'wavelength_max_nm': 525\n",
    "                          },\n",
    "                    'B3': {'name': 'green',\n",
    "                           'wavelength_min_nm': 541,\n",
    "                           'wavelength_max_nm': 577\n",
    "                          },\n",
    "                    'B4': {'name': 'red',\n",
    "                           'wavelength_min_nm': 649,\n",
    "                           'wavelength_max_nm': 680\n",
    "                          },\n",
    "                    'B8': {'name': 'NIR',\n",
    "                           'wavelength_min_nm': 780,\n",
    "                           'wavelength_max_nm': 886\n",
    "                          },\n",
    "                    'B11': {'name': 'SWIR1',\n",
    "                           'wavelength_min_nm': 1567,\n",
    "                           'wavelength_max_nm': 1658\n",
    "                            \n",
    "                          },\n",
    "                    'B12': {'name': 'SWIR2',\n",
    "                           'wavelength_min_nm': 2114,\n",
    "                           'wavelength_max_nm': 2289\n",
    "                          }\n",
    "                   }\n",
    "PS_dict = dataset_dict['PlanetScope']\n",
    "PS_dict['bands'] = {'B1': {'name': 'blue',\n",
    "                           'wavelength_min_nm':,\n",
    "                           'wavelength_max_nm': \n",
    "                          }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98d5327-415c-4cfe-9c01-5da91f30511b",
   "metadata": {},
   "source": [
    "## Example ideal and difficult conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3a99c-7090-4432-927d-6f149fb0bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Set up figure\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "plt.rcParams.update({'font.size':28, 'font.sans-serif':'Arial'})\n",
    "ax = ax.flatten()\n",
    "\n",
    "# -----Ideal conditions\n",
    "## PlanetScope - Wolverine - 20210815\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Wolverine/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20210815*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Wolverine/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20210815T200000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[0].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[0].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[0].text(ax[0].get_xlim()[0] + 0.85*(ax[0].get_xlim()[1] - ax[0].get_xlim()[0]), \n",
    "           ax[0].get_ylim()[0] + 0.05*(ax[0].get_ylim()[1] - ax[0].get_ylim()[0]),\n",
    "           'a)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[0].set_title('Ideal conditions')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "## PlanetScope - Lemon Creek - 20220821\n",
    "# image\n",
    "im_path = base_path + '../study-sites/LemonCreek/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20220821*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/LemonCreek/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20220821T190000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[2].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[2].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[2].text(ax[2].get_xlim()[0] + 0.8*(ax[2].get_xlim()[1] - ax[2].get_xlim()[0]), \n",
    "           ax[2].get_ylim()[0] + 0.05*(ax[2].get_ylim()[1] - ax[2].get_ylim()[0]),\n",
    "           'c)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])\n",
    "\n",
    "# -----Difficult conditions\n",
    "## PlanetScope - Sperry - 20160816\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Sperry/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20160816*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Sperry/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20160816T170000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[1].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[1].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[1].text(ax[1].get_xlim()[0] + 0.85*(ax[1].get_xlim()[1] - ax[1].get_xlim()[0]), \n",
    "           ax[1].get_ylim()[0] + 0.05*(ax[1].get_ylim()[1] - ax[1].get_ylim()[0]),\n",
    "           'b)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[1].set_title('Difficult conditions')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "\n",
    "## PlanetScope - Gulkana - 20170629\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Gulkana/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20170629*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Gulkana/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20170629T200000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[3].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[3].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[3].text(ax[3].get_xlim()[0] + 0.9*(ax[3].get_xlim()[1] - ax[3].get_xlim()[0]), \n",
    "           ax[3].get_ylim()[0] + 0.08*(ax[3].get_ylim()[1] - ax[3].get_ylim()[0]),\n",
    "           'd)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[3].set_xticks([])\n",
    "ax[3].set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----Save figure\n",
    "fig_fn = 'example_ideal+difficult_conditions.png'\n",
    "fig.savefig(out_path + fig_fn, dpi=300, facecolor='w')\n",
    "print('figure saved to file: '+ out_path + fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9dd185-34f0-4a5b-95fe-5af721b5dbc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
