{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff1eb620",
   "metadata": {},
   "source": [
    "# Notebook to make figures for conferences and manuscripts\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "2022/2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e9e15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import contextily as cx\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from skimage.measure import find_contours\n",
    "import ee\n",
    "import sys\n",
    "from shapely.geometry import Point, LineString\n",
    "import rasterio as rio\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap, LightSource\n",
    "import matplotlib\n",
    "import glob\n",
    "import wxee as wx\n",
    "import matplotlib\n",
    "import pickle\n",
    "from scipy.signal import medfilt\n",
    "import os\n",
    "import glob\n",
    "import operator\n",
    "import json\n",
    "from ast import literal_eval\n",
    "\n",
    "# path to snow-cover-mapping/\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "\n",
    "# path to study-sites/\n",
    "study_sites_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/snow_cover_mapping/study-sites/'\n",
    "\n",
    "# determine whether to save output figures\n",
    "save_figures = True\n",
    "\n",
    "# path for saving output figures\n",
    "out_path = base_path+'figures/'\n",
    "\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f\n",
    "\n",
    "# load dataset dictionary\n",
    "dataset_dict = json.load(open(base_path + 'inputs-outputs/datasets_characteristics.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4579e3a-9da2-4e1a-a7b4-da00e6a7cb0a",
   "metadata": {},
   "source": [
    "### Define some colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc8b362-d077-481f-b2eb-edb6bca4a8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Imagery Datasets\n",
    "color_Landsat = '#ff7f00'\n",
    "color_Sentinel2 = '#984ea3'\n",
    "color_PlanetScope = '#4daf4a'\n",
    "\n",
    "ListedColormap([color_Landsat, color_Sentinel2, color_PlanetScope])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c7849-b09b-4c83-9477-2af67f9ac92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Classified images\n",
    "# Indicies: 0 = snow, 1 = shadowed snow, 2 = ice, 3 = bare ground, 4 = water\n",
    "colors_classified = list(dataset_dict['classified_image']['class_colors'].values())\n",
    "ListedColormap(colors_classified)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013784a0-a641-4ae4-b9e7-24d20d8afe1f",
   "metadata": {},
   "source": [
    "## Figure 1. Spectral signatures for earth materials and satellite band ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9d1ed4-cb10-4ba7-9620-8ebc4a38b268",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# -----Set up figure\n",
    "# define colors for different materials\n",
    "color_snow = colors_classified[0]\n",
    "# color_ice = colors_classified[2]\n",
    "color_veg = '#006d2c'\n",
    "color_rock = colors_classified[3]\n",
    "color_water = colors_classified[4]\n",
    "colors = [color_snow, color_veg, color_rock, color_water]\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,6))\n",
    "plt.rcParams.update({'font.size':13})\n",
    "plt.xlabel('Wavelength [$\\mu$m]')\n",
    "plt.ylabel('Reflectance')\n",
    "    \n",
    "# -----Plot satellite band ranges\n",
    "def draw_boxes(ax, band_ranges, NDSI_indices, y0=0.2, box_height=0.04, \n",
    "               facecolor='#bdbdbd', edgecolor='k', alpha=1.0, NDSI_label=False):\n",
    "    labeled = False\n",
    "    # loop over band ranges\n",
    "    for i, band_range in enumerate(band_ranges):\n",
    "        # convert from nanometers to micrometers\n",
    "        x0, x1 = band_range[0], band_range[1]\n",
    "        # calculate width\n",
    "        box_width = x1-x0\n",
    "        # create rectangle and add to axes\n",
    "        ax.add_patch(Rectangle((x0, y0), width=box_width, height=box_height, \n",
    "                               facecolor=facecolor, edgecolor=edgecolor, alpha=alpha))\n",
    "        # plot star on NDSI bands\n",
    "        if i in NDSI_indices:\n",
    "            if (not labeled) and NDSI_label:\n",
    "                label = 'NDSI bands'\n",
    "                labeled = True\n",
    "            else:\n",
    "                label='_nolegend_'\n",
    "            ax.plot(x0 + box_width/2, y0 + box_height/2, '*k', markersize=10, label=label)\n",
    "\n",
    "    # add one rectangle to contain all bands\n",
    "    x0, x1 = band_ranges[0][0], band_ranges[-1][-1]\n",
    "    box_width = x1-x0\n",
    "    ax.add_patch(Rectangle((x0, y0), width=box_width, height=box_height, facecolor='none', edgecolor='k', alpha=1.0))\n",
    "    \n",
    "    return\n",
    "\n",
    "# -----Add satellite band ranges\n",
    "# Landsat 8/9 OLI\n",
    "L_band_ranges = [[0.45, 0.51], [0.53, 0.59], [0.64, 0.67], [0.85, 0.88], # 2, 3, 4, 5\n",
    "                 [1.57, 1.65], [2.11, 2.29]] # 6, 7\n",
    "L_band_names = ['Blue', 'Green', 'Red', 'NIR', 'SWIR1', 'SWIR2']#, 'TIRS1', 'TIRS2']\n",
    "L_NDSI_band_indices = [1, 4]\n",
    "draw_boxes(ax, L_band_ranges, L_NDSI_band_indices, y0=0.71, NDSI_label=True, facecolor=color_Landsat)\n",
    "ax.text(2.32, 0.715, 'Landsat 8/9')\n",
    "# Sentinel-2 MSI\n",
    "S2_20_band_ranges = [[0.69, 0.718], [0.727, 0.755], [0.764, 0.802], # B5, B6, B7\n",
    "                     [0.845, 0.85], [1.52, 1.70], [2.010, 2.37]] # B8A, B11 (SWIR1), B12 (SWIR2)\n",
    "S2_20_NDSI_band_indices = [4]\n",
    "draw_boxes(ax, S2_20_band_ranges, S2_20_NDSI_band_indices, y0=0.81, facecolor=color_Sentinel2)\n",
    "ax.text(2.4, 0.815, 'Sentinel-2 (20m)')\n",
    "\n",
    "S2_10_band_ranges = [[0.425, 0.555], [0.525, 0.595], [0.635, 0.695], # B2 B3 B4 \n",
    "                     [0.728, 1.038]] # B8 (NIR)\n",
    "S2_10_NDSI_band_indices = [1]\n",
    "draw_boxes(ax, S2_10_band_ranges, S2_10_NDSI_band_indices, y0=0.91, facecolor=color_Sentinel2)\n",
    "ax.text(1.068, 0.915, 'Sentinel-2 (10m)')\n",
    "\n",
    "# PlanetScope 4-band\n",
    "PS_band_ranges = [[0.455, 0.515], [0.51, 0.59], [0.590, 0.670], [0.780, 0.860]]\n",
    "PS_NDSI_indices = [1, 3]\n",
    "draw_boxes(ax, PS_band_ranges, PS_NDSI_indices, y0=1.01, facecolor=color_PlanetScope)\n",
    "ax.text(0.90, 1.015, 'PlanetScope 4-band')\n",
    "\n",
    "# -----Load spectral signatures data and plot\n",
    "spec_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/write-ups/snow_cover_mapping_methods_manuscript/figures/USGS_spectral_signatures/'\n",
    "os.chdir(spec_path)\n",
    "# define prefixes used in file names for each material\n",
    "prefixes = ['Melting_snow', 'Aspen', 'Basalt', 'Seawater']\n",
    "# define labels for plot\n",
    "labels = ['melting snow', 'vegetation', 'soil', 'seawater']\n",
    "# loop through prefixes\n",
    "for i, prefix in enumerate(prefixes):\n",
    "    # grab folder name\n",
    "    folder = glob.glob('*'+prefix+'*')[0]\n",
    "    # load wavelengths\n",
    "    wave_fn = glob.glob(folder + '/*Wavelengths*.txt')[0]\n",
    "    wave = pd.read_csv(wave_fn)\n",
    "    wave = wave[wave.keys()[0]].values\n",
    "    if prefix=='Basalt':\n",
    "        refl_fn = glob.glob(folder + '/*'+prefix+'*.txt')[1]\n",
    "    else:\n",
    "        refl_fn = glob.glob(folder + '/*'+prefix+'*.txt')[0]\n",
    "    refl = pd.read_csv(refl_fn)\n",
    "    refl = refl[refl.keys()[0]].values\n",
    "    refl[refl<0] = np.nan\n",
    "    # plot\n",
    "    ax.plot(wave, refl, '-', color=colors[i], linewidth=3, label=labels[i])\n",
    "    \n",
    "ax.grid()\n",
    "ax.set_xlim(0, 3.3)\n",
    "ax.set_ylim(0, 1.1)\n",
    "ax.legend(loc='center right', bbox_to_anchor=[0.8, 0.3, 0.2, 0.2])\n",
    "plt.show()\n",
    "\n",
    "# -----Save figure to file\n",
    "fig.tight_layout()\n",
    "fig_fn = 'spectral_signatures_satellite_bands.png'\n",
    "fig.savefig(out_path + fig_fn, facecolor='w', dpi=300)\n",
    "print('figure saved to file: '+out_path+fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593f951a",
   "metadata": {},
   "source": [
    "## Figure 2. Study sites - USGS Benchmark Glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85cc8c5b-b16b-4abf-8cf4-307a8b589a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load RGI data\n",
    "# path to RGI data\n",
    "rgi_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/GIS_data/RGI/'\n",
    "# RGI shapefile names\n",
    "rgi_fns = ['01_rgi60_Alaska/01_rgi60_Alaska.shp', \n",
    "           '02_rgi60_WesternCanadaUS/02_rgi60_WesternCanadaUS.shp']\n",
    "# load and combine rgis\n",
    "rgis = gpd.GeoDataFrame()\n",
    "for rgi_fn in rgi_fns:\n",
    "    rgi = gpd.read_file(rgi_path + rgi_fn)\n",
    "    rgis = pd.concat([rgis, rgi])\n",
    "rgis.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302aee73-a407-4cc7-9665-4f24cb931f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Count number of glaciers with areas < 1000 km^2 (for manuscript)\n",
    "print('Total # of glaciers in RGI regions 1 and 2 = ', len(rgis))\n",
    "print('Number of glaciers with areas < 1 km^2 = ', len(rgis.loc[rgis['Area'] < 1]))\n",
    "print('Percentage of glaciers with areas < 1 km^2 = ', len(rgis.loc[rgis['Area'] < 1]) / len(rgis))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a209a3d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Define site specifics\n",
    "site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry']\n",
    "site_names_display = ['Wolverine', 'Gulkana', 'Lemon Creek', 'South Cascade', 'Sperry']\n",
    "site_colors = ['#1f78b4', '#33a02c', '#fec44f', '#cc4c02', '#984ea3']\n",
    "text_labels = ['a)', 'b)', 'c)', 'd)', 'e)']\n",
    "\n",
    "# -----Define colormap for elevations\n",
    "cmap_elev = plt.cm.terrain(np.linspace(0, 1, 100))\n",
    "cmap_elev = ListedColormap(cmap_elev[25:, :])\n",
    "\n",
    "# ----Function for formatting contour labels\n",
    "def fmt(x):\n",
    "    s = f\"{x:.1f}\"\n",
    "    if s.endswith(\"0\"):\n",
    "        s = f\"{x:.0f}\"\n",
    "    return rf\"{s} m\" if plt.rcParams[\"text.usetex\"] else f\"{s} m\"\n",
    "\n",
    "# -----Set up figure\n",
    "fig, ax = plt.subplots(2, 3, figsize=(16, 12), layout='constrained')\n",
    "plt.rcParams.update({'font.size':18, 'font.sans-serif':'Arial'})\n",
    "ax = ax.flatten()\n",
    "epsg_A = 32610\n",
    "\n",
    "# -----Loop through sites\n",
    "i=0\n",
    "for site_name, site_color, site_name_display, text_label in list(zip(site_names, site_colors, site_names_display, text_labels)):\n",
    "    ### AOI\n",
    "    # load file\n",
    "    AOI_fn = glob.glob(study_sites_path + site_name + '/AOIs/' + site_name + '_USGS_*.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs(4326)\n",
    "    # solve for optimal UTM zone\n",
    "    AOI_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    epsg_UTM = f.convert_wgs_to_utm(AOI_centroid[0], AOI_centroid[1])\n",
    "    # reproject\n",
    "    AOI_UTM = AOI_WGS.to_crs(epsg_UTM)\n",
    "    AOI_A = AOI.to_crs(epsg_A)\n",
    "    ### DEM\n",
    "    # DEM_fn = glob.glob(study_sites_path + site_name + '/DEMs/' + site_name + '*_clip.tif')[0]\n",
    "    # DEM = xr.open_dataset(DEM_fn)\n",
    "    # DEM = DEM.rename({'band_data': 'elevation'})\n",
    "    # # reproject \n",
    "    # DEM = DEM.rio.reproject(str('EPSG:'+epsg_UTM))\n",
    "    # create meshgrid of coordinates\n",
    "    X_mesh, Y_mesh = np.meshgrid(DEM.x.data, DEM.y.data)\n",
    "    ### Plot\n",
    "    # A) Study sites map\n",
    "    ax[0].plot(AOI_A.geometry[0].centroid.xy[0][0], AOI_A.geometry[0].centroid.xy[1][0], \n",
    "            '.', markerfacecolor=site_color, markeredgecolor='k', markersize=5)\n",
    "    ax[0].text(AOI_A.geometry[0].centroid.xy[0][0], AOI_A.geometry[0].centroid.xy[1][0],\n",
    "               text_labels[i], bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "    # Individual glacier plot\n",
    "    AOI_UTM.plot(ax=ax[i+1], edgecolor='k', facecolor='none', linewidth=2)\n",
    "    # CS = ax[i+1].contour(X_mesh, Y_mesh, DEM.elevation.data[0], levels=4, colors='grey')\n",
    "    # ax[i+1].clabel(CS, CS.levels, inline=True, fmt=fmt, fontsize=10, colors='grey')\n",
    "    if AOI.geometry[0].geom_type=='MultiPolygon':\n",
    "        xmin_AOI = np.min([np.min(geom.exterior.coords.xy[0]) for geom in AOI.geometry[0].geoms])\n",
    "        xmax_AOI = np.max([np.max(geom.exterior.coords.xy[0]) for geom in AOI.geometry[0].geoms])\n",
    "        ymin_AOI = np.min([np.min(geom.exterior.coords.xy[1]) for geom in AOI.geometry[0].geoms])\n",
    "        ymax_AOI = np.max([np.max(geom.exterior.coords.xy[1]) for geom in AOI.geometry[0].geoms])      \n",
    "    else:\n",
    "        xmin_AOI = np.min(AOI.geometry[0].exterior.coords.xy[0])\n",
    "        xmax_AOI = np.max(AOI.geometry[0].exterior.coords.xy[0])\n",
    "        ymin_AOI = np.min(AOI.geometry[0].exterior.coords.xy[1])\n",
    "        ymax_AOI = np.max(AOI.geometry[0].exterior.coords.xy[1])  \n",
    "    xmin = xmin_AOI - 0.1*(xmax_AOI - xmin_AOI)\n",
    "    xmax = xmax_AOI + 0.1*(xmax_AOI - xmin_AOI)\n",
    "    ymin = ymin_AOI - 0.1*(ymax_AOI - ymin_AOI)\n",
    "    ymax = ymax_AOI + 0.1*(ymax_AOI - ymin_AOI) \n",
    "    # change x and y tick labels to km\n",
    "    ax[i+1].set_xlim(xmin, xmax)\n",
    "    ax[i+1].set_ylim(ymin, ymax)\n",
    "    if i < 3:\n",
    "        ax[i+1].set_xticks(np.arange(np.round(xmin,-3), np.round(xmax,-3), 2e3))\n",
    "        ax[i+1].set_yticks(np.arange(np.round(ymin,-3), np.round(ymax,-3), 2e3)) \n",
    "    else:\n",
    "        ax[i+1].set_xticks(np.arange(np.round(xmin,-3), np.round(xmax,-3), 1e3))\n",
    "        ax[i+1].set_yticks(np.arange(np.round(ymin,-3), np.round(ymax,-3), 1e3)) \n",
    "    ax[i+1].set_xticklabels([str(int(x/1e3)) for x in ax[i+1].get_xticks()])\n",
    "    ax[i+1].set_yticklabels([str(int(y/1e3)) for y in ax[i+1].get_yticks()])\n",
    "    ax[i+1].set_title(text_label + ' ' + site_name_display + ' Glacier')\n",
    "    ax[i+1].grid()\n",
    "    # add axes labels\n",
    "    if (i==1) or (i==3):\n",
    "        ax[i].set_ylabel('Northing [km]')\n",
    "    if i > 1:\n",
    "        ax[i+1].set_xlabel('Easting [km]')\n",
    "    cx.add_basemap(ax[i+1], crs='EPSG:'+str(epsg_UTM), source=cx.providers.Esri.WorldImagery, attribution=False)\n",
    "\n",
    "    # increase loop counter\n",
    "    i+=1\n",
    "\n",
    "# A: study sites map\n",
    "ax[0].set_xlim(-2000000, 1500000)\n",
    "ax[0].set_ylim(5000000, 7800000)\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "cx.add_basemap(ax[0], crs='EPSG:'+str(epsg_A), source=cx.providers.Esri.WorldGrayCanvas, attribution=False)\n",
    "rgis_reproj = rgis.to_crs('EPSG:'+str(epsg_A))\n",
    "rgis_reproj.plot(ax=ax[0], facecolor=colors_classified[2], edgecolor=colors_classified[2])\n",
    "# fig.colorbar(DEM_im, ax=[ax[2], ax[5]], shrink=0.5, label='Elevation [m]')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    fig.savefig(out_path+'study_sites.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "    print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29c3a2",
   "metadata": {},
   "source": [
    "## Figure 3. Methods workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00177f0c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "font_size = 32\n",
    "save_figures = 1\n",
    "\n",
    "# -----Load dataset dictionary\n",
    "with open(base_path + 'inputs-outputs/datasets_characteristics.json') as fn:\n",
    "    dataset_dict = json.load(fn)\n",
    "dataset = 'PlanetScope'\n",
    "\n",
    "# -----Image settings\n",
    "# site name\n",
    "site_name = 'SouthCascade'\n",
    "# create colormap for classified image\n",
    "cmp = ListedColormap(colors_classified)\n",
    "\n",
    "# -----Load AOI as gpd.GeoDataFrame\n",
    "AOI_fn = study_sites_path + site_name + '/AOIs/' + site_name + '_USGS_*.shp'\n",
    "AOI_fn = glob.glob(AOI_fn)[0]\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "# reproject the AOI to WGS to solve for the optimal UTM zone\n",
    "AOI_WGS = AOI.to_crs(4326)\n",
    "AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "# reproject AOI to UTM\n",
    "AOI_UTM = AOI.to_crs(str(epsg_UTM))\n",
    "\n",
    "# -----Load DEM as Xarray DataSet\n",
    "DEM_fn = study_sites_path + site_name + '/DEMs/' + site_name + '*_DEM*.tif'\n",
    "# load DEM as xarray DataSet\n",
    "DEM_fn = glob.glob(DEM_fn)[0]\n",
    "DEM = xr.open_dataset(DEM_fn)\n",
    "DEM = DEM.rename({'band_data': 'elevation'})\n",
    "# reproject the DEM to the optimal UTM zone\n",
    "DEM = DEM.rio.reproject(str('EPSG:'+epsg_UTM))\n",
    "# remove unnecessary data (possible extra bands from ArcticDEM or other DEM)\n",
    "if len(np.shape(DEM.elevation.data))>2:\n",
    "    DEM['elevation'] = DEM.elevation[0]\n",
    "    \n",
    "# -----1. Raw image\n",
    "im_path = study_sites_path + site_name + '/imagery/PlanetScope/mosaics/'\n",
    "im_fn = '20210924_18.tif'\n",
    "im = xr.open_dataset(im_path + im_fn)\n",
    "# determine image date from image mosaic file name\n",
    "im_date = im_fn[0:4] + '-' + im_fn[4:6] + '-' + im_fn[6:8] + 'T' + im_fn[9:11] + ':00:00'\n",
    "im_dt = np.datetime64(im_date)\n",
    "xmin, xmax, ymin, ymax = np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)\n",
    "# plot\n",
    "fig1, ax1 = plt.subplots(figsize=(8,8))\n",
    "ax1.imshow(np.dstack([im.band_data.data[2]/1e4, im.band_data.data[1]/1e4, im.band_data.data[0]/1e4]), \n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI.plot(ax=ax1, facecolor='none', edgecolor='k', linewidth=3)\n",
    "ax1.set_xlim(xmin, xmax)\n",
    "ax1.set_ylim(ymin, ymax)\n",
    "ax1.axis('off')\n",
    "\n",
    "# -----2. Adjusted image\n",
    "polygon_top, polygon_bottom = f.create_aoi_elev_polys(AOI_UTM, DEM)\n",
    "im_adj, im_adj_method = f.planetscope_adjust_image_radiometry(im, im_dt, polygon_top, polygon_bottom, dataset_dict, skip_clipped=False)\n",
    "# plot\n",
    "fig2, ax2 = plt.subplots(figsize=(8,8))\n",
    "ax2.imshow(np.dstack([im_adj.Red.data[0], im_adj.Green.data[0], im_adj.Blue.data[0]]), \n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI_UTM.plot(ax=ax2, facecolor='none', edgecolor='k', linewidth=3)\n",
    "ax2.set_xlim(xmin, xmax)\n",
    "ax2.set_ylim(ymin, ymax)\n",
    "ax2.axis('off')\n",
    "\n",
    "# -----3. Classified image\n",
    "im_classified_path = study_sites_path + site_name + '/imagery/classified/'\n",
    "im_classified_fn = '20210924T180000_SouthCascade_PlanetScope_classified.nc'\n",
    "im_classified = xr.open_dataset(im_classified_path + im_classified_fn)\n",
    "# remove no data values\n",
    "im_classified = xr.where(im_classified==-9999, np.nan, im_classified)\n",
    "# plot\n",
    "fig3, ax3 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "ax3.imshow(im_classified.classified.data[0], cmap=cmp, vmin=1, vmax=5,\n",
    "           extent=(xmin, xmax, ymin, ymax))\n",
    "AOI.plot(ax=ax3, facecolor='none', edgecolor='k', linewidth=3)\n",
    "# plot dummy points for legend\n",
    "ax3.scatter(0, 0, marker='s', color=colors_classified[0], s=300, label='snow')\n",
    "ax3.scatter(0, 0, marker='s', color=colors_classified[1], s=300, label='shadowed snow')\n",
    "ax3.scatter(0, 0, marker='s', color=colors_classified[2], s=300, label='ice')\n",
    "ax3.scatter(0, 0, marker='s', color=colors_classified[3], s=300, label='rock')\n",
    "ax3.scatter(0, 0, marker='s', color=colors_classified[4], s=300, label='water')\n",
    "ax3.set_xlim(xmin, xmax+300)\n",
    "ax3.set_ylim(ymin, ymax)\n",
    "ax3.legend(loc='center right', bbox_to_anchor=[1.3, 0.7, 0.2, 0.2])\n",
    "ax3.axis('off')\n",
    "\n",
    "# -----4. Snow edges\n",
    "# create binary snow matrix\n",
    "im_binary = xr.where(im_classified.classified.data[0] <=2, 1, 0)\n",
    "# Find contours at a constant value of 0.5 (between 0 and 1)\n",
    "contours = find_contours(im_binary, 0.5)\n",
    "# convert contour points to image coordinates\n",
    "contours_coords = []\n",
    "for contour in contours: \n",
    "    ix = np.round(contour[:,1]).astype(int)\n",
    "    iy = np.round(contour[:,0]).astype(int)\n",
    "    coords = (im_adj.isel(x=ix, y=iy).x.data, # image x coordinates\n",
    "              im_adj.isel(x=ix, y=iy).y.data) # image y coordinates\n",
    "    # zip points together\n",
    "    xy = list(zip([x for x in coords[0]], \n",
    "                  [y for y in coords[1]]))\n",
    "    contours_coords = contours_coords + [xy]\n",
    "# plot\n",
    "fig4, ax4 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "binary_plt = ax4.imshow(im_binary, cmap='Greys')\n",
    "for i, contour in list(zip(np.arange(0,len(contours)), contours)):\n",
    "    if i==0:\n",
    "        plt.plot(contour[:,1], contour[:,0], '-m', label='edges', linewidth=2)\n",
    "    else:\n",
    "        plt.plot(contour[:,1], contour[:,0], '-m', label='_nolegend', linewidth=2)\n",
    "# plot dummy points for legend\n",
    "ax4.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='k', s=100, label='snow')\n",
    "ax4.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='w', s=100, label='no snow')\n",
    "ax4.set_xlim(0,len(im.x.data)+300)\n",
    "ax4.set_ylim(len(im.y.data), 0)\n",
    "ax4.legend(loc='upper right', bbox_to_anchor=[0.9, 0.8, 0.2, 0.2])\n",
    "ax4.axis('off')\n",
    "\n",
    "# -----5. Snow line\n",
    "snowlines_fn = study_sites_path + site_name + '/imagery/snowlines/20210924T180000_SouthCascade_PlanetScope_snowline.csv'\n",
    "snowlines = pd.read_csv(snowlines_fn)\n",
    "snowlines_X = snowlines.snowlines_coords_X.apply(literal_eval)[0]\n",
    "snowlines_Y = snowlines.snowlines_coords_Y.apply(literal_eval)[0]\n",
    "\n",
    "# plot\n",
    "fig5, ax5 = plt.subplots(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':font_size, 'font.sans-serif':'Arial'})\n",
    "binary_plt = ax5.imshow(im_binary, \n",
    "                        extent=(xmin, xmax, ymin, ymax),\n",
    "                        cmap='Greys')\n",
    "ax5.plot(snowlines_X, snowlines_Y, '.c', label='_nolegend', markersize=10)\n",
    "ax5.plot(-20, -20, 'c', label='snowline', linewidth=5)\n",
    "# plot dummy points for legend\n",
    "ax5.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='k', s=100, label='snow')\n",
    "ax5.scatter(np.array([-10, -9]),np.array([-10, -9]), edgecolor='k', facecolor='w', s=100, label='no snow')\n",
    "ax5.set_xlim(xmin, xmax+300)\n",
    "ax5.set_ylim(ymin, ymax)\n",
    "ax5.legend(loc='center right', bbox_to_anchor=[1.0, 0.6, 0.2, 0.2])\n",
    "ax5.axis('off')\n",
    "plt.show()\n",
    "\n",
    "if save_figures:\n",
    "    fig1.savefig(out_path+'methods_workflow_1.png', dpi=300, facecolor='white', edgecolor='none', bbox_inches='tight')\n",
    "    fig2.savefig(out_path+'methods_workflow_2.png', dpi=300, facecolor='white', edgecolor='none', bbox_inches='tight')\n",
    "    fig3.savefig(out_path+'methods_workflow_3.png', dpi=300, facecolor='white', edgecolor='none', bbox_inches='tight')\n",
    "    fig4.savefig(out_path+'methods_workflow_4.png', dpi=300, facecolor='white', edgecolor='none', bbox_inches='tight')\n",
    "    fig5.savefig(out_path+'methods_workflow_5.png', dpi=300, facecolor='white', edgecolor='none', bbox_inches='tight')\n",
    "    print('figures saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57233c12-414d-4b4d-8b04-5aebb96b5bc7",
   "metadata": {},
   "source": [
    "## Figure 4. Images used for classification performance assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0da72-602b-428b-aa1e-9c6114f008c7",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/snow_cover_mapping/classified-points/assessment/'\n",
    "\n",
    "# grab Sentinel-2_SR image file names\n",
    "os.chdir(data_path)\n",
    "im_fns = sorted(glob.glob('*Sentinel-2_SR*.tif'))\n",
    "# plot Lemon Creek images on top\n",
    "im_fns = im_fns[2:] + im_fns[0:2]\n",
    "\n",
    "# grab validation point names\n",
    "data_pts_fns = sorted(glob.glob('*.shp'))\n",
    "\n",
    "# set up figure\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8,8))\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "ax = ax.flatten()\n",
    "text_labels = ['a)', 'b)', 'c)', 'd)']\n",
    "# plot dummy points for legend\n",
    "ax[0].plot(0,0, '.', markersize=8, color=colors_classified[0], label='snow')\n",
    "ax[0].plot(0,0, '.', markersize=8, color=colors_classified[3], label='no snow')\n",
    "\n",
    "# loop through image files\n",
    "for i, im_fn in enumerate(im_fns):\n",
    "    \n",
    "    print(im_fn)\n",
    "    \n",
    "    # open image and plot\n",
    "    im = rxr.open_rasterio(im_fn)\n",
    "    im = im / 1e4\n",
    "    ax[i].imshow(np.dstack([im.data[3], im.data[2], im.data[1]]),\n",
    "                extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "    \n",
    "    # load data points and plot\n",
    "    site_name = im_fn.split('_')[0]\n",
    "    im_date = im_fn[-12:-4]\n",
    "    data_pts_snow_fn = [x for x in data_pts_fns if (site_name in x) and (im_date[0:6] in x) and ('_snow' in x)]\n",
    "    if len(data_pts_snow_fn) > 0:\n",
    "        data_pts_snow = gpd.read_file(data_pts_snow_fn[0])\n",
    "        data_pts_snow = data_pts_snow.to_crs(im.rio.crs)\n",
    "        data_pts_snow.plot(ax=ax[i], color=colors_classified[0], markersize=1)\n",
    "    data_pts_no_snow_fn = [x for x in data_pts_fns if (site_name in x) and (im_date[0:6] in x) and ('no-snow' in x)]\n",
    "    if len(data_pts_no_snow_fn) > 0:\n",
    "        data_pts_no_snow = gpd.read_file(data_pts_no_snow_fn[0])\n",
    "        data_pts_no_snow = data_pts_no_snow.to_crs(im.rio.crs)\n",
    "        data_pts_no_snow.plot(ax=ax[i], color=colors_classified[3], markersize=1)\n",
    "        \n",
    "    # set axis limits and ticks\n",
    "    if i>=2:\n",
    "        ax[i].set_xlim(593e3, 603e3)\n",
    "        ax[i].set_ylim(5188e3, 5196e3)\n",
    "        ax[i].set_xticks(np.arange(594e3, 603e3, step=2e3))\n",
    "        ax[i].set_yticks(np.arange(5188e3, 5197e3, step=2e3))\n",
    "    else:\n",
    "        ax[i].set_xlim(535e3, 541e3)\n",
    "        ax[i].set_ylim(6468e3, 6475e3)\n",
    "        ax[i].set_xticks(np.arange(536e3, 541e3, step=2e3))\n",
    "        ax[i].set_yticks(np.arange(6468e3, 6475e3, step=2e3))\n",
    "    # change labels from m to km\n",
    "    ax[i].set_xticklabels([str(int(x/1e3)) for x in ax[i].get_xticks()])\n",
    "    ax[i].set_yticklabels([str(int(x/1e3)) for x in ax[i].get_yticks()])\n",
    "        \n",
    "    # add text labels\n",
    "    ax[i].text((ax[i].get_xlim()[1] - ax[i].get_xlim()[0])*0.05 + ax[i].get_xlim()[0],\n",
    "               (ax[i].get_ylim()[1] - ax[i].get_ylim()[0])*0.9 + ax[i].get_ylim()[0],\n",
    "               text_labels[i], backgroundcolor='w')\n",
    "    \n",
    "\n",
    "# add axis labels\n",
    "ax[0].set_ylabel('Northing [km]')\n",
    "ax[2].set_ylabel('Northing [km]')\n",
    "ax[2].set_xlabel('Easting [km]')\n",
    "ax[3].set_xlabel('Easting [km]')\n",
    "\n",
    "# add legend\n",
    "handles, labels = ax[0].get_legend_handles_labels()\n",
    "fig.legend(handles, labels, loc=(0.38, 0.92), ncols=2)\n",
    "\n",
    "# fig.tight_layout()\n",
    "plt.show()\n",
    "    \n",
    "# save figure\n",
    "if save_figures:\n",
    "    fig_fn = 'classification_performance_assessment_images.png'\n",
    "    fig.savefig(out_path + fig_fn, facecolor='w', dpi=300, bbox_inches='tight')\n",
    "    print('figure saved to file: ' + out_path + fig_fn)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d78494-d9a0-4fc9-b39c-f07441646475",
   "metadata": {},
   "source": [
    "## Figure 5. Median snowline elevations for the USGS Benchmark Glaciers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c15fcf-cc5d-4bcb-b942-39d0c42b4a66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Settings and display parameters\n",
    "site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry']\n",
    "site_names_display = ['Wolverine',  'Gulkana', 'Lemon Creek', 'South Cascade', 'Sperry']\n",
    "text_labels = ['a)', 'b)', 'c)', 'd)', 'e)']\n",
    "\n",
    "# -----Path to USGS mass balance data\n",
    "usgs_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "\n",
    "# -----Set up figures\n",
    "# sall sites\n",
    "fig, ax = plt.subplots(5, 1, figsize=(20, 24))\n",
    "ax = ax.flatten()\n",
    "plt.rcParams.update({'font.size':20, 'font.sans-serif':'Arial'})\n",
    "fmt_month = matplotlib.dates.MonthLocator(bymonth=(5, 11)) # minor ticks every month\n",
    "fmt_year = matplotlib.dates.YearLocator() # minor ticks every year\n",
    "alpha = 0.9\n",
    "\n",
    "# -----Loop through sites\n",
    "for site_name, site_name_display, text_label, i in list(zip(site_names, site_names_display, text_labels, np.arange(0,len(site_names)))):\n",
    "    \n",
    "    print(site_name)\n",
    "    \n",
    "    # load estimated snow lines  \n",
    "    sl_est_fns = glob.glob(study_sites_path + site_name + '/imagery/snowlines/*snowline.csv')\n",
    "    sl_ests = gpd.GeoDataFrame()\n",
    "    for sl_est_fn in sl_est_fns:\n",
    "        sl_est = pd.read_csv(sl_est_fn)\n",
    "        sl_ests = pd.concat([sl_ests, sl_est])\n",
    "    sl_ests.reset_index(drop=True, inplace=True)\n",
    "    sl_ests['datetime'] = sl_ests['datetime'].astype('datetime64[ns]')\n",
    "    \n",
    "    # define axis limits\n",
    "    xmin, xmax = np.datetime64('2013-05-01T00:00:00'), np.datetime64('2022-12-01T00:00:00')\n",
    "    sl_elev_median_min = np.nanmin(sl_ests['snowlines_elevs_median_m'])\n",
    "    sl_elev_median_max = np.nanmax(sl_ests['snowlines_elevs_median_m'])\n",
    "    ymin = sl_elev_median_min - 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "    ymax = sl_elev_median_max + 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "    \n",
    "    # plot minimum elevation \n",
    "    ax[i].plot([xmin, xmax], [sl_elev_median_min, sl_elev_median_min], '--', color='grey')\n",
    "    \n",
    "    # plot\n",
    "    # PlanetScope\n",
    "    ax[i].plot(sl_ests['datetime'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "               sl_ests['snowlines_elevs_median_m'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "               '.', markeredgecolor='w', markerfacecolor=color_PlanetScope, \n",
    "               alpha=alpha, markersize=15, markeredgewidth=1, label='_nolegend_')\n",
    "        \n",
    "    # Sentinel-2 SR\n",
    "    ax[i].plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel-2_SR'], \n",
    "               sl_ests['snowlines_elevs_median_m'].loc[sl_ests['dataset']=='Sentinel-2_SR'], \n",
    "               '*', markeredgecolor='w', markerfacecolor=color_Sentinel2, \n",
    "               alpha=alpha, markersize=15, markeredgewidth=1, label='_nolegend_')\n",
    "    \n",
    "    # Sentinel-2 TOA\n",
    "    ax[i].plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel-2_TOA'], \n",
    "               sl_ests['snowlines_elevs_median_m'].loc[sl_ests['dataset']=='Sentinel-2_TOA'], \n",
    "               'o', markeredgecolor=color_Sentinel2, markerfacecolor='None', \n",
    "               alpha=alpha, markersize=5, markeredgewidth=3, label='_nolegend_')\n",
    "    \n",
    "    # Landsat\n",
    "    ax[i].plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Landsat'], \n",
    "               sl_ests['snowlines_elevs_median_m'].loc[sl_ests['dataset']=='Landsat'], \n",
    "               '^', markeredgecolor='w', markerfacecolor=color_Landsat, \n",
    "               alpha=alpha, markersize=10, markeredgewidth=1, label='_nolegend_')                 \n",
    "    \n",
    "    # sett axis limits\n",
    "    ax[i].set_xlim(xmin, xmax)\n",
    "    ax[i].set_ylim(ymin, ymax)\n",
    "    ax[i].grid()\n",
    "    # x-labels\n",
    "    ax[i].xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "    ax[i].xaxis.set_major_locator(fmt_month)\n",
    "    ax[i].xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "    sec_xaxis = ax[4].secondary_xaxis(-0.1)\n",
    "    sec_xaxis.xaxis.set_major_locator(fmt_year)\n",
    "    sec_xaxis.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "    # Hide the second x-axis spines and ticks\n",
    "    sec_xaxis.spines['bottom'].set_visible(False)\n",
    "    sec_xaxis.tick_params(length=0, pad=10)\n",
    "    if i<4:\n",
    "        ax[i].set_xticklabels([])\n",
    "        sec_xaxis.set_xticklabels([])\n",
    "    # y-label on middle panel\n",
    "    if i==2:\n",
    "        ax[i].set_ylabel('Median snowline elevation [m]')\n",
    "    # text label\n",
    "    ax[i].text((xmax-xmin)*0.015 + xmin, (ymax-ymin)*0.87 + ymin, \n",
    "               text_label + ' ' + site_name_display, \n",
    "               bbox=dict(facecolor='white', edgecolor='black', pad=5))\n",
    "\n",
    "    # -----Observed snow lines\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = study_sites_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    # load DEM\n",
    "    DEM_fn = glob.glob(study_sites_path + site_name + '/DEMs/*_clip.tif')[0]\n",
    "    # load DEM as xarray DataSet\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "    if len(np.shape(DEM.elevation.data))>2: # remove unnecessary dimensions\n",
    "        DEM['elevation'] = DEM.elevation[0]\n",
    "    # solve for optimal UTM zone\n",
    "    DEM_WGS = DEM.rio.reproject('EPSG:4326')\n",
    "    epsg_UTM = f.convert_wgs_to_utm(np.nanmean(DEM_WGS.x.data), np.nanmean(DEM_WGS.y.data))\n",
    "    # reproject DEM\n",
    "    DEM = DEM.rio.reproject('EPSG:'+epsg_UTM)\n",
    "    # loop through observed snow lines\n",
    "    for j, sl_obs_fn in enumerate(sl_obs_fns):\n",
    "        # load observed snow line\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:8]\n",
    "        datetime = np.datetime64(date[0:4] + '-' + date[4:6] + '-' + date[6:8] + 'T00:00:00')\n",
    "        # reproject snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs('EPSG:'+epsg_UTM)\n",
    "        # interpolate elevation at snow line points\n",
    "        if len(sl_obs_UTM) > 1:\n",
    "            sl_obs_elev = np.array([DEM.sel(x=x, y=y, method='nearest').elevation.data \n",
    "                                for x, y in list(zip(sl_obs_UTM.geometry[1].xy[0], \n",
    "                                                     sl_obs_UTM.geometry[1].xy[1]))])\n",
    "        else:\n",
    "            sl_obs_elev = np.array([DEM.sel(x=x, y=y, method='nearest').elevation.data \n",
    "                                for x, y in list(zip(sl_obs_UTM.geometry[0].xy[0], \n",
    "                                                     sl_obs_UTM.geometry[0].xy[1]))])\n",
    "        # calculate median snow line elevation\n",
    "        sl_obs_elev_median = np.nanmedian(sl_obs_elev)\n",
    "        # plot\n",
    "        ax[i].plot(datetime, sl_obs_elev_median, 'xk', markersize=10, markeredgewidth=2, label='_nolegend_')   \n",
    "            \n",
    "    # load USGS ELA estimates\n",
    "    usgs_fn = usgs_path + site_name + '/Output_' + site_name + '_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype('datetime64[ns]')\n",
    "    ax[i].plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='k', \n",
    "               ms=10, markeredgewidth=2, label='_nolegend_')\n",
    "            \n",
    "# -----Dummy points for legend\n",
    "# observed\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, 'xk', \n",
    "           markersize=15, markeredgewidth=3, label='observed')\n",
    "# USGS\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, 's', markerfacecolor='None', markeredgecolor='k', \n",
    "               ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "# Landsat\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '^', \n",
    "           markeredgecolor=color_Landsat, markerfacecolor=color_Landsat, \n",
    "           markersize=12, label='Landsat 8/9')\n",
    "# Sentinel-2 SR\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor=color_Sentinel2, markerfacecolor=color_Sentinel2, \n",
    "           markersize=18, label='Sentinel-2 SR')\n",
    "# Sentinel-2 TOA\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, 'o',\n",
    "           markeredgecolor=color_Sentinel2, markerfacecolor='w', \n",
    "           markersize=18, markeredgewidth=4, label='Sentinel-2 TOA')\n",
    "# PlanetScope\n",
    "ax[0].plot(np.datetime64('1970-01-01'), 0, '.', \n",
    "       markeredgecolor=color_PlanetScope, markerfacecolor=color_PlanetScope, \n",
    "       markersize=20, label='PlanetScope')\n",
    "ax[0].legend(loc='center', bbox_to_anchor=(0.5, 1.15), ncol=6)\n",
    "\n",
    "plt.show()\n",
    "    \n",
    "# -----Save figure\n",
    "if save_figures:\n",
    "    fig_fn = 'median_snowline_elevs.png'\n",
    "    fig.savefig(out_path + fig_fn, facecolor='w', dpi=300)\n",
    "    print('figure saved to file: ' + out_path + fig_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3055b332-fbcd-442b-b0e1-4b0d8e420517",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "col = plt.cm.viridis\n",
    "for i, site_name in enumerate(site_names):\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype('datetime64[ns]')\n",
    "    plt.plot(ELA_date, ELA, '.-', color=col((i+1)/len(site_names)), label=site_name)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce8d43f-fe2e-4b81-8c00-2918286386de",
   "metadata": {},
   "source": [
    "## Figure 6. Example ideal and difficult conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf3a99c-7090-4432-927d-6f149fb0bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Set up figure\n",
    "fig, ax = plt.subplots(2, 2, figsize=(12, 12))\n",
    "plt.rcParams.update({'font.size':28, 'font.sans-serif':'Arial'})\n",
    "ax = ax.flatten()\n",
    "\n",
    "# -----Ideal conditions\n",
    "## PlanetScope - Wolverine - 20210815\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Wolverine/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20210815*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Wolverine/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20210815T200000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[0].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[0].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[0].text(ax[0].get_xlim()[0] + 0.85*(ax[0].get_xlim()[1] - ax[0].get_xlim()[0]), \n",
    "           ax[0].get_ylim()[0] + 0.05*(ax[0].get_ylim()[1] - ax[0].get_ylim()[0]),\n",
    "           'a)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[0].set_title('Ideal conditions')\n",
    "ax[0].set_xticks([])\n",
    "ax[0].set_yticks([])\n",
    "## PlanetScope - Lemon Creek - 20220821\n",
    "# image\n",
    "im_path = base_path + '../study-sites/LemonCreek/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20220821*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/LemonCreek/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20220821T190000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[2].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[2].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[2].text(ax[2].get_xlim()[0] + 0.8*(ax[2].get_xlim()[1] - ax[2].get_xlim()[0]), \n",
    "           ax[2].get_ylim()[0] + 0.05*(ax[2].get_ylim()[1] - ax[2].get_ylim()[0]),\n",
    "           'c)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[2].set_xticks([])\n",
    "ax[2].set_yticks([])\n",
    "\n",
    "# -----Difficult conditions\n",
    "## PlanetScope - Sperry - 20160816\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Sperry/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20160816*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Sperry/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20160816T170000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[1].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[1].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[1].text(ax[1].get_xlim()[0] + 0.85*(ax[1].get_xlim()[1] - ax[1].get_xlim()[0]), \n",
    "           ax[1].get_ylim()[0] + 0.05*(ax[1].get_ylim()[1] - ax[1].get_ylim()[0]),\n",
    "           'b)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[1].set_title('Difficult conditions')\n",
    "ax[1].set_xticks([])\n",
    "ax[1].set_yticks([])\n",
    "\n",
    "## PlanetScope - Gulkana - 20170629\n",
    "# image\n",
    "im_path = base_path + '../study-sites/Gulkana/imagery/PlanetScope/adjusted/'\n",
    "im_fn = glob.glob(im_path + '*20170629*.nc')[0]\n",
    "im = xr.open_dataset(im_fn)\n",
    "im = im.isel(time=0)\n",
    "# snowline\n",
    "sl_fn = glob.glob(base_path + '../study-sites/Gulkana/imagery/PlanetScope/snowlines/*snowlines.pkl')[0]\n",
    "sl = pd.read_pickle(sl_fn)\n",
    "sl = sl.loc[sl['datetime']=='20170629T200000'].reset_index(drop=True)\n",
    "# plot\n",
    "ax[3].imshow(np.dstack([im['red'].data, im['green'].data, im['blue'].data]), \n",
    "             extent=(np.min(im.x.data), np.max(im.x.data), np.min(im.y.data), np.max(im.y.data)))\n",
    "ax[3].plot(*sl['snowlines_coords'][0].coords.xy, '.m', markersize=2)\n",
    "ax[3].text(ax[3].get_xlim()[0] + 0.9*(ax[3].get_xlim()[1] - ax[3].get_xlim()[0]), \n",
    "           ax[3].get_ylim()[0] + 0.08*(ax[3].get_ylim()[1] - ax[3].get_ylim()[0]),\n",
    "           'd)', bbox=dict(facecolor='white', edgecolor='black', pad=3))\n",
    "ax[3].set_xticks([])\n",
    "ax[3].set_yticks([])\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# -----Save figure\n",
    "fig_fn = 'example_ideal+difficult_conditions.png'\n",
    "fig.savefig(out_path + fig_fn, dpi=300, facecolor='w')\n",
    "print('figure saved to file: '+ out_path + fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430d0c4",
   "metadata": {},
   "source": [
    "## Snow cover products comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1083e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # -----Load Landsat fSCA\n",
    "# LS_fn = base_path+'../study-sites/Wolverine/imagery/Landsat/fSCA/LC08_AK_016008_20210829_20210913_02_SNOW/LC08_AK_016008_20210829_20210913_02_VIEWABLE_SNOW_UTM.TIF'\n",
    "# LS = rxr.open_rasterio(LS_fn)\n",
    "# # remove no-data values\n",
    "# LS = LS.where(LS != -9999)\n",
    "# # account for image multiplier\n",
    "# LS_scalar = 0.001\n",
    "# LS = LS * LS_scalar\n",
    "# crs = LS.rio.crs.to_string()\n",
    "\n",
    "# # -----Load MODIS fSCA\n",
    "# M_fn = base_path+'../study-sites/Wolverine/imagery/MODIS/Terra_fSCA/2021_08_15.tif'\n",
    "# M = rxr.open_rasterio(M_fn)\n",
    "# # grab snow cover band\n",
    "# M_fSCA = M.isel(band=0)\n",
    "# # remove no data values\n",
    "# M_fSCA = M_fSCA.where(M_fSCA != -3.2768e04)\n",
    "# # reproject \n",
    "# M_fSCA= M_fSCA.rio.reproject(crs)\n",
    "\n",
    "# # -----Load PlanetScope image and snow\n",
    "# # RGB image\n",
    "# PS_path = base_path+'../study-sites/Wolverine/imagery/PlanetScope/adjusted-filtered/'\n",
    "# PS_fn = '20210815_20_adj.tif'\n",
    "# PS = rxr.open_rasterio(PS_path + PS_fn)\n",
    "# PS = PS / 1e4\n",
    "# # classify image\n",
    "# clf_fn = base_path+'/inputs-outputs/PS_classifier_all_sites.sav'\n",
    "# clf = pickle.load(open(clf_fn, 'rb'))\n",
    "# feature_cols_fn = base_path+'inputs-outputs/PS_feature_cols.pkl'\n",
    "# feature_cols = pickle.load(open(feature_cols_fn,'rb'))\n",
    "# sys.path.insert(1, base_path+'functions/')\n",
    "# from ps_pipeline_utils import classify_image\n",
    "# im_classified_fn, im = classify_image(PS_fn, PS_path, clf, feature_cols, False, None, out_path)\n",
    "# # load classified image\n",
    "# im_classified = rxr.open_rasterio(out_path + im_classified_fn) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3180d701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # -----Create snow colormap\n",
    "# color_snow = '#4eb3d3'\n",
    "# color_no_snow = 'w'\n",
    "# # create colormap\n",
    "# colors = [color_no_snow, color_snow]\n",
    "# cmp = cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)\n",
    "\n",
    "# # -----Plot\n",
    "# fig, ax = plt.subplots(2, 2, figsize=(10,10))\n",
    "# ax = ax.flatten()\n",
    "# plt.rcParams.update({'font.size':16, 'font.sans-serif':'Arial'})\n",
    "# xmin, xmax, ymin, ymax = 391, 399, 6694, 6702\n",
    "# # MODIS\n",
    "# M_im = ax[0].imshow(M_fSCA.data, cmap=cmp, clim=(0,100),\n",
    "#                     extent=(np.min(M_fSCA.x.data)/1000, np.max(M_fSCA.x.data)/1000, \n",
    "#                             np.min(M_fSCA.y.data)/1000, np.max(M_fSCA.y.data)/1000))\n",
    "# ax[0].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[0].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[0].set_xticklabels([])\n",
    "# ax[0].set_xlim(xmin, xmax)\n",
    "# ax[0].set_ylim(ymin, ymax)\n",
    "# ax[0].set_ylabel('Northing [km]')\n",
    "# ax[0].set_title('a) MODIS f$_{SCA}$')\n",
    "# # LS\n",
    "# LS_im = ax[1].imshow(LS_fSCA, cmap=cmp, clim=(0,1),\n",
    "#                    extent=(np.min(LS_x)/1000, np.max(LS_x)/1000, np.min(LS_y)/1000, np.max(LS_y)/1000))\n",
    "# ax[1].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[1].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[1].set_xticklabels([])\n",
    "# ax[1].set_yticklabels([])\n",
    "# ax[1].set_xlim(xmin, xmax)\n",
    "# ax[1].set_ylim(ymin, ymax)\n",
    "# ax[1].set_title('b) Landsat 8 f$_{SCA}$')\n",
    "# # PS RGB\n",
    "# ax[2].imshow(np.dstack([PS.data[2], PS.data[1], PS.data[0]]),\n",
    "#            extent=(np.min(PS.x.data)/1000, np.max(PS.x.data)/1000, np.min(PS.y.data)/1000, np.max(PS.y.data)/1000))\n",
    "# ax[2].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[2].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[2].set_xlim(xmin, xmax)\n",
    "# ax[2].set_ylim(ymin, ymax)\n",
    "# ax[2].set_ylabel('Northing [km]')\n",
    "# ax[2].set_xlabel('Easting [km]')\n",
    "# ax[2].set_title('c) PlanetScope RGB')\n",
    "# # PS snow\n",
    "# im_classified = im_classified.where(im_classified!=-9999)\n",
    "# im_binary = xr.where(im_classified<=2, 1, 0)\n",
    "# PS_snow_im = ax[3].imshow(im_binary.data[0], cmap=cmp, clim=(0,1),\n",
    "#                    extent=(np.min(PS.x.data)/1000, np.max(PS.x.data)/1000, np.min(PS.y.data)/1000, np.max(PS.y.data)/1000))\n",
    "# ax[3].set_xticks(np.linspace(392, 398, num=4))\n",
    "# ax[3].set_yticks(np.linspace(6694, 6702, num=5))\n",
    "# ax[3].set_yticklabels([])\n",
    "# ax[3].set_xlim(xmin, xmax)\n",
    "# ax[3].set_ylim(ymin, ymax)\n",
    "# ax[3].set_xlabel('Easting [km]')\n",
    "# ax[3].set_title('d) PlanetScope SCA')\n",
    "# # colorbar\n",
    "# cbar_ax = fig.add_axes([0.92, 0.35, 0.02, 0.3])\n",
    "# fig.colorbar(M_im, cax=cbar_ax)\n",
    "# plt.show()\n",
    "\n",
    "# if save_figures:\n",
    "#     fig.savefig(out_path+'comparing_SCA_products.png', dpi=300, facecolor='white', edgecolor='none')\n",
    "#     print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4215bd39-59b9-4a53-be64-0c5db99554fc",
   "metadata": {},
   "source": [
    "## Study sites: RGI regions 1 and 2 (Alaska, the Western U.S. and Canada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad7d55f3-12d3-4b55-aef0-f04546239ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to RGI data\n",
    "RGI_path = '/Volumes/GoogleDrive/My Drive/Research/PhD/GIS_data/RGI/'\n",
    "# RGI shapefile names\n",
    "RGI_fns = ['01_rgi60_Alaska/01_rgi60_Alaska.shp', \n",
    "           '02_rgi60_WesternCanadaUS/02_rgi60_WesternCanadaUS.shp']\n",
    "\n",
    "# -----Load, format, filter, plot RGI glacier outlines\n",
    "# Create geopandas.DataFrame for storing RGIs\n",
    "RGI = gpd.GeoDataFrame()\n",
    "# Read RGI files\n",
    "for RGI_fn in RGI_fns:\n",
    "    file = gpd.read_file(RGI_path + RGI_fn)\n",
    "    RGI = pd.concat([RGI, file])\n",
    "# subset to glaciers with area > 5 km^2\n",
    "RGI_gt5 = RGI.loc[RGI['Area'] > 5].reset_index(drop=True)\n",
    "# change int data types to float for saving\n",
    "RGI_gt5[['Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect', 'Lmax', 'Status', 'Connect', \n",
    "         'Form', 'TermType', 'Surging', 'Linkages']] = RGI_gt5[['Zmin', 'Zmax', 'Zmed', 'Slope', 'Aspect', 'Lmax', \n",
    "                                                            'Status', 'Connect', 'Form', 'TermType', 'Surging', 'Linkages']].astype(float)\n",
    "\n",
    "# -----Grab list of all unique regions and subregions in dataset\n",
    "regions_subregions = sorted(RGI_gt5[['O1Region', 'O2Region']].drop_duplicates().values,\n",
    "                            key=operator.itemgetter(0, 1))\n",
    "subregions_names = ['Brooks Range', 'Alaska Range', 'Aleutians', 'W. Chugach Mtns.', 'St. Elias Mtns.', \n",
    "                    'N. Coast Ranges', 'N. Rockies', 'N. Cascades', 'S. Rockies', 'S. Cascades']\n",
    "subregions_colors = ['c', '#1f78b4', '#b2df8a', '#33a02c', '#fb9a99', '#e31a1c', \n",
    "                     '#fdbf6f', '#ff7f00', '#cab2d6', '#6a3d9a']\n",
    "\n",
    "# -----Plot all sites with color distinguishing subregions\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12,10))\n",
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "crs = 'EPSG:9822' # Albers Equal Conic projection\n",
    "i=0\n",
    "for region, subregion in regions_subregions:\n",
    "    RGI_gt5_subregion = RGI_gt5.loc[(RGI_gt5['O1Region']==region) & (RGI_gt5['O2Region']==subregion)]\n",
    "    RGI_gt5_subregion_reproj = RGI_gt5_subregion.to_crs(crs)\n",
    "    for j in range(0, len(RGI_gt5_subregion)):\n",
    "        polygon = RGI_gt5_subregion_reproj.iloc[j]['geometry']\n",
    "        if j==0:\n",
    "            label=subregions_names[i]\n",
    "        else:\n",
    "            label='_nolegend_'\n",
    "        ax.plot(*polygon.exterior.xy, label=label, color=subregions_colors[i])\n",
    "    i+=1\n",
    "cx.add_basemap(ax, crs=crs, source=cx.providers.Esri.WorldShadedRelief, attribution=False)\n",
    "ax.legend(loc='center right', title='RGI Subregions', bbox_to_anchor=[1.25, 0.5, 0.2, 0.2])\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.grid()\n",
    "plt.show()\n",
    "\n",
    "# -----Save figure\n",
    "fig.savefig(out_path + 'RGI_regions_1+2.png', dpi=300, facecolor='w')\n",
    "print('figure saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e224916",
   "metadata": {},
   "source": [
    "## Median snow line elevations for individual sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cf63bb-73e1-437b-b3c8-7b9e98c16148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Settings and display parameters\n",
    "site_name = 'Gulkana' # as shown in folder name\n",
    "# site_name_display = 'Gulkana' # how to display on figure\n",
    "dataset_colors = {'Landsat': '#33a02c',\n",
    "                  'Sentinel2_TOA': '#1f78b4',\n",
    "                  'Sentinel2_SR': '#1f78b4',\n",
    "                  'PlanetScope': '#a6cee3'\n",
    "                 }\n",
    "\n",
    "# -----Path to USGS mass balance data\n",
    "usgs_path = '/Volumes/GoogleDrive/My Drive/Research/PhD/GIS_data/USGS/benchmarkGlacier_massBalance/'\n",
    "    \n",
    "# -----Load estimated snow lines  \n",
    "sl_est_fns = glob.glob(base_path + '../study-sites/' + site_name + '/imagery/snowlines/*snowline.pkl')\n",
    "sl_ests = pd.DataFrame()\n",
    "for sl_est_fn in sl_est_fns:\n",
    "    sl_est = pd.read_pickle(sl_est_fn)\n",
    "    sl_ests = pd.concat([sl_ests, sl_est])\n",
    "sl_ests = sl_ests.reset_index(drop=True)\n",
    "sl_ests['datetime'] = sl_ests['datetime'].astype(np.datetime64)\n",
    "\n",
    "# -----Plot\n",
    "# Set up figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(20, 8))\n",
    "plt.rcParams.update({'font.size':16, 'font.sans-serif':'Arial'})\n",
    "fmt_month = matplotlib.dates.MonthLocator(bymonth=(5, 11)) # minor ticks every month\n",
    "fmt_year = matplotlib.dates.YearLocator() # minor ticks every year\n",
    "# PlanetScope\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='PlanetScope'], \n",
    "           '.', markeredgecolor='w', markerfacecolor=dataset_colors['PlanetScope'], \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Sentinel-2 TOA\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel2_TOA'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Sentinel2_TOA'], \n",
    "           '*', markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2_TOA'], \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Sentinel-2 SR\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Sentinel2_SR'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Sentinel2_SR'], \n",
    "           '*', markeredgecolor=dataset_colors['Sentinel2_SR'], markerfacecolor='None', \n",
    "           markersize=20, markeredgewidth=1, label='_nolegend_')\n",
    "# Landsat\n",
    "ax.plot(sl_ests['datetime'].loc[sl_ests['dataset']=='Landsat'], \n",
    "           sl_ests['snowlines_elevs_median'].loc[sl_ests['dataset']=='Landsat'], \n",
    "           '^', markeredgecolor='w', markerfacecolor=dataset_colors['Landsat'], \n",
    "           markersize=15, markeredgewidth=1, label='_nolegend_')                \n",
    "        \n",
    "# -----Dummy points for legend\n",
    "# observed\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, 'xk', \n",
    "           markersize=15, markeredgewidth=3, label='observed')\n",
    "# USGS\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='USGS ELA')\n",
    "# Landsat\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '^', \n",
    "           markeredgecolor=dataset_colors['Landsat'], markerfacecolor=dataset_colors['Landsat'], \n",
    "           markersize=12, label='Landsat 8/9')\n",
    "# Sentinel-2 TOA\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor='w', markerfacecolor=dataset_colors['Sentinel2_TOA'], \n",
    "           markersize=18, label='Sentinel-2 TOA')\n",
    "# Sentinel-2 SR\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '*',\n",
    "           markeredgecolor=dataset_colors['Sentinel2_SR'], markerfacecolor='None', \n",
    "           markersize=18, label='Sentinel-2 SR')\n",
    "# PlanetScope\n",
    "ax.plot(np.datetime64('1970-01-01'), 0, '.', \n",
    "       markeredgecolor=dataset_colors['PlanetScope'], markerfacecolor=dataset_colors['PlanetScope'], \n",
    "       markersize=20, label='PlanetScope')\n",
    "ax.legend(loc='center', bbox_to_anchor=(0.5, 1.05), ncol=6)\n",
    "\n",
    "# -----Observed snow lines\n",
    "# define path to digitized snow lines\n",
    "sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "# load AOI as gpd.GeoDataFrame\n",
    "AOI_fn = base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp'\n",
    "AOI_fn = glob.glob(AOI_fn)[0]\n",
    "AOI = gpd.read_file(AOI_fn)\n",
    "# load DEM from GEE\n",
    "DEM, AOI_UTM = pf.query_GEE_for_DEM(AOI)\n",
    "# loop through observed snow lines\n",
    "for j, sl_obs_fn in enumerate(sl_obs_fns):\n",
    "    # load observed snow line\n",
    "    sl_obs = gpd.read_file(sl_obs_fn)\n",
    "    # extract date from filename\n",
    "    date = sl_obs_fn.split('/'+site_name+'_')[1][0:8]\n",
    "    datetime = np.datetime64(date[0:4] + '-' + date[4:6] + '-' + date[6:8]\n",
    "                             + 'T00:00:00')\n",
    "    # reproject snow line to UTM\n",
    "    sl_obs_UTM = sl_obs.to_crs(str(AOI_UTM.crs.to_epsg()))\n",
    "    # interpolate elevation at snow line points\n",
    "    if len(sl_obs_UTM) > 1:\n",
    "        sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                            for x, y in list(zip(sl_obs_UTM.geometry[1].xy[0], \n",
    "                                                 sl_obs_UTM.geometry[1].xy[1]))])\n",
    "    else:\n",
    "        sl_obs_elev = np.array([DEM.sel(time=DEM.time.data[0], x=x, y=y, method='nearest').elevation.data \n",
    "                            for x, y in list(zip(sl_obs_UTM.geometry[0].xy[0], \n",
    "                                                 sl_obs_UTM.geometry[0].xy[1]))])\n",
    "    # calculate median snow line elevation\n",
    "    sl_obs_elev_median = np.nanmedian(sl_obs_elev)\n",
    "    # plot\n",
    "    ax.plot(datetime, sl_obs_elev_median, 'xk', markersize=10, markeredgewidth=2, label='_nolegend_')   \n",
    "            \n",
    "    # load USGS ELA estimates\n",
    "    usgs_fn = usgs_path + site_name+'/Output_'+site_name+'_Glacier_Wide_solutions_calibrated.csv'\n",
    "    usgs_file = pd.read_csv(usgs_fn)\n",
    "    ELA = usgs_file['ELA']\n",
    "    ELA_date = usgs_file['Ba_Date'].astype(np.datetime64)\n",
    "    ax.plot(ELA_date, ELA, 's', markerfacecolor='None', markeredgecolor='r', \n",
    "               ms=10, markeredgewidth=2, label='_nolegend_')\n",
    "\n",
    "# -----Adjust axes\n",
    "# axis limits\n",
    "xmin, xmax = np.datetime64('2017-05-01T00:00:00'), np.datetime64('2023-01-01T00:00:00')\n",
    "sl_elev_median_min = np.min(sl_ests['snowlines_elevs_median'])\n",
    "sl_elev_median_max = np.max(sl_ests['snowlines_elevs_median'])\n",
    "ymin = sl_elev_median_min - 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "ymax = sl_elev_median_max + 0.1*(sl_elev_median_max - sl_elev_median_min)\n",
    "ax.set_xlim(xmin, xmax)\n",
    "ax.set_ylim(ymin, ymax)\n",
    "ax.grid()\n",
    "# x-labels\n",
    "ax.xaxis.set_minor_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "ax.xaxis.set_major_locator(fmt_month)\n",
    "ax.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%b'))\n",
    "sec_xaxis = ax.secondary_xaxis(-0.1)\n",
    "sec_xaxis.xaxis.set_major_locator(fmt_year)\n",
    "sec_xaxis.xaxis.set_major_formatter(matplotlib.dates.DateFormatter('%Y'))\n",
    "# Hide the second x-axis spines and ticks\n",
    "sec_xaxis.spines['bottom'].set_visible(False)\n",
    "sec_xaxis.tick_params(length=0, pad=10)\n",
    "# y-label\n",
    "ax.set_ylabel('Elevation [m]')\n",
    "plt.show()\n",
    "    \n",
    "# -----Save figure\n",
    "fig_fn = 'median_snowline_elevs_' + site_name + '.png'\n",
    "fig.savefig(out_path + fig_fn, facecolor='w', dpi=300)\n",
    "print('figure saved to file: '+out_path+fig_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdacd23-947f-426b-8cb0-6fc48d3c4dba",
   "metadata": {},
   "source": [
    "## Training data characteristics by dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953ef42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load dataset dictionary\n",
    "with open(base_path + 'inputs-outputs/datasets_characteristics.pkl', 'rb') as fn:\n",
    "    dataset_dict = pickle.load(fn)\n",
    "\n",
    "# -----Define band ranges\n",
    "L8_dict = dataset_dict['Landsat']\n",
    "L8_dict['bands'] = {'SR_B2': {'name': 'blue',\n",
    "                              'min_nm': 450,\n",
    "                              'max_nm': 510},\n",
    "                    'SR_B3': {'name': 'green',\n",
    "                              'min_nm': 530,\n",
    "                              'max_nm': 590},\n",
    "                    'SR_B4': {'name': 'red',\n",
    "                              'min_nm': 640,\n",
    "                              'max_nm': 670},\n",
    "                    'SR_B5': {'name': 'NIR',\n",
    "                              'min_nm': 850,\n",
    "                              'max_nm': 880},\n",
    "                    'SR_B6': {'name': 'SWIR1',\n",
    "                              'min_nm': 1570,\n",
    "                              'max_nm': 1650},\n",
    "                    'SR_B7': {'name': 'SWIR2',\n",
    "                              'min_nm': 2110,\n",
    "                              'max_nm': 2290}\n",
    "                   }\n",
    "\n",
    "S2_dict = dataset_dict['Sentinel-2']\n",
    "S2_dict['bands'] = {'B2': {'name': 'blue',\n",
    "                           'wavelength_min_nm': 459,\n",
    "                           'wavelength_max_nm': 525\n",
    "                          },\n",
    "                    'B3': {'name': 'green',\n",
    "                           'wavelength_min_nm': 541,\n",
    "                           'wavelength_max_nm': 577\n",
    "                          },\n",
    "                    'B4': {'name': 'red',\n",
    "                           'wavelength_min_nm': 649,\n",
    "                           'wavelength_max_nm': 680\n",
    "                          },\n",
    "                    'B8': {'name': 'NIR',\n",
    "                           'wavelength_min_nm': 780,\n",
    "                           'wavelength_max_nm': 886\n",
    "                          },\n",
    "                    'B11': {'name': 'SWIR1',\n",
    "                           'wavelength_min_nm': 1567,\n",
    "                           'wavelength_max_nm': 1658\n",
    "                            \n",
    "                          },\n",
    "                    'B12': {'name': 'SWIR2',\n",
    "                           'wavelength_min_nm': 2114,\n",
    "                           'wavelength_max_nm': 2289\n",
    "                          }\n",
    "                   }\n",
    "PS_dict = dataset_dict['PlanetScope']\n",
    "PS_dict['bands'] = {'B1': {'name': 'blue',\n",
    "                           'wavelength_min_nm':,\n",
    "                           'wavelength_max_nm': \n",
    "                          }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
