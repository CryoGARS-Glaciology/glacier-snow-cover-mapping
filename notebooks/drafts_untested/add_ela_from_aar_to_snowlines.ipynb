{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40ced372-7da9-4715-844a-2b935734e7a2",
   "metadata": {},
   "source": [
    "# Add ELAs from AARs to snowline files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b20c4f-0f2a-4a67-ac5e-296d6ce797d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from tqdm.auto import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import ee\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d2139-c0fd-42a3-a020-ac003b6cd4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to study-sites\n",
    "study_sites_path = '/Users/raineyaberle/Google Drive/My Drive/Research/CryoGARS-Glaciology/Advising/student-research/Alexandra-Friel/snow_cover_mapping_application/study-sites/'\n",
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afa4cf0-2faa-4129-8d98-19f74537092e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Initialize GEE account\n",
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18840538-cb5a-4af7-b3a4-8d6c635a8a5c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Grab list of site names in study_sites_path\n",
    "site_names = sorted(os.listdir(study_sites_path))\n",
    "site_names = [x for x in site_names if not x.startswith('.')]\n",
    "# don't include BGOTUS (already done)\n",
    "bgotus_site_names = ['Wolverine', 'LemonCreek', 'Gulkana', 'SouthCascade', 'Sperry']\n",
    "site_names = [x for x in site_names if (x not in bgotus_site_names) and (\"all_\" not in x)]\n",
    "print(str(len(site_names)) + ' study sites:')\n",
    "site_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61e69f1-2da2-4828-838a-3f0d0138d975",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# iterate over site names\n",
    "for site_name in tqdm(site_names):\n",
    "    \n",
    "    print(site_name)\n",
    "    \n",
    "    # Load snowline file names\n",
    "    snowlines_path = study_sites_path + site_name + '/imagery/snowlines/'\n",
    "    snowline_fns = [os.path.basename(x) for x in glob.glob(snowlines_path + '*.csv')]\n",
    "    if len(snowline_fns)<1:\n",
    "        print(' ')\n",
    "        continue\n",
    "    \n",
    "    # Load AOI\n",
    "    AOI_path = study_sites_path + site_name + '/AOIs/'\n",
    "    AOI_fn = glob.glob(AOI_path + '*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                        AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    # grab the optimal UTM zone EPSG code\n",
    "    epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "    # reproject AOI to the optimal UTM zone\n",
    "    AOI_UTM = AOI.to_crs('EPSG:'+epsg_UTM)\n",
    "\n",
    "    # Load DEM, clip to AOI\n",
    "    DEM_path = study_sites_path + site_name + '/DEMs/'\n",
    "    # DEM_fn = glob.glob(DEM_path + '*USGS*.tif')[0]\n",
    "    # DEM = rxr.open_rasterio(DEM_fn)\n",
    "    DEM = f.query_gee_for_dem(AOI_UTM, base_path, site_name, DEM_path)  \n",
    "    if len(np.shape(DEM.elevation.data))>2:\n",
    "        DEM['elevation'] = DEM.elevation[0]\n",
    "    DEM_clip = DEM.rio.clip(AOI_UTM.geometry, 'EPSG:' + str(epsg_UTM))\n",
    "    # DEM_clip = xr.where(DEM_clip < 250, np.nan, DEM_clip)\n",
    "    elevations = np.ravel(DEM_clip.elevation.data)    \n",
    "    plt.hist(elevations)\n",
    "    plt.show()\n",
    "    \n",
    "    # iterate over snowline files\n",
    "    for snowline_fn in tqdm(snowline_fns):\n",
    "                        \n",
    "        # load snowline\n",
    "        try:\n",
    "            snowline = pd.read_csv(snowlines_path + snowline_fn)\n",
    "        except:\n",
    "            continue\n",
    "            \n",
    "        cols = snowline.columns.tolist()\n",
    "        # if 'ELA_from_AAR_m' in cols:\n",
    "        #     # print('column already exists, skipping...')\n",
    "        #     # print(' ')\n",
    "        #     continue\n",
    "\n",
    "        # calculate ELA from AAR\n",
    "        aar = snowline['AAR'].values[0]\n",
    "        ela_from_aar = np.nanquantile(elevations, 1 - aar)\n",
    "\n",
    "        # add to snowline dataframe\n",
    "        snowline['ELA_from_AAR_m'] = ela_from_aar\n",
    "\n",
    "        # remove any \"Unnamed\" columns\n",
    "        cols = snowline.columns.tolist()\n",
    "        cols = [x for x in cols if \"Unnamed\" not in x]\n",
    "        snowline = snowline[cols]\n",
    "                \n",
    "        # save to file\n",
    "        snowline.to_csv(snowlines_path + snowline_fn, index=False)\n",
    "        \n",
    "    print(' ')\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505fbd37-4f02-4d98-8743-1726d1c6d59c",
   "metadata": {},
   "source": [
    "### Plot snowlines and ELAs from AARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaa43e9-6d56-4738-91a8-56fafa0c59f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size':12, 'font.sans-serif':'Arial'})\n",
    "\n",
    "# iterate over site names\n",
    "for site_name in site_names:\n",
    "        \n",
    "    # define paths in directory\n",
    "    snowlines_path = study_sites_path + site_name + '/imagery/snowlines/'\n",
    "    \n",
    "    # load snowline and classified image file names\n",
    "    snowline_fns = [os.path.basename(x) for x in glob.glob(snowlines_path + '*.csv')]\n",
    "    \n",
    "    if len(snowline_fns) < 1:\n",
    "        continue\n",
    "    \n",
    "    # iterate over snowline files\n",
    "    snowlines = pd.DataFrame()\n",
    "    for snowline_fn in snowline_fns:\n",
    "                \n",
    "        # load snowline\n",
    "        try:\n",
    "            snowline = pd.read_csv(snowlines_path + snowline_fn)\n",
    "            snowlines = pd.concat([snowlines, snowline])\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    snowlines.reset_index(drop=True, inplace=True)\n",
    "    snowlines['datetime'] = pd.to_datetime(snowlines['datetime'], format='mixed')\n",
    "    \n",
    "    # plot\n",
    "    fig, ax = plt.subplots(1,1,figsize=(10,6))\n",
    "    ax.plot(snowlines['datetime'], snowlines['snowline_elevs_median_m'], '.m', label='from snowline')\n",
    "    ax.plot(snowlines['datetime'], snowlines['ELA_from_AAR_m'], 'xb', markersize=5, label='from AAR')\n",
    "    ax.grid()\n",
    "    ax.set_title(site_name)\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set_ylabel('Elevation [m]')\n",
    "    plt.show()\n",
    "    \n",
    "    # fig.savefig('ELAs_' + site_name + '.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28449afb-5677-4d60-b29e-a1bc248c4008",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
