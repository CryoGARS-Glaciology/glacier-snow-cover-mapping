{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fdf19a3-16b9-4c04-878c-6181b4ff7009",
   "metadata": {},
   "source": [
    "# Transform elevations from the ellipsoid to the EGM96 geoid vertical reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8b84da-a2ed-40fd-9586-ce43202ee6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pyproj\n",
    "import os\n",
    "import glob\n",
    "import rioxarray as rxr\n",
    "import sys\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyproj.crs import CompoundCRS\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely import wkt\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beae48a0-5310-4668-ad72-de73a3d56366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define paths in directory\n",
    "# path to study-sites\n",
    "study_sites_path = '/Users/raineyaberle/Google Drive/My Drive/Research/CryoGARS-Glaciology/Advising/student-research/Alexandra-Friel/snow_cover_mapping_application/study-sites/'\n",
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a210ea6-52f5-4f67-a42f-b101b5af9991",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Grab list of site names in study_sites_path\n",
    "site_names = sorted(os.listdir(study_sites_path))\n",
    "site_names = [x for x in site_names if not x.startswith('.')]\n",
    "# only include sites with snowlines\n",
    "site_names = [x for x in site_names if len(glob.glob(study_sites_path + x + '/imagery/snowlines/*.csv')) > 0]\n",
    "# only include sites with ArcticDEM geoid files\n",
    "site_names = [x for x in site_names if os.path.exists(study_sites_path + x + '/DEMs/' + x + '_ArcticDEM_clip_geoid.tif')]\n",
    "print(str(len(site_names)) + ' study sites:')\n",
    "site_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4824d65-60c5-488e-beb9-a54030616c09",
   "metadata": {},
   "source": [
    "## Transform elevations for snowlines that used ArcticDEM Mosaic or USGS DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3560ca9-458f-4e39-a7a8-5de2a4bd76a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Iterate over sites\n",
    "bgotus_site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry'] # BGOTUS\n",
    "    \n",
    "for site_name in site_names[8:9]:\n",
    "\n",
    "    print(site_name)\n",
    "\n",
    "    # load AOI\n",
    "    AOI_path = study_sites_path + site_name + '/AOIs/'\n",
    "    AOI_fn = glob.glob(AOI_path + '*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                        AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    # grab the optimal UTM zone EPSG code\n",
    "    epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "\n",
    "    # Check if AOI intersects with ArcticDEM coverage\n",
    "    intersects = arcticdem_coverage.geometry[0].intersects(AOI_WGS.to_crs('EPSG:'+str(arcticdem_coverage_crs)).geometry[0])\n",
    "    if (not intersects) and (site_name not in bgotus_site_names):\n",
    "        print('Outside ArcticDEM coverage and not BGOTUS, continuing... \\n\\n')\n",
    "        continue\n",
    "        \n",
    "    # Load DEM\n",
    "    DEM_path = os.path.join(study_sites_path, site_name, 'DEMs')\n",
    "    DEM_fn = glob.glob(DEM_path + '*.tif')[0]\n",
    "    \n",
    "\n",
    "    # load classified image and snowline file names\n",
    "    snowline_fns = sorted(glob.glob(study_sites_path + site_name + '/imagery/snowlines/*.csv'))\n",
    "    snowline_fns = [x for x in snowline_fns if '_adj' not in x]\n",
    "\n",
    "    # iterate over snowlines\n",
    "    for snowline_fn in tqdm(snowline_fns[0:10]):\n",
    "        \n",
    "        # define adjusted file name and check if it exists\n",
    "        snowline_adj_fn = snowline_fn[0:-3] + '_adj.csv'\n",
    "        if os.path.exists(snowline_adj_fn):\n",
    "            continue\n",
    "\n",
    "        # load snowline\n",
    "        try:\n",
    "            snowline = pd.read_csv(snowline_fn)  \n",
    "        except:\n",
    "            print('error opening ' + snowline_fn.split('/')[-1] + ', skipping...')\n",
    "            continue\n",
    "        \n",
    "        # skip if vertical reference already exists in attributes\n",
    "        if 'VerticalReference' in snowline.keys():\n",
    "            continue\n",
    "        \n",
    "        snowline_adj = snowline.to_crs('EPSG:4326') # reproject to WGS84 horizontal coordinates\n",
    "\n",
    "        \n",
    "        # Initialize an empty array for the transformed elevation data\n",
    "        # sl_elevs = snowline_adj['elevation'].data[0]  # Extract the elevation data as a NumPy array\n",
    "\n",
    "#         # Iterate through each point and transform the coordinates\n",
    "#         elevation_geoid = np.empty_like(elevation)\n",
    "#         lon, lat = im_classified['x'].values, im_classified['y'].values\n",
    "#         lon_mesh, lat_mesh = np.meshgrid(lon, lat)\n",
    "#         x, y, elevation_geoid = vertical_transformer.transform(lon_mesh, lat_mesh, elevation)\n",
    "#         elevation_geoid[elevation_geoid < 0] = np.nan\n",
    "\n",
    "#         im_classified['elevation'] = (('time', 'y', 'x'), [elevation_geoid]) # Replace the elevation data with the transformed data\n",
    "\n",
    "        # plot results\n",
    "        # fig, ax = plt.subplots(1, 3, figsize=(24,6))\n",
    "        # elev1 = ax[0].imshow(elevation, extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "        #                                         np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[0].set_title('Ellipsoid height')\n",
    "        # fig.colorbar(elev1, ax=ax[0], shrink=0.5, label='m.a.s.l.')\n",
    "        # elev2 = ax[1].imshow(im_classified.elevation.data[0], extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "        #                                                               np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[1].set_title('EGM96 height')\n",
    "        # fig.colorbar(elev2, ax=ax[1], shrink=0.5, label='m.a.s.l.')\n",
    "        # diff = ax[2].imshow(elevation - im_classified.elevation.data[0], cmap='Reds', \n",
    "        #                     extent=(np.min(im_classified.x.data), np.max(im_classified.x.data),\n",
    "        #                             np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[2].set_title('Difference')\n",
    "        # fig.colorbar(diff, ax=ax[2], shrink=0.5, label='meters')\n",
    "        # plt.show()\n",
    "\n",
    "        # adjust values from float to int for saving\n",
    "#         im_classified_adj = im_classified.classified.data.astype(float)\n",
    "#         im_classified_adj[im_classified_adj==0] = np.nan\n",
    "#         im_classified['classified'] = (('time', 'y', 'x'), im_classified_adj)\n",
    "#         im_classified = im_classified.fillna(-9999).astype(int)\n",
    "\n",
    "#         # define elevation source attribute\n",
    "#         if site_name in bgotus_site_names:\n",
    "#             elevation_source = \"USGS Benchmark Glacier Project: Most recent Digital Elevation Model available for site in the 2022 (Version 7.0) glacier-wide mass balance data release (https://doi.org/10.5066/F7HD7SRF)\"\n",
    "#         else:\n",
    "#             elevation_source = \"ArcticDEM Mosaic (https://developers.google.com/earth-engine/datasets/catalog/UMN_PGC_ArcticDEM_V3_2m_mosaic)\"\n",
    "\n",
    "#         # assign attributes\n",
    "#         im_classified = im_classified.assign_attrs({'Description': 'Classified image',\n",
    "#                                                     'Classes':'1 = Snow, 2 = Shadowed snow, 4 = Ice, 5 = Rock, 6 = Water',\n",
    "#                                                     'HorizontalReference': 'WGS84 (EPSG:4326)',\n",
    "#                                                     'VerticalReference': 'EGM96 height (EPSG:5773)',\n",
    "#                                                     'ElevationSource': elevation_source,\n",
    "#                                                     'NoDataValues': '-9999'\n",
    "#                                                    })\n",
    "#         # save to file\n",
    "#         im_classified.to_netcdf(im_classified_adj_fn, mode='w')\n",
    "#         # print('adjusted image saved to file: ' + im_classified_adj_fn)\n",
    "\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ad9e0b-6220-4314-afb7-399e667ca189",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEM_fn = glob.glob(DEM_path + '/*.tif')[0]\n",
    "DEM = xr.open_dataset(DEM_fn)\n",
    "elevation = DEM.band_data.data[0]\n",
    "DEM = DEM.drop_dims('band')\n",
    "DEM['elevation'] = (('y', 'x'), elevation)\n",
    "DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111680d2-9396-4a24-9f2f-51b9e74dde71",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(DEM.elevation.data, cmap='terrain', clim=(1000,3000),\n",
    "           extent=(np.min(DEM.x.data)/1e3, np.max(DEM.x.data)/1e3, np.min(DEM.y.data)/1e3, np.max(DEM.y.data)/1e3))\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d77d20-24b2-472f-82e5-4b9e9960510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "snowline = pd.read_csv(snowline_fns[10])\n",
    "snowline['geometry'] = snowline['geometry'].apply(wkt.loads)\n",
    "snowline_gdf = gpd.GeoDataFrame(snowline, geometry=snowline['geometry'], crs=snowline['CRS'][0])\n",
    "snowline_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be6ed76-0bcf-495f-8ebf-2c88553456de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reproject to WGS84 in geometry\n",
    "snowline_gdf = snowline_gdf.to_crs('EPSG:4326')\n",
    "\n",
    "# Initialize an empty array for the transformed elevation data\n",
    "# snowline_elevs = np.zeros(len(snowline['snowline_coords_X']))\n",
    "    \n",
    "# sample elevations from DEM at coordinates\n",
    "snowline_gdf['snowlines_coords_X'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b28790-f1af-4eab-b3b3-cd08c940cdfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a252efb3-0990-435d-aace-877afd78cb71",
   "metadata": {},
   "source": [
    "## Transform elevations for classified images that used ArcticDEM Mosaic or USGS DEMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f9016-f868-4b24-9650-b0d16e39f979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define source and target CRS\n",
    "src_crs = pyproj.CRS(4979)  # Define the source CRS (WGS 84 ellipsoid)\n",
    "target_crs = CompoundCRS(name=\"WGS 84 + EGM96 height\", components=[\"EPSG:4326\", \"EPSG:5773\"]) # Define the target CRS with EGM96 geoid as the vertical datum\n",
    "vertical_transformer = pyproj.Transformer.from_crs(src_crs, target_crs, always_xy=True) # Create a Pyproj Transformer object to perform the vertical transformation\n",
    "\n",
    "print('Source CRS:')\n",
    "print(str(src_crs))\n",
    "print(' ')\n",
    "print('Target CRS:')\n",
    "print(str(target_crs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bdcdd1-e6df-476a-8c6a-f384760eb9ea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Iterate over sites\n",
    "bgotus_site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry'] # BGOTUS\n",
    "    \n",
    "for site_name in site_names[20:]:\n",
    "\n",
    "    if site_name=='LemonCreek':\n",
    "        continue\n",
    "        \n",
    "    print(site_name)\n",
    "\n",
    "    # load AOI\n",
    "    AOI_path = study_sites_path + site_name + '/AOIs/'\n",
    "    AOI_fn = glob.glob(AOI_path + '*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                        AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    # grab the optimal UTM zone EPSG code\n",
    "    epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "\n",
    "    # Check if AOI intersects with ArcticDEM coverage\n",
    "    intersects = arcticdem_coverage.geometry[0].intersects(AOI_WGS.to_crs('EPSG:'+str(arcticdem_coverage_crs)).geometry[0])\n",
    "    if (not intersects) and (site_name not in bgotus_site_names):\n",
    "        print('Outside ArcticDEM coverage and not BGOTUS, continuing... \\n\\n')\n",
    "        continue\n",
    "\n",
    "    # load classified image and snowline file names\n",
    "    im_classified_fns = sorted(glob.glob(study_sites_path + site_name + '/imagery/classified/*.nc'))\n",
    "    im_classified_fns = [x for x in im_classified_fns if '_adj' not in x]\n",
    "\n",
    "    # iterate over classified images\n",
    "    for im_classified_fn in tqdm(im_classified_fns):\n",
    "        \n",
    "        # define adjusted file name and check if it exists\n",
    "        im_classified_adj_fn = im_classified_fn[0:-3] + '_adj.nc'\n",
    "        if os.path.exists(im_classified_adj_fn):\n",
    "            continue\n",
    "\n",
    "        # load classified image\n",
    "        try:\n",
    "            im_classified = xr.open_dataset(im_classified_fn)  \n",
    "        except:\n",
    "            print('error opening ' + im_classified_fn.split('/')[-1] + ', skipping...')\n",
    "            continue\n",
    "        \n",
    "        # skip if vertical reference already exists in attributes\n",
    "        if 'VerticalReference' in im_classified.attrs.keys():\n",
    "            continue\n",
    "        \n",
    "        im_classified = im_classified.rio.write_crs('EPSG:'+str(epsg_UTM))\n",
    "        im_classified = im_classified.rio.reproject('EPSG:4326') # reproject to WGS84 horizontal coordinates\n",
    "\n",
    "        # Initialize an empty array for the transformed elevation data\n",
    "        elevation = im_classified['elevation'].data[0]  # Extract the elevation data as a NumPy array\n",
    "\n",
    "        # Iterate through each point and transform the coordinates\n",
    "        elevation_geoid = np.empty_like(elevation)\n",
    "        lon, lat = im_classified['x'].values, im_classified['y'].values\n",
    "        lon_mesh, lat_mesh = np.meshgrid(lon, lat)\n",
    "        x, y, elevation_geoid = vertical_transformer.transform(lon_mesh, lat_mesh, elevation)\n",
    "        elevation_geoid[elevation_geoid < 0] = np.nan\n",
    "\n",
    "        im_classified['elevation'] = (('time', 'y', 'x'), [elevation_geoid]) # Replace the elevation data with the transformed data\n",
    "\n",
    "        # plot results\n",
    "        # fig, ax = plt.subplots(1, 3, figsize=(24,6))\n",
    "        # elev1 = ax[0].imshow(elevation, extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "        #                                         np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[0].set_title('Ellipsoid height')\n",
    "        # fig.colorbar(elev1, ax=ax[0], shrink=0.5, label='m.a.s.l.')\n",
    "        # elev2 = ax[1].imshow(im_classified.elevation.data[0], extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "        #                                                               np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[1].set_title('EGM96 height')\n",
    "        # fig.colorbar(elev2, ax=ax[1], shrink=0.5, label='m.a.s.l.')\n",
    "        # diff = ax[2].imshow(elevation - im_classified.elevation.data[0], cmap='Reds', \n",
    "        #                     extent=(np.min(im_classified.x.data), np.max(im_classified.x.data),\n",
    "        #                             np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "        # ax[2].set_title('Difference')\n",
    "        # fig.colorbar(diff, ax=ax[2], shrink=0.5, label='meters')\n",
    "        # plt.show()\n",
    "\n",
    "        # adjust values from float to int for saving\n",
    "        im_classified_adj = im_classified.classified.data.astype(float)\n",
    "        im_classified_adj[im_classified_adj==0] = np.nan\n",
    "        im_classified['classified'] = (('time', 'y', 'x'), im_classified_adj)\n",
    "        im_classified = im_classified.fillna(-9999).astype(int)\n",
    "\n",
    "        # define elevation source attribute\n",
    "        if site_name in bgotus_site_names:\n",
    "            elevation_source = \"USGS Benchmark Glacier Project: Most recent Digital Elevation Model available for site in the 2022 (Version 7.0) glacier-wide mass balance data release (https://doi.org/10.5066/F7HD7SRF)\"\n",
    "        else:\n",
    "            elevation_source = \"ArcticDEM Mosaic (https://developers.google.com/earth-engine/datasets/catalog/UMN_PGC_ArcticDEM_V3_2m_mosaic)\"\n",
    "\n",
    "        # assign attributes\n",
    "        im_classified = im_classified.assign_attrs({'Description': 'Classified image',\n",
    "                                                    'Classes':'1 = Snow, 2 = Shadowed snow, 4 = Ice, 5 = Rock, 6 = Water',\n",
    "                                                    'HorizontalReference': 'WGS84 (EPSG:4326)',\n",
    "                                                    'VerticalReference': 'EGM96 height (EPSG:5773)',\n",
    "                                                    'ElevationSource': elevation_source,\n",
    "                                                    'NoDataValues': '-9999'\n",
    "                                                   })\n",
    "        # save to file\n",
    "        im_classified.to_netcdf(im_classified_adj_fn, mode='w')\n",
    "        # print('adjusted image saved to file: ' + im_classified_adj_fn)\n",
    "\n",
    "    print(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b826f86-af2b-424a-9364-4bb183036e4b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "site_name = 'Wolverine'\n",
    "\n",
    "# load classified image and snowline file names\n",
    "im_classified_fns = sorted(glob.glob(study_sites_path + site_name + '/imagery/classified/*_adj.nc'))\n",
    "\n",
    "# iterate over classified images\n",
    "for im_classified_fn in im_classified_fns:\n",
    "\n",
    "    # load classified image\n",
    "    im_classified = xr.open_dataset(im_classified_fn)\n",
    "    im_classified = xr.where(im_classified==-9999, np.nan, im_classified)\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 2, figsize=(12,6))\n",
    "    ax[0].imshow(im_classified['classified'].data[0], clim=(0,5),\n",
    "                 extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "                         np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "    ax[1].imshow(im_classified['elevation'].data[0], cmap='terrain',\n",
    "                 extent=(np.min(im_classified.x.data), np.max(im_classified.x.data), \n",
    "                         np.min(im_classified.y.data), np.max(im_classified.y.data)))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737e75d-8b56-4d59-81e5-fa61b4735508",
   "metadata": {},
   "source": [
    "## For images that used NASADEM, reproject to WGS84 and add image attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d2b296-b03a-438e-9fda-045e2bf31e25",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "bgotus_site_names = ['Wolverine', 'Gulkana', 'LemonCreek', 'SouthCascade', 'Sperry'] # BGOTUS\n",
    "\n",
    "# Adjust classified images that use the NASADEM\n",
    "for i, site_name in enumerate(site_names):\n",
    "        \n",
    "    print(site_name)\n",
    "\n",
    "    # load AOI\n",
    "    AOI_path = study_sites_path + site_name + '/AOIs/'\n",
    "    AOI_fn = glob.glob(AOI_path + '*_outline.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "    AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                        AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "    # grab the optimal UTM zone EPSG code\n",
    "    epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "\n",
    "    # Check if AOI intersects with ArcticDEM coverage\n",
    "    intersects = arcticdem_coverage.geometry[0].intersects(AOI_WGS.to_crs('EPSG:'+str(arcticdem_coverage_crs)).geometry[0])\n",
    "    if intersects | (site_name in bgotus_site_names):\n",
    "        print('Not NASADEM site, continuing... \\n')\n",
    "        continue\n",
    "\n",
    "    # load classified image and snowline file names\n",
    "    im_classified_fns = sorted(glob.glob(study_sites_path + site_name + '/imagery/classified/*.nc'))\n",
    "    im_classified_fns = [x for x in im_classified_fns if '_adj' not in x]\n",
    "\n",
    "    # iterate over classified images\n",
    "    for im_classified_fn in tqdm(im_classified_fns):\n",
    "        \n",
    "        # define adjusted file name and check if it exists\n",
    "        im_classified_adj_fn = im_classified_fn[0:-3] + '_adj.nc'\n",
    "        if os.path.exists(im_classified_adj_fn):\n",
    "            continue\n",
    "            \n",
    "        try:\n",
    "            im_classified = xr.open_dataset(im_classified_fn) \n",
    "        except:\n",
    "            print('error with ' + im_classified_fn + ', skipping...')\n",
    "            continue\n",
    "        im_classified = im_classified.rio.write_crs('EPSG:'+str(epsg_UTM))\n",
    "        im_classified = im_classified.rio.reproject('EPSG:4326') # reproject to WGS84 horizontal coordinates\n",
    "        im_classified = xr.where(im_classified==0, -9999, im_classified)\n",
    "        im_classified = im_classified.rio.write_crs('EPSG:4326')\n",
    "\n",
    "        # assign attributes\n",
    "        elevation_source = 'NASADEM (https://developers.google.com/earth-engine/datasets/catalog/NASA_NASADEM_HGT_001)'\n",
    "        im_classified = im_classified.assign_attrs({'Description': 'Classified image',\n",
    "                                                    'Classes':'1 = Snow, 2 = Shadowed snow, 4 = Ice, 5 = Rock, 6 = Water',\n",
    "                                                    'HorizontalReference': 'WGS84 (EPSG:4326)',\n",
    "                                                    'VerticalReference': 'EGM96 height (EPSG:5773)',\n",
    "                                                    'ElevationSource': elevation_source,\n",
    "                                                    'NoDataValues': '-9999'\n",
    "                                                   })\n",
    "        \n",
    "        # save to file\n",
    "        im_classified.to_netcdf(im_classified_adj_fn, mode='w')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffdf037-9ad9-4d62-a7b4-840e85f9304e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sites with errors: \n",
    "# ['Emmons', 'Gulkana', 'LemonCreek', 'RGI60-01.08288', 'RGI60-01.08296', 'RGI60-02.04363', 'RGI60-02.06862', 'RGI60-02.12435']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a263481f-1648-48e0-814c-97297cc65d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_site_names = []\n",
    "for site_name in site_names:\n",
    "        \n",
    "    im_classified_path = study_sites_path + site_name + '/imagery/classified/'\n",
    "    im_classified_fns = [x for x in glob.glob(im_classified_path + '*.nc') if '_adj' not in x]\n",
    "    im_classified_adj_fns = glob.glob(im_classified_path + '*_adj.nc')\n",
    "    if len(im_classified_fns) != len(im_classified_adj_fns):\n",
    "        missing_site_names.append(site_name)\n",
    "\n",
    "print(missing_site_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85b479e-ce2d-49e1-8091-0d82f5efa195",
   "metadata": {},
   "source": [
    "## Delete non-adjusted classified images, rename adjusted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662ca949-e156-45b6-98d8-b137b6ec54a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "for site_name in site_names:\n",
    "    \n",
    "    print(site_name)\n",
    "    \n",
    "    im_classified_path = study_sites_path + site_name + '/imagery/classified/'\n",
    "    im_classified_fns = [x for x in glob.glob(im_classified_path + '*.nc') if '_adj' not in x]\n",
    "    im_classified_adj_fns = glob.glob(im_classified_path + '*_adj.nc')\n",
    "    \n",
    "    if (len(im_classified_fns) > 0) and (len(im_classified_adj_fns)>0):\n",
    "        for im_classified_fn in im_classified_fns:\n",
    "            os.remove(im_classified_fn)\n",
    "        \n",
    "    if len(im_classified_adj_fns) > 0:\n",
    "        \n",
    "        for im_classified_adj_fn in im_classified_adj_fns:\n",
    "            im_classified_adj_fn_new = im_classified_adj_fn.replace('_adj', '')\n",
    "            os.rename(im_classified_adj_fn, im_classified_adj_fn_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22de020-9872-4c37-ba64-a8f12aa5c302",
   "metadata": {},
   "source": [
    "## Remove elevation band from classified images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06ce285-1f0f-4ca2-9201-f8bd86c0e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Iterate over sites\n",
    "for site_name in site_names:\n",
    "        \n",
    "    print('\\n' + site_name)\n",
    "\n",
    "    # load classified image and snowline file names\n",
    "    im_classified_fns = sorted(glob.glob(study_sites_path + site_name + '/imagery/classified/*.nc'))\n",
    "    im_classified_fns = [x for x in im_classified_fns if '_adj' not in x]\n",
    "\n",
    "    # iterate over classified images\n",
    "    for im_classified_fn in tqdm(im_classified_fns):\n",
    "        \n",
    "        # skip if adjusted image already exists in file\n",
    "        im_classified_adj_fn = im_classified_fn[0:-3] + '_adj.nc'\n",
    "        if os.path.exists(im_classified_adj_fn):\n",
    "            continue\n",
    "\n",
    "        # load classified image\n",
    "        try:\n",
    "            im_classified = xr.open_dataset(im_classified_fn)  \n",
    "        except:\n",
    "            print('error opening ' + im_classified_fn.split('/')[-1] + ', skipping...')\n",
    "            continue\n",
    "            \n",
    "        # drop elevation band, edit attributes\n",
    "        im_classified_adj = im_classified.drop('elevation')\n",
    "        im_classified_adj.attrs = {'Description': 'Classified image',\n",
    "                               'Classes':'1 = Snow, 2 = Shadowed snow, 4 = Ice, 5 = Rock, 6 = Water',\n",
    "                               'HorizontalReference': 'WGS84 (EPSG:4326)',\n",
    "                               'NoDataValues': '-9999'\n",
    "                              }\n",
    "        \n",
    "        # resave classified image\n",
    "        im_classified_adj.to_netcdf(im_classified_adj_fn, mode='w')\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8de38f-d64c-445f-8632-6f137a7809b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
