{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce5d338c",
   "metadata": {},
   "source": [
    "# Try fixing image ID errors when querying from GEE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8979f4",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "\n",
    "#### Define paths in directory and desired settings. \n",
    "Modify lines located within the following:\n",
    "\n",
    "`#### MODIFY HERE ####`  \n",
    "\n",
    "`#####################`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183ca5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "\n",
    "# -----Paths in directory\n",
    "site_name = 'RGI60-01.00038'\n",
    "# path to snow-cover-mapping/ - Make sure you include a \"/\" at the end\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# path to folder containing AOI files\n",
    "AOI_path = '/Users/raineyaberle/Google Drive/My Drive/Research/PhD/snow_cover_mapping/study-sites/' + site_name + '/AOIs/'\n",
    "# AOI file name\n",
    "AOI_fn = site_name + '_outline.shp' \n",
    "# path to folder containing DEM raster file\n",
    "# Note: set DEM_fn=None if you want to use the ArcticDEM or ASTER GDEM via Google Earth Engine\n",
    "DEM_path = AOI_path + '../DEMs/'\n",
    "# DEM file name\n",
    "DEM_fn = None\n",
    "# path for output images\n",
    "out_path = AOI_path + '../imagery/'\n",
    "# path to PlanetScope images\n",
    "# Note: set PS_im_path=None if not using PlanetScope\n",
    "PS_im_path = out_path + 'PlanetScope/raw_images/'\n",
    "# path for output figures\n",
    "figures_out_path = AOI_path + '../figures/'\n",
    "\n",
    "# -----Define image search filters\n",
    "date_start = '2013-05-01'\n",
    "date_end = '2022-12-01'\n",
    "month_start = 5\n",
    "month_end = 10\n",
    "cloud_cover_max = 70\n",
    "\n",
    "# -----Determine whether to mask clouds using the respective cloud masking data products\n",
    "# NOTE: Cloud mask products anecdotally are less accurate over glacierized/snow-covered surfaces. \n",
    "# If the cloud masks are consistently masking large regions or your study site, I suggest setting mask_clouds = False\n",
    "mask_clouds = True\n",
    "\n",
    "# -----Determine image download, clipping & plotting settings\n",
    "# Note: if im_download = False, but images over the AOI exceed GEE limit,\n",
    "# images must be downloaded regardless.\n",
    "im_download = False  # = True to download all satellite images by default\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "skip_clipped = False # = True to skip images where bands appear \"clipped\", i.e. max(blue) < 0.8\n",
    "crop_to_AOI = True # = True to crop images to AOI before calculating SCA\n",
    "save_outputs = True # = True to save SCAs and snowlines to file\n",
    "save_figures = True # = True to save output figures to file\n",
    "\n",
    "#######################\n",
    "\n",
    "# -----Import packages\n",
    "import xarray as xr\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import matplotlib\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import sys\n",
    "import ee\n",
    "import geedim as gd\n",
    "import json\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import dump, load\n",
    "from shapely.geometry import MultiPolygon, Polygon\n",
    "\n",
    "# -----Set paths for output files\n",
    "S2_TOA_im_path = out_path + 'Sentinel-2_TOA/'\n",
    "S2_SR_im_path = out_path + 'Sentinel-2_SR/'\n",
    "L_im_path = out_path + 'Landsat/'\n",
    "PS_im_masked_path = out_path + 'PlanetScope/masked/'\n",
    "PS_im_mosaics_path = out_path + 'PlanetScope/mosaics/'\n",
    "im_classified_path = out_path + 'classified/'\n",
    "snowlines_path = out_path + 'snowlines/'\n",
    "\n",
    "# -----Add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f\n",
    "\n",
    "# -----Load dataset dictionary\n",
    "dataset_dict = json.load(open(base_path + 'inputs-outputs/datasets_characteristics.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaee83ad",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize Google Earth Engine (GEE). \n",
    "\n",
    "__Note:__ The first time you run the following cell, you will be asked to authenticate your GEE account for use in this notebook. This will send you to an external web page, where you will walk through the GEE authentication workflow and copy an authentication code back into the space below this cell when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176ec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize(opt_url='https://earthengine-highvolume.googleapis.com')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b83185",
   "metadata": {},
   "source": [
    "#### Load AOI and DEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959210a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load AOI as gpd.GeoDataFrame\n",
    "AOI = gpd.read_file(AOI_path + AOI_fn)\n",
    "# reproject the AOI to WGS to solve for the optimal UTM zone\n",
    "AOI_WGS = AOI.to_crs('EPSG:4326')\n",
    "AOI_WGS_centroid = [AOI_WGS.geometry[0].centroid.xy[0][0],\n",
    "                    AOI_WGS.geometry[0].centroid.xy[1][0]]\n",
    "# grab the optimal UTM zone EPSG code\n",
    "epsg_UTM = f.convert_wgs_to_utm(AOI_WGS_centroid[0], AOI_WGS_centroid[1])\n",
    "print('Optimal UTM CRS = EPSG:' + str(epsg_UTM))\n",
    "# reproject AOI to the optimal UTM zone\n",
    "AOI_UTM = AOI.to_crs('EPSG:'+epsg_UTM)\n",
    "\n",
    "# -----Load DEM as Xarray DataSet\n",
    "if DEM_fn is None:\n",
    "    # query GEE for DEM\n",
    "    DEM = f.query_gee_for_dem(AOI_UTM, base_path, site_name, DEM_path)\n",
    "else:\n",
    "    # load DEM as xarray DataSet\n",
    "    DEM = xr.open_dataset(DEM_path + DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "    # reproject the DEM to the optimal UTM zone\n",
    "    DEM = DEM.rio.reproject('EPSG:'+str(epsg_UTM))\n",
    "    DEM = DEM.rio.write_crs('EPSG:'+str(epsg_UTM))\n",
    "# remove unnecessary data (possible extra bands from ArcticDEM or other DEM)\n",
    "if len(np.shape(DEM.elevation.data))>2:\n",
    "    DEM['elevation'] = DEM.elevation[0]\n",
    "    DEM = xr.where(DEM < -100, np.nan, DEM)\n",
    "    DEM = DEM.rio.write_crs('EPSG:'+str(epsg_UTM))\n",
    "\n",
    "# -----Plot\n",
    "fig, ax = plt.subplots(1, 1, figsize=(6,6))\n",
    "dem_im = ax.imshow(DEM.elevation.data, cmap='terrain', \n",
    "          extent=(np.min(DEM.x.data)/1e3, np.max(DEM.x.data)/1e3, np.min(DEM.y.data)/1e3, np.max(DEM.y.data)/1e3))\n",
    "if type(AOI_UTM.geometry[0])==Polygon:\n",
    "    ax.plot([x/1e3 for x in AOI_UTM.geometry[0].exterior.coords.xy[0]],\n",
    "            [y/1e3 for y in AOI_UTM.geometry[0].exterior.coords.xy[1]], '-k')\n",
    "elif type(AOI_UTM.geometry[0])==MultiPolygon:\n",
    "    [ax.plot([x/1e3 for x in geom.exterior.coords.xy[0]],\n",
    "            [y/1e3 for y in geom.exterior.coords.xy[1]], '-k') for geom in AOI_UTM.geometry[0].geoms]\n",
    "ax.grid()\n",
    "ax.set_xlabel('Easting [km]')\n",
    "ax.set_ylabel('Northing [km]')\n",
    "fig.colorbar(dem_im, ax=ax, shrink=0.5, label='Elevation [m]')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10df07b",
   "metadata": {},
   "source": [
    "## 2. Sentinel-2 SR imagery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4c43f2-bfb1-4221-9ec1-d2224ea5a9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_start = '2022-05-15'\n",
    "# date_end = '2022-06-15'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7615f094",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Query GEE for imagery and download to S2_SR_im_path if necessary\n",
    "dataset = 'Sentinel-2_SR'\n",
    "im_col_gd = query_gee_for_imagery(dataset_dict, dataset, AOI_UTM, date_start, date_end, month_start, \n",
    "                                  month_end, cloud_cover_max, mask_clouds, S2_SR_im_path, im_download)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bbe1a5-a484-48ce-b78d-76c95377c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    properties = im_col_gd.properties\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    exc_id = str(e).split('ID=')[1].split(')')[0]\n",
    "    exc_date = exc_id[0:4] + '-' + exc_id[4:6] + '-' + exc_id[6:8]\n",
    "    print('Error accessing image ID: ' + exc_id)\n",
    "    print('Error image date: ' + exc_date) \n",
    "    print('Removing from collection...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a46c9fc-2aaa-4aa4-a95a-1673ba918c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare AOI for querying geedim (AOI bounding box)\n",
    "region = ee.Geometry.Polygon([[[AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                           [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                           [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                           [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                           [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]]\n",
    "                           ]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d1218e-ceef-4b96-8fa7-8ed27b4bc080",
   "metadata": {},
   "outputs": [],
   "source": [
    "im_col = (ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "          .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_cover_max))\n",
    "          .filterDate(ee.Date(date_start), ee.Date(date_end))\n",
    "          .filter(ee.Filter.calendarRange(5, 10, 'month'))\n",
    "          .filterBounds(region))\n",
    "im_ids = im_col.aggregate_array('system:id').getInfo()\n",
    "\n",
    "im_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d677d866",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Load trained classifier and feature columns\n",
    "clf_fn = base_path+'inputs-outputs/Sentinel-2_SR_classifier_all_sites.joblib'\n",
    "clf = load(clf_fn)\n",
    "feature_cols_fn = base_path+'inputs-outputs/Sentinel-2_SR_feature_columns.json'\n",
    "feature_cols = json.load(open(feature_cols_fn))\n",
    "\n",
    "# -----Loop through images\n",
    "if type(im_list)==str: # check that images were found\n",
    "    print('No images found to classify, quiting...')\n",
    "else:\n",
    "    \n",
    "    for i in tqdm(range(0, len(im_list))):\n",
    "        \n",
    "        # -----Subset image using loop index\n",
    "        im_xr = im_list[i]\n",
    "        im_date = str(im_xr.time.data[0])[0:19]\n",
    "        print(im_date)\n",
    "        \n",
    "        # -----Adjust image for image scalar and no data values\n",
    "        # replace no data values with NaN and account for image scalar\n",
    "        crs = im_xr.rio.crs.to_epsg()\n",
    "        if np.nanmean(im_xr['B2'])>1e3:\n",
    "            im_xr = xr.where(im_xr==dataset_dict[dataset]['no_data_value'], np.nan, \n",
    "                             im_xr / dataset_dict[dataset]['image_scalar'])\n",
    "        else:\n",
    "            im_xr = xr.where(im_xr==dataset_dict[dataset]['no_data_value'], np.nan, im_xr)\n",
    "        # add NDSI band\n",
    "        im_xr['NDSI'] = ((im_xr[dataset_dict[dataset]['NDSI_bands'][0]] - im_xr[dataset_dict[dataset]['NDSI_bands'][1]]) \n",
    "                             / (im_xr[dataset_dict[dataset]['NDSI_bands'][0]] + im_xr[dataset_dict[dataset]['NDSI_bands'][1]]))\n",
    "        im_xr.rio.write_crs('EPSG:'+str(crs), inplace=True)\n",
    "                \n",
    "        # -----Classify image\n",
    "        # check if classified image already exists in file\n",
    "        im_classified_fn = im_date.replace('-','').replace(':','') + '_' + site_name + '_' + dataset + '_classified.nc'\n",
    "        if os.path.exists(im_classified_path + im_classified_fn):\n",
    "            print('Classified image already exists in file, continuing...')\n",
    "            im_classified = xr.open_dataset(im_classified_path + im_classified_fn)\n",
    "            # remove no data values\n",
    "            im_classified = xr.where(im_classified==-9999, np.nan, im_classified)\n",
    "        else:  \n",
    "            # classify image\n",
    "            im_classified = f.classify_image(im_xr, clf, feature_cols, crop_to_AOI, AOI_UTM, DEM,\n",
    "                                             dataset_dict, dataset, im_classified_fn, im_classified_path)\n",
    "            if type(im_classified)==str: # skip if error in classification\n",
    "                continue\n",
    "        \n",
    "        # -----Delineate snowline(s)\n",
    "        # check if snowline already exists in file\n",
    "        snowline_fn = im_date.replace('-','').replace(':','') + '_' + site_name + '_' + dataset + '_snowline.csv'\n",
    "        if os.path.exists(snowlines_path + snowline_fn):\n",
    "            print('Snowline already exists in file, continuing...')\n",
    "            continue # no need to load snowline if it already exists\n",
    "        else:\n",
    "            plot_results = True\n",
    "            # create directory for figures if it doesn't already exist\n",
    "            if (not os.path.exists(figures_out_path)) & plot_results:\n",
    "                os.mkdir(figures_out_path)\n",
    "                print('Created directory for output figures: '+figures_out_path)\n",
    "            snowline_df = f.delineate_image_snowline(im_xr, im_classified, site_name, AOI_UTM, dataset_dict, dataset, \n",
    "                                                     im_date, snowline_fn, snowlines_path, figures_out_path, plot_results)\n",
    "            # plt.show()\n",
    "            print('Accumulation Area Ratio =  ' + str(snowline_df['AAR'][0]))\n",
    "        print(' ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snow-cover-mapping",
   "language": "python",
   "name": "snow-cover-mapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
