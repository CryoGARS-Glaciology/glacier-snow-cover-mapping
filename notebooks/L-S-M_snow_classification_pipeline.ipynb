{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba08359f-4f07-4197-b84f-9d82a17e5246",
   "metadata": {},
   "source": [
    "# Classify snow-covered area (SCA) in Landsat, Sentinel-2, and MODIS surface reflectance imagery: full pipeline\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "Department of Geosciences, Boise State University\n",
    "\n",
    "2022\n",
    "\n",
    "### Requirements:\n",
    "- Area of Interest (AOI) shapefile: where snow will be classified in all available images. \n",
    "- Google Earth Engine (GEE) account: used to pull DEM over the AOI. Sign up for a free account [here](https://earthengine.google.com/new_signup/). \n",
    "\n",
    "### Outline:\n",
    "__0. Setup__ paths in directory, AOI file location - _modify this section!_\n",
    "\n",
    "__1. Load images__ over the AOI since 2016. \n",
    "\n",
    "__2. Prepare image collections__ for classification: reprojection and image quality masking. \n",
    "\n",
    "__3. Classify SCA__ and use the snow elevations distribution to estimate the seasonal snowline\n",
    "\n",
    "-------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566a459b-0289-4488-953f-18f3c6462fff",
   "metadata": {},
   "source": [
    "### 0. Setup\n",
    "\n",
    "#### Define paths in directory and desired settings. \n",
    "Modify lines located within the following:\n",
    "\n",
    "`#### MODIFY HERE ####`  \n",
    "\n",
    "`#####################`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f331e9-ed10-4fa2-9b12-3ae384cbde17",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### MODIFY HERE #####\n",
    "# -----Path to planet-snow\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "\n",
    "# -----Paths in directory\n",
    "site_name = 'Wolverine'\n",
    "# path to AOI including the name of the shapefile\n",
    "AOI_fn = base_path+'../../GIS_data/RGI_outlines/'+site_name+'_RGI.shp'\n",
    "# path for output figures\n",
    "figures_out_path = base_path+'../study-sites/'+site_name+'/figures/SCA_Landsat/'\n",
    "\n",
    "# -----Define maximum cloud cover filter for image search\n",
    "cloud_cover_max = 10\n",
    "\n",
    "# -----Determine settings\n",
    "plot_results = True # = True to plot figures of results for each image where applicable\n",
    "crop_to_AOI = True # = True to crop images to AOI before calculating SCA\n",
    "save_outputs = True # = True to save SCA images to file\n",
    "save_figures = True # = True to save SCA output figures to file\n",
    "\n",
    "#######################\n",
    "\n",
    "# -----Import packages\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import wxee as wx\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "from osgeo import gdal\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.dates import DateFormatter\n",
    "from matplotlib.patches import Rectangle\n",
    "from matplotlib import pyplot as plt, dates\n",
    "import rasterio as rio\n",
    "import rasterio.features\n",
    "from rasterio.mask import mask\n",
    "from rasterio.plot import show\n",
    "from shapely.geometry import Polygon, shape\n",
    "import shapely.geometry\n",
    "from scipy.interpolate import interp2d\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geemap\n",
    "import math\n",
    "import sys\n",
    "import ee\n",
    "import fiona\n",
    "import pickle\n",
    "import wxee as wx\n",
    "import time\n",
    "\n",
    "# -----Add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import ps_pipeline_utils as f\n",
    "\n",
    "# -----Load AOI as geopandas.GeoDataFrame\n",
    "AOI = gpd.read_file(AOI_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d19dfe9-0e44-44e7-b54e-3bd2391b7729",
   "metadata": {},
   "source": [
    "#### Authenticate and initialize Google Earth Engine (GEE). \n",
    "\n",
    "__Note:__ The first time you run the following cell, you will be asked to authenticate your GEE account for use in this notebook. This will send you to an external web page, where you will walk through the GEE authentication workflow and copy an authentication code back in this notebook when prompted. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f87c0f-9ba4-4f34-8700-a23187894509",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ee.Initialize()\n",
    "except: \n",
    "    ee.Authenticate()\n",
    "    ee.Initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58403e13-eeb8-4413-b59a-11ef83557d99",
   "metadata": {},
   "source": [
    "### 1. Load images over the AOI since 2016\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508420d8-5764-473a-b94e-38208eafda65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Reformat AOI for clipping images\n",
    "# reproject AOI to WGS 84 for compatibility with images\n",
    "AOI_WGS = AOI.to_crs(4326)\n",
    "# reformat AOI_WGS bounding box as ee.Geometry for clipping DEM\n",
    "AOI_WGS_bb_ee = ee.Geometry.Polygon(\n",
    "                        [[[AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                          [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.miny[0]],\n",
    "                          [AOI_WGS.geometry.bounds.maxx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                          [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.maxy[0]],\n",
    "                          [AOI_WGS.geometry.bounds.minx[0], AOI_WGS.geometry.bounds.miny[0]]]\n",
    "                        ])\n",
    "\n",
    "# -----Define start and end dates and months\n",
    "date_range_start = '2022-01-01'\n",
    "date_range_end = '2022-12-01'\n",
    "month_start = 5\n",
    "month_end = 10\n",
    "\n",
    "# -----Query GEE for Landsat, Sentinel, and MODIS imagery\n",
    "L_col = (ee.ImageCollection(\"LANDSAT/LC08/C02/T1_L2\")\n",
    "         .filter(ee.Filter.lt(\"CLOUD_COVER\", cloud_cover_max))\n",
    "         .filterDate(ee.Date(date_range_start), ee.Date(date_range_end))\n",
    "         .filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "         .filterBounds(AOI_WGS_bb_ee))\n",
    "S_col = (ee.ImageCollection(\"COPERNICUS/S2_SR\")\n",
    "         .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', cloud_cover_max))\n",
    "         .filterDate(ee.Date(date_range_start), ee.Date(date_range_end))\n",
    "         .filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "         .filterBounds(AOI_WGS_bb_ee))\n",
    "M_col = (ee.ImageCollection(\"MODIS/061/MOD09GA\").merge(ee.ImageCollection(\"MODIS/061/MYD09GA\"))\n",
    "         .filterDate(ee.Date(date_range_start), ee.Date(date_range_end))\n",
    "         .filter(ee.Filter.calendarRange(month_start, month_end, 'month'))\n",
    "         .filterBounds(AOI_WGS_bb_ee))\n",
    "\n",
    "# -----Clip images to AOI and select bands\n",
    "L_band_names = ['SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B6', 'SR_B7']\n",
    "S_band_names = ['B2', 'B3', 'B4', 'B5', 'B6', 'B8', 'B11', 'B12']\n",
    "M_band_names = ['sur_refl_'+x for x in ['b01', 'b04', 'b03', 'b05', 'b06', 'b07']]\n",
    "def clip_image(im):\n",
    "    return im.clip(AOI_WGS_bb_ee.buffer(2000))\n",
    "L_col_clip = L_col.map(clip_image).select(L_band_names + ['QA_PIXEL'])\n",
    "S_col_clip = S_col.map(clip_image).select(S_band_names + ['QA60'])\n",
    "M_col_clip = M_col.map(clip_image).select(M_band_names + ['state_1km'])\n",
    "\n",
    "# -----Convert image collections to xarray Datasets\n",
    "print('Landsat image collection:')\n",
    "L_col_xr = L_col_clip.wx.to_xarray(scale=30, crs='EPSG:4326')\n",
    "print('Sentinel-2 image collection:')\n",
    "S_col_xr = S_col_clip.wx.to_xarray(scale=20, crs='EPSG:4326')\n",
    "print('MODIS image collection:')\n",
    "M_col_xr = M_col_clip.wx.to_xarray(scale=500, crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3bec14-1758-4232-8ab8-a70edf0c6441",
   "metadata": {},
   "source": [
    "### 2. Prepare image collections for classification: reproject images collections to UTM and apply quality masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7dd8f4-9e30-4a8e-baa5-324a857ca97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Reproject image collections to UTM\n",
    "# Determine optimal UTM zone \n",
    "epsg_code = f.convert_wgs_to_utm((AOI_WGS.geometry.bounds.maxx[0] - AOI_WGS.geometry.bounds.minx[0]) + AOI_WGS.geometry.bounds.minx[0],\n",
    "                                 (AOI_WGS.geometry.bounds.maxy[0] - AOI_WGS.geometry.bounds.miny[0]) + AOI_WGS.geometry.bounds.miny[0])\n",
    "# Reproject using rasterio.reproject\n",
    "L_col_xr_UTM = L_col_xr.rio.reproject(\"EPSG:\"+epsg_code)\n",
    "S_col_xr_UTM = S_col_xr.rio.reproject(\"EPSG:\"+epsg_code)\n",
    "M_col_xr_UTM = M_col_xr.rio.reproject(\"EPSG:\"+epsg_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a979b36-2b7b-4957-bc1c-d2422fdd21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Apply image quality masking to Landsat and Sentinel imagery\n",
    "# Landsat\n",
    "# Pixel quality band = \"QA_PIXEL\"\n",
    "# Bit 3 = cloud shadow, Bit 5 = cloud\n",
    "# def L8_QA_mask(im):\n",
    "#     cloudShadowBitMask = 1 << 3\n",
    "#     cloudsBitMask = 1 << 5;\n",
    "#     # Get the pixel QA band.\n",
    "#     qa = im.select('QA_PIXEL')\n",
    "#     # Both flags should be set to zero, indicating clear conditions.\n",
    "#     mask = (qa.bitwiseAnd(cloudShadowBitMask).eq(0) & (qa.bitwiseAnd(cloudsBitMask).eq(0)))\n",
    "#     # Return the masked image without the QA bands.\n",
    "#     return (\n",
    "#         image.updateMask(mask)\n",
    "#         .select(\"SR_B[0-9]*\")\n",
    "#         .copyProperties(image, [\"system:time_start\"])\n",
    "#     )\n",
    "\n",
    "# L_col_clip_mask = L_col_clip.map(L8_QA_mask)\n",
    "\n",
    "\n",
    "#   // Sentinel-2 image quality masking\n",
    "#   function S2QAMask(image){\n",
    "#     var QA60 = image.select(['QA60']);\n",
    "#     return image.updateMask(QA60.lt(1));\n",
    "#   }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74573ecd-cd7b-44f8-8083-bfda3ef184c9",
   "metadata": {},
   "source": [
    "### 3. Classify SCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42134ce3-8be3-4b1b-a988-42f3eef8ded6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start timer\n",
    "# t1 = time.time()\n",
    "\n",
    "# -----Load image classifiers and feature columns\n",
    "# Landsat\n",
    "L_clf_fn = base_path+'inputs-outputs/L_classifier_all_sites.sav'\n",
    "L_clf = pickle.load(open(L_clf_fn, 'rb'))\n",
    "L_feature_cols_fn = base_path+'inputs-outputs/L_feature_cols.pkl'\n",
    "L_feature_cols = pickle.load(open(L_feature_cols_fn,'rb'))\n",
    "# Sentinel-2\n",
    "S_clf_fn = base_path+'inputs-outputs/S2_classifier_all_sites.sav'\n",
    "S_clf = pickle.load(open(S_clf_fn, 'rb'))\n",
    "S_feature_cols_fn = base_path+'inputs-outputs/S2_feature_cols.pkl'\n",
    "S_feature_cols = pickle.load(open(S_feature_cols_fn,'rb'))\n",
    "# MODIS\n",
    "M_clf_fn = base_path+'inputs-outputs/M_classifier_all_sites.sav'\n",
    "M_clf = pickle.load(open(M_clf_fn, 'rb'))\n",
    "M_feature_cols_fn = base_path+'inputs-outputs/M_feature_cols.pkl'\n",
    "M_feature_cols = pickle.load(open(M_feature_cols_fn,'rb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8c3ed2-5163-474e-b94e-6a2663e652a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Classify snow\n",
    "# Landsat\n",
    "for date in L_col_xr.time.data:\n",
    "    # create data frame to store pixel values\n",
    "    L_df = pd.DataFrame(columns=L_band_names+['NDSI'])\n",
    "    # extract pixel values\n",
    "    for band in L_band_names:\n",
    "        L_df[band] = L_col_xr.sel(time=date)[band].data.flatten()\n",
    "    # find indices of rows without NaN\n",
    "    I_real = np.where(pd.isnull(L_df).any(1)==False)[0]\n",
    "    # drop rows with NaN\n",
    "    L_df = L_df.dropna().reset_index(drop=True)\n",
    "    # calculate NDSI (G-SWIR)/(G+SWIR)\n",
    "    L_df['NDSI'] = (L_df['SR_B3'] -  L_df['SR_B6']) / (L_df['SR_B3'] +  L_df['SR_B6'])\n",
    "    \n",
    "    # classify SCA\n",
    "    array_classified = L_clf.predict(L_df[L_feature_cols])\n",
    "    \n",
    "    # reshape from flat array to original shape\n",
    "    im_classified = np.zeros((np.shape(L_col_xr['SR_B3'].sel(time=date).data)[0], np.shape(L_col_xr['SR_B3'].sel(time=date).data)[1]))\n",
    "    im_classified[:] = np.nan\n",
    "    im_classified[I_real] = array_classified\n",
    "    \n",
    "    # plot classified image\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12,6))\n",
    "    plt.rcParams.update({'font.size': 14, 'font.sans-serif': 'Arial'})\n",
    "    # define x and y limits\n",
    "    xmin, xmax = np.min(L_col_xr.sel(time=date).x.data)/1000, np.max(L_col_xr.sel(time=date).x.data)/1000\n",
    "    ymin, ymax = np.min(L_col_xr.sel(time=date).y.data)/1000, np.max(L_col_xr.sel(time=date).y.data)/1000\n",
    "    # RGB image\n",
    "    ax1.imshow(np.dstack([L_col_xr['SR_B4'].sel(time=date), L_col_xr['SR_B3'].sel(time=date), L_col_xr['SR_B2'].sel(time=date)]), \n",
    "               extent=(xmin, xmax, ymin, ymax))\n",
    "    ax1.set_xlabel(\"Easting [km]\")\n",
    "    ax1.set_ylabel(\"Northing [km]\")\n",
    "    # define colors for plotting\n",
    "    color_snow = '#4eb3d3'\n",
    "    color_ice = '#084081'\n",
    "    color_rock = '#fdbb84'\n",
    "    color_water = '#bdbdbd'\n",
    "    # snow\n",
    "    if any(im_classified.flatten()==1):\n",
    "        ax2.imshow(np.where(im_classified == 1, 1, np.nan), cmap=matplotlib.colors.ListedColormap([color_snow, 'white']),\n",
    "                    extent=(xmin, xmax, ymin, ymax))\n",
    "        ax2.scatter(0, 0, color=color_snow, s=50, label='snow') # plot dummy point for legend\n",
    "    if any(im_classified.flatten()==2):\n",
    "        ax2.imshow(np.where(im_classified == 2, 4, np.nan), cmap=matplotlib.colors.ListedColormap([color_snow, 'white']),\n",
    "                    extent=(xmin, xmax, ymin, ymax))\n",
    "    # ice\n",
    "    if any(im_classified.flatten()==3):\n",
    "        ax2.imshow(np.where(im_classified == 3, 1, np.nan), cmap=matplotlib.colors.ListedColormap([color_ice, 'white']),\n",
    "                    extent=(xmin, xmax, ymin, ymax))\n",
    "        ax2.scatter(0, 0, color=color_ice, s=50, label='ice') # plot dummy point for legend\n",
    "    # rock/debris\n",
    "    if any(im_classified.flatten()==4):\n",
    "        ax2.imshow(np.where(im_classified == 4, 1, np.nan), cmap=matplotlib.colors.ListedColormap([color_rock, 'white']),\n",
    "                    extent=(xmin, xmax, ymin, ymax))\n",
    "        ax2.scatter(0, 0, color=color_rock, s=50, label='rock') # plot dummy point for legend\n",
    "    # water\n",
    "    if any(im_classified.flatten()==5):\n",
    "        ax2.imshow(np.where(im_classified == 5, 10, np.nan), cmap=matplotlib.colors.ListedColormap([color_water, 'white']),\n",
    "                    extent=(xmin, xmax, ymin, ymax))\n",
    "        ax2.scatter(0, 0, color=color_water, s=50, label='water') # plot\n",
    "    ax2.set_xlim(xmin, xmax)\n",
    "    ax2.set_ylim(ymin, ymax)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27640d3a-b22a-48bf-8a66-d6985fd3dd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data frame to store pixel values\n",
    "L_df = pd.DataFrame(columns=L_band_names+['NDSI'])\n",
    "# extract pixel values\n",
    "for band in L_band_names:\n",
    "    L_df[band] = L_col_xr.sel(time=date)[band].data.flatten()\n",
    "L_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaedf36-81a9-4329-8bdb-07d319932ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
