{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9025527",
   "metadata": {},
   "source": [
    "# Notebook to adjust radiometry of Planet images using snow-covered pixels and dark areas\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "Spring 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ddee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "from shapely.geometry import Polygon\n",
    "from scipy.interpolate import interp2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a17aef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Determine whether to save output images\n",
    "save_images = True # = True to save adjusted raster image files in out_path\n",
    "save_figures = True # = True to save output figures to figures_out_path\n",
    "\n",
    "# ----Define ID for study site (used in output file names)\n",
    "site_ID = 'GG'\n",
    "\n",
    "# -----Define paths in directory\n",
    "# path to Planet images\n",
    "im_path = '/Users/raineyaberle/Research/PhD/study-sites/Gulkana/imagery/2021-04-01_2021-10-01/PSScene4Band/'\n",
    "# output path for adjusted images\n",
    "out_path = im_path+'../filtered-adjusted-radiometry/'\n",
    "# output path for figures\n",
    "figures_out_path = im_path+'../../../figures/filtered-adjusted-radiometry/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c1e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Load Planet image and metadata file names from directory\n",
    "ims = os.chdir(im_path) # change directory\n",
    "im_names = glob.glob('*SR_clip.tif') # load all .tif file names\n",
    "im_names.sort() # sort file names by date\n",
    "meta_names = glob.glob('*metadata_clip.xml') # load metadata file names\n",
    "meta_names.sort() # sort file names by date\n",
    "\n",
    "# ----Create output folders if they do not exist\n",
    "if os.path.isdir(out_path)==0:\n",
    "    os.mkdir(out_path)\n",
    "    print(out_path+' directory made')\n",
    "if os.path.isdir(figures_out_path)==0:\n",
    "    os.mkdir(figures_out_path)\n",
    "    print(figures_out_path+' directory made')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4acdff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----Define 'bright' area to use for image radiometric adjustment\n",
    "\n",
    "# define minx, maxx, miny, and maxy for bright area\n",
    "# Wolverine\n",
    "# bright_minx, bright_maxx, bright_miny, bright_maxy = 393.5e3, 396.5e3, 6699.2e3, 6700.5e3\n",
    "# Gulkana\n",
    "bright_minx, bright_maxx, bright_miny, bright_maxy = 576.5e3, 577.6e3, 7017.4e3, 7018.1e3\n",
    "\n",
    "# create Shapely Polygon of bright area\n",
    "bright_poly = Polygon([[bright_minx, bright_miny], \n",
    "                       [bright_maxx, bright_miny], \n",
    "                       [bright_maxx, bright_maxy],\n",
    "                       [bright_minx, bright_maxy],\n",
    "                       [bright_minx, bright_miny]])\n",
    "\n",
    "# load one image to plot points\n",
    "im = rio.open(im_names[3])\n",
    "# define bands (blue, green, red, near infrared)\n",
    "im_scalar = 10000 # scalar multiplier for image reflectance values\n",
    "b = im.read(1).astype(float) / im_scalar \n",
    "g = im.read(2).astype(float) / im_scalar \n",
    "r = im.read(3).astype(float) / im_scalar \n",
    "nir = im.read(4).astype(float) / im_scalar  \n",
    "# define coordinates grid\n",
    "x = np.linspace(im.bounds.left, im.bounds.right, num=np.shape(b)[1])\n",
    "y = np.linspace(im.bounds.top, im.bounds.bottom, num=np.shape(b)[0])\n",
    "# plot image with bright and dark points\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.rcParams.update({'font.size': 12, 'font.serif': 'Arial'})\n",
    "plt.imshow(np.dstack([r, g, b]), extent=(np.min(x)/1000, np.max(x)/1000, np.min(y)/1000, np.max(y)/1000))\n",
    "plt.plot([x/1000 for x in bright_poly.exterior.xy[0]], [y/1000 for y in bright_poly.exterior.xy[1]],\n",
    "         color='black', linewidth=2, label='SCA')\n",
    "plt.xlabel('Easting [km]')\n",
    "plt.ylabel('Northing [km]')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09de833e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# -----Apply radiometric correction by 'stretching' image to bright and darkest points\n",
    "\n",
    "# Define desired SR values at the bright area and darkest point for each band\n",
    "# bright area\n",
    "bright_b_adj = 0.94\n",
    "bright_g_adj = 0.95\n",
    "bright_r_adj = 0.94\n",
    "bright_nir_adj = 0.78\n",
    "# dark point\n",
    "dark_adj = 0.0\n",
    "\n",
    "# maximum cloud cover (skips image if cloud cover exceed max cloud cover)\n",
    "max_cloud_cover = 20.0\n",
    "\n",
    "# Loop through images\n",
    "y_count = 0\n",
    "n_count = 0\n",
    "instrument = []\n",
    "cloud_cover = []\n",
    "for im_name in im_names:\n",
    "    \n",
    "    # load image\n",
    "    im = rio.open(im_name)\n",
    "    \n",
    "    # define bands (blue, green, red, near infrared)\n",
    "    im_scalar = 10000 # scalar multiplier for image reflectance values\n",
    "    b = im.read(1).astype(float) / im_scalar \n",
    "    g = im.read(2).astype(float) / im_scalar \n",
    "    r = im.read(3).astype(float) / im_scalar \n",
    "    nir = im.read(4).astype(float) / im_scalar  \n",
    "    \n",
    "    # define coordinates grid\n",
    "    x = np.linspace(im.bounds.left, im.bounds.right, num=np.shape(b)[1])\n",
    "    y = np.linspace(im.bounds.top, im.bounds.bottom, num=np.shape(b)[0])\n",
    "\n",
    "    # check if image contains bright area\n",
    "    if ((np.min(bright_poly.exterior.xy[0])>np.min(x)) \n",
    "        & (np.max(bright_poly.exterior.xy[0])<np.max(x)) \n",
    "        & (np.min(bright_poly.exterior.xy[1])>np.min(y)) \n",
    "        & (np.max(bright_poly.exterior.xy[1])<np.max(y))):\n",
    "        \n",
    "        y_count+=1 # increase counter for adjusted images\n",
    "    \n",
    "        # create vectors of image points that fall within the bright area\n",
    "        x_pts = x[(x>bright_minx) & (x<bright_maxx)]\n",
    "        y_pts = y[(y>bright_miny) & (y<bright_maxy)]\n",
    "        \n",
    "        # check that values are greater than zero at the bright area and dark point\n",
    "        f_b = interp2d(x, y, b)\n",
    "        if (np.median(f_b(x_pts, y_pts))>0) & (~np.isnan(np.median(f_b(x_pts, y_pts)))):\n",
    "        \n",
    "            # filter images with clipped green and blue bands\n",
    "            \n",
    "            \n",
    "            # load instrument name and cloud cover percentage from metadata\n",
    "            for meta_name in meta_names:\n",
    "                if im_name[0:24] in meta_name:\n",
    "                    # open the sample file used\n",
    "                    meta = open(meta_name)\n",
    "                    # read the content of the file opened\n",
    "                    meta_content = meta.readlines()\n",
    "                    # read instrument name from the file\n",
    "                    inst = meta_content[53].split('>')[1]\n",
    "                    if \"PS2\" in inst:\n",
    "                        inst = inst[0:3]\n",
    "                    elif \"PSB\" in inst:\n",
    "                        inst = inst[0:6]\n",
    "                    instrument = instrument + [inst]\n",
    "                    # read cloud cover percentage from the file\n",
    "                    cc = meta_content[148].split('>')[1]\n",
    "                    cc = cc.split('<')[0]\n",
    "                    cc = float(cc)\n",
    "                    cloud_cover = cloud_cover + [cc]\n",
    "    \n",
    "            # continue to next iteration if cloud cover is above 20%\n",
    "            if cc > max_cloud_cover:\n",
    "                continue\n",
    "            \n",
    "            # adjust SR using bright and dark points\n",
    "            # band_adjusted = band*A - B\n",
    "            # A = (bright_adjusted - dark_adjusted) / (bright - dark)\n",
    "            # B = (dark*bright_adjusted - bright*dark_adjusted) / (bright - dark)\n",
    "            # blue band\n",
    "            bright_b = np.median(f_b(x_pts, y_pts)) # SR at bright point\n",
    "            dark_b = np.min(b) # SR at darkest point\n",
    "            A = (bright_b_adj - dark_adj) / (bright_b - dark_b)\n",
    "            B = (dark_b*bright_b_adj - bright_b*dark_adj) / (bright_b - dark_b)\n",
    "            b_adj = (b * A) - B\n",
    "            b_adj = np.where(b==0, np.nan, b_adj) # replace no data values with nan\n",
    "            # green band\n",
    "            f_g = interp2d(x, y, g)\n",
    "            bright_g = np.median(f_g(x_pts, y_pts)) # SR at bright point\n",
    "            dark_g = np.min(g) # SR at darkest point\n",
    "            A = (bright_g_adj - dark_adj) / (bright_g - dark_g)\n",
    "            B = (dark_g*bright_g_adj - bright_g*dark_adj) / (bright_g - dark_g)\n",
    "            g_adj = (g * A) - B\n",
    "            g_adj = np.where(g==0, np.nan, g_adj) # replace no data values with nan\n",
    "            # red band\n",
    "            f_r = interp2d(x, y, r)\n",
    "            bright_r = np.median(f_r(x_pts, y_pts)) # SR at bright point\n",
    "            dark_r = np.min(r) # SR at darkest point\n",
    "            A = (bright_r_adj - dark_adj) / (bright_r - dark_r)\n",
    "            B = (dark_r*bright_r_adj - bright_r*dark_adj) / (bright_r - dark_r)\n",
    "            r_adj = (r * A) - B\n",
    "            r_adj = np.where(r==0, np.nan, r_adj) # replace no data values with nan\n",
    "            # nir band\n",
    "            f_nir = interp2d(x, y, nir)\n",
    "            bright_nir = np.median(f_nir(x_pts, y_pts)) # SR at bright point\n",
    "            dark_nir = np.min(nir) # SR at darkest point\n",
    "            A = (bright_nir_adj - dark_adj) / (bright_nir - dark_nir)\n",
    "            B = (dark_nir*bright_nir_adj - bright_nir*dark_adj) / (bright_nir - dark_nir)\n",
    "            nir_adj = (nir * A) - B\n",
    "            nir_adj = np.where(nir==0, np.nan, nir_adj) # replace no data values with nan\n",
    "\n",
    "            # print new values at the bright and dark points to check for success\n",
    "    #         f_b_adj = interp2d(x, y, b_adj)\n",
    "    #         f_g_adj = interp2d(x, y, g_adj)\n",
    "    #         f_r_adj = interp2d(x, y, r_adj)\n",
    "    #         f_nir_adj = interp2d(x, y, nir_adj)\n",
    "    #         print('    blue:',f_b_adj(bright_pt[0], bright_pt[1]))\n",
    "    #         print('    green:',f_g_adj(bright_pt[0], bright_pt[1]))\n",
    "    #         print('    red:',f_r_adj(bright_pt[0], bright_pt[1]))\n",
    "    #         print('    nir:',f_nir_adj(bright_pt[0], bright_pt[1]))\n",
    "                    \n",
    "            # plot results\n",
    "            fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2,2,figsize=(16,10),gridspec_kw={'height_ratios': [3,1]})\n",
    "            plt.rcParams.update({'font.size': 12, 'font.serif': 'Arial'})\n",
    "            # original image\n",
    "            im_original = ax1.imshow(np.dstack([r, g, b]), \n",
    "                        extent=(np.min(x)/1000, np.max(x)/1000, np.min(y)/1000, np.max(y)/1000))\n",
    "            ax1.plot([x/1000 for x in bright_poly.exterior.xy[0]], [y/1000 for y in bright_poly.exterior.xy[1]],\n",
    "                     color='black', linewidth=2, label='SCA')\n",
    "            ax1.legend()\n",
    "            ax1.set_xlabel('Easting [km]')\n",
    "            ax1.set_ylabel('Northing [km]')\n",
    "            ax1.set_title('Original image')\n",
    "            # adjusted image\n",
    "            im_adjusted = ax2.imshow(np.dstack([r_adj, g_adj, b_adj]), \n",
    "                        extent=(np.min(x)/1000, np.max(x)/1000, np.min(y)/1000, np.max(y)/1000))\n",
    "            ax2.plot([x/1000 for x in bright_poly.exterior.xy[0]], [y/1000 for y in bright_poly.exterior.xy[1]],\n",
    "                     color='black', linewidth=2, label='SCA')\n",
    "            ax2.set_xlabel('Easting [km]')\n",
    "            ax2.set_title('Adjusted image')\n",
    "            # histograms\n",
    "            h1_nir = ax3.hist(nir.flatten(), color='purple', bins=100, alpha=0.5, label='NIR')\n",
    "            h1_b = ax3.hist(b.flatten(), color='blue', bins=100, alpha=0.5, label='blue')\n",
    "            h1_g = ax3.hist(g.flatten(), color='green', bins=100, alpha=0.5, label='green')\n",
    "            h1_r = ax3.hist(r.flatten(), color='red', bins=100, alpha=0.5, label='red')\n",
    "            ax3.set_xlabel('Surface reflectance')\n",
    "            ax3.set_ylabel('Pixel counts')\n",
    "            ax3.grid()\n",
    "            ax3.legend(loc='right')\n",
    "            ax3.set_ylim(0,np.max([h1_nir[0][1:], h1_g[0][1:], h1_r[0][1:], h1_b[0][1:]])+5000)\n",
    "            h2_nir = ax4.hist(nir_adj.flatten(), color='purple', bins=100, alpha=0.5, label='NIR')\n",
    "            h2_b = ax4.hist(b_adj.flatten(), color='blue', bins=100, alpha=0.5, label='blue')\n",
    "            h2_g = ax4.hist(g_adj.flatten(), color='green', bins=100, alpha=0.5, label='green')\n",
    "            h2_r = ax4.hist(r_adj.flatten(), color='red', bins=100, alpha=0.5, label='red')\n",
    "            ax4.set_xlabel('Surface reflectance')\n",
    "            ax4.set_ylim(0,np.max([h1_nir[0][1:], h1_g[0][1:], h1_r[0][1:], h1_b[0][1:]])+5000)\n",
    "            ax4.grid()\n",
    "            fig.suptitle(im_name[0:8]+' '+im_name[9:11]+':'+im_name[11:13]+':'+im_name[13:15]+', Inst: '+inst)\n",
    "            fig.tight_layout()\n",
    "            plt.show() \n",
    "\n",
    "            # save adjusted raster to file\n",
    "            if save_images==True:\n",
    "                # file name\n",
    "                fn = im_name[0:-4]+'_'+inst+'_adj.tif'\n",
    "                # metadata\n",
    "                out_meta = im.meta.copy()\n",
    "                out_meta.update({'driver':'GTiff',\n",
    "                                 'width':b_adj.shape[1],\n",
    "                                 'height':b_adj.shape[0],\n",
    "                                 'count':4,\n",
    "                                 'dtype':'float64',\n",
    "                                 'crs':im.crs, \n",
    "                                 'transform':im.transform})\n",
    "                # write to file\n",
    "                with rio.open(out_path+fn, mode='w',**out_meta) as dst:\n",
    "                    dst.write_band(1,b_adj)\n",
    "                    dst.write_band(2,g_adj)\n",
    "                    dst.write_band(3,r_adj)\n",
    "                    dst.write_band(4,nir_adj)\n",
    "                print('adjusted image saved to file')\n",
    "\n",
    "            # save output figure to file\n",
    "            if save_figures==True:\n",
    "                # file name\n",
    "                fn = site_ID+'_'+im_name[0:8]+'_adj.png'\n",
    "                # save\n",
    "                fig.savefig(figures_out_path+fn, dpi=200, facecolor='white', edgecolor='none')\n",
    "                print('figure saved to file')\n",
    "                \n",
    "        else:\n",
    "            n_count+=1 # increase counter for UN-adjusted images\n",
    "        \n",
    "    else:\n",
    "        n_count+=1 # increase counter for UN-adjusted images\n",
    "    \n",
    "print('Number of images:',len(im_names))\n",
    "print('Number of adjusted images:', y_count)\n",
    "print('Number of UN-adjusted/filtered out images:', n_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afb50fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define image class and list of images\n",
    "# class image:\n",
    "#     def __init__(self, im_name, x, y, b, g, r, nir):\n",
    "#         self.im_name = im_name\n",
    "#         self.x = x\n",
    "#         self.y = y\n",
    "#         self.b = b\n",
    "#         self.g = g\n",
    "#         self.r = r\n",
    "#         self.nir = nir\n",
    "#     def show(self):\n",
    "#         print('Image file name:',self.im_name)\n",
    "# im_list = [] # list for saving image info\n",
    "\n",
    "\n",
    "    # save image info\n",
    "#     newImage = image(im_name, x, y, b, g, r, nir)\n",
    "#     im_list.append(newImage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:planet-snow] *",
   "language": "python",
   "name": "conda-env-planet-snow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
