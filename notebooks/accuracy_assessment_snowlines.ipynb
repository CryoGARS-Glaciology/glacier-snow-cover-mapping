{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a738ee4d-62e5-4e1d-aee5-68dc7f494617",
   "metadata": {},
   "source": [
    "# Conduct snowline accuracy assessment\n",
    "\n",
    "Rainey Aberle\n",
    "\n",
    "October 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d809a61d-618f-44f7-a82c-7946104a000a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rioxarray as rxr\n",
    "import rasterio as rio\n",
    "import xarray as xr\n",
    "import ee\n",
    "import wxee as wx\n",
    "import glob\n",
    "import geopandas as gpd\n",
    "import sys\n",
    "from scipy import stats\n",
    "import skimage.io\n",
    "from skimage import feature\n",
    "from shapely.geometry import Point, LineString, shape, MultiPolygon, Polygon\n",
    "from shapely.ops import split, unary_union, polygonize, nearest_points\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc578f-bec3-4e6f-930d-633b083db83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to snow-cover-mapping\n",
    "base_path = '/Users/raineyaberle/Research/PhD/snow_cover_mapping/snow-cover-mapping/'\n",
    "# names of study sites\n",
    "site_names = ['Wolverine', 'LemonCreek', 'SouthCascade', 'Sperry', 'Gulkana']\n",
    "# path for output figures\n",
    "figures_out_path = base_path+'figures/'\n",
    "\n",
    "# add path to functions\n",
    "sys.path.insert(1, base_path+'functions/')\n",
    "import pipeline_utils as f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870334a-841b-4aa2-8faa-1e1178f97ffc",
   "metadata": {},
   "source": [
    "## Planet-Scope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9853ff3d-0006-46c9-8f89-3d2a7ae6734d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Loop through sites\n",
    "results_df = pd.DataFrame()\n",
    "for i, site_name in enumerate(site_names):    \n",
    "\n",
    "    print(site_name)\n",
    "    print('----------')\n",
    "    \n",
    "    # define path to classified snow images\n",
    "    im_path = base_path + '../study-sites/' + site_name + '/imagery/PlanetScope/'\n",
    "\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "\n",
    "    # load observed snow line shapefile names\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    sl_obs_fns = sorted(sl_obs_fns) # sort chronologically\n",
    "\n",
    "    # load estimated snowlines\n",
    "    sl_est_fn = glob.glob(im_path + 'snowlines/*' + site_name + '*snowlines.pkl')[0]\n",
    "    sl_ests = pd.read_pickle(sl_est_fn)\n",
    "    \n",
    "    # AOI\n",
    "    AOI_fn = glob.glob(base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    \n",
    "    # DEM\n",
    "    DEM_fn = glob.glob(base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif')[0]\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "\n",
    "    # initialize variables\n",
    "    sl_obs_elevs = [None]*len(sl_obs_fns) # observed snow elevations\n",
    "    datetimes = [None]*len(sl_obs_fns) # image datetimes\n",
    "\n",
    "    # loop through observed snow lines\n",
    "    for sl_obs_fn in sl_obs_fns:\n",
    "\n",
    "        # -----Load datasets\n",
    "        ### Observed\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # drop None geometry columns\n",
    "        sl_obs = sl_obs.drop(columns=['id']).dropna().reset_index(drop=True)\n",
    "        # reproject observed snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs(str(AOI.crs.to_epsg()))\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:11]\n",
    "        datetime = np.datetime64(date[0:4]+ '-' + date[4:6] + '-' + date[6:8] + ' ' + date[9:11] + ':00:00')\n",
    "        print(date)\n",
    "        \n",
    "        ### PlanetScope\n",
    "        sl_est = sl_ests.loc[sl_ests.datetime==datetime]\n",
    "        sl_est = sl_est.reset_index(drop=True)\n",
    "        # drop n/a\n",
    "        sl_est = sl_est[sl_est['snowlines_elevs_median'].notna()]\n",
    "        # format datetimes as np.datetime64\n",
    "        sl_ests['datetime'] = sl_ests['datetime'].astype(np.datetime64)\n",
    "        # check if any snowlines exist\n",
    "        if len(sl_est['snowlines_coords'])==0:\n",
    "            print('No data for this date, continuing...')\n",
    "            continue\n",
    "        # check if snowline is None\n",
    "        if sl_est['snowlines_coords'][0]==None:\n",
    "            print('No snowline detected, continuing...')\n",
    "            continue        \n",
    "        # open adjusted image of the same date\n",
    "        im_adj_fn = glob.glob(im_path + 'adjusted/*' + date[0:8] + '*.nc')[0] # define file name\n",
    "        im_adj = xr.open_dataset(im_adj_fn) # open image as xarray.DataArray\n",
    "        im_adj = im_adj.isel(time=0)\n",
    "         # open classified image from the same date\n",
    "        im_classified_fn = glob.glob(im_path + 'classified/*' + date[0:8] + '*.nc')[0] # define file name\n",
    "        im_classified = xr.open_dataset(im_classified_fn) # open image as xarray.DataArray\n",
    "        im_classified = im_classified.isel(time=0)\n",
    "               \n",
    "        # -----Sample elevations at observed snowline points\n",
    "        xsamp = sl_obs_UTM.geometry[0].coords.xy[0]\n",
    "        ysamp = sl_obs_UTM.geometry[0].coords.xy[1]\n",
    "        sl_obs_elev = [DEM.sel(x=x, y=y, method='nearest')['elevation'].data[0] for x,y in list(zip(xsamp, ysamp))]\n",
    "        \n",
    "        # -----Split line depending on distance between points\n",
    "        max_dist = 100 # m\n",
    "        line = sl_obs_UTM.geometry[0]\n",
    "        first_point = Point(line.coords.xy[0][0], line.coords.xy[1][0])\n",
    "        points = [Point(line.coords.xy[0][i], line.coords.xy[1][i]) for i in np.arange(0,len(line.coords.xy[0]))]\n",
    "        isplit = [0] # point indices where to split the line\n",
    "        for i, p in enumerate(points):\n",
    "            if i!=0:\n",
    "                dist = p.distance(points[i-1])\n",
    "                if dist > max_dist:\n",
    "                    isplit.append(i)\n",
    "        isplit.append(len(points)) # add ending point to complete the last line\n",
    "        line_split = [] # initialize split lines\n",
    "        # loop through split indices\n",
    "        if isplit:\n",
    "            for i, p in enumerate(isplit[:-1]):\n",
    "                if isplit[i+1]-isplit[i] > 1: # must have at least two points to make a line\n",
    "                    line_split = line_split + [LineString(points[isplit[i]:isplit[i+1]])]\n",
    "        else:\n",
    "            line_split = line\n",
    "    \n",
    "        # -----Regrid the observed snowlines to equal spacing\n",
    "        dx = 30 # point spacing\n",
    "        points_regrid = []\n",
    "        for line in line_split:\n",
    "            distances = np.arange(0, line.length, dx)\n",
    "            line_points = [line.interpolate(distance) for distance in distances] + [first_point]\n",
    "            # filter points outside the AOI\n",
    "            IAOI = np.where(np.array([p.within(AOI.geometry[0]) for p in line_points], dtype=int) ==1)[0]\n",
    "            points_AOI = [line_points[i] for i in IAOI]\n",
    "            points_regrid = points_regrid + [p for p in points_AOI]\n",
    "\n",
    "        # -----Calculate distance between each observed snowline point and the closest estimated snowline point\n",
    "        distances = np.zeros(len(points_regrid))\n",
    "        for i, p in enumerate(points_regrid):\n",
    "            # find nearest point\n",
    "            nearest_point = nearest_points(sl_est['snowlines_coords'][0], p)[0]\n",
    "            # calculate distance between points\n",
    "            distances[i] = p.distance(nearest_point)\n",
    "            \n",
    "        # -----Display results\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(np.dstack([im_adj['red'].data, im_adj['green'].data, im_adj['blue'].data]), \n",
    "                   extent=(np.min(im_adj.x.data), np.max(im_adj.x.data), np.min(im_adj.y.data), np.max(im_adj.y.data)))\n",
    "        plt.plot([p.coords.xy[0][0] for p in points_regrid], \n",
    "                 [p.coords.xy[1][0] for p in points_regrid], '.c', label='observed')\n",
    "        plt.plot(*sl_est['snowlines_coords'][0].coords.xy, '.m', label='estimated')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.title(datetime)\n",
    "        plt.show()\n",
    "        \n",
    "        # compile results in df\n",
    "        result_df = pd.DataFrame({'study_site': site_name, \n",
    "                                  'datetime': datetime, \n",
    "                                  'snowline_obs': [points_regrid], \n",
    "                                  'snowline_obs_elev_median': np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_est': [sl_est['snowlines_coords'][0]], \n",
    "                                  'snowline_est_elev_median': sl_est['snowlines_elevs_median'],\n",
    "                                  'snowline_elev_median_difference': sl_est['snowlines_elevs_median'] - np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_distances': [distances],\n",
    "                                  'snowline_distance_median': np.nanmedian(distances)})\n",
    "        \n",
    "        if i==0:\n",
    "            results_df = result_df\n",
    "        else:\n",
    "            # concatenate to results_df\n",
    "            results_df = pd.concat([results_df, result_df])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2462620d-1e7d-44e0-9557-e851f872506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,6))\n",
    "ax[0].boxplot(results_df['snowline_distance_median'])\n",
    "ax[0].set_title('snowline_distance_median')\n",
    "ax[1].boxplot(results_df['snowline_elev_median_difference'])\n",
    "ax[1].set_title('snowline_elev_median_difference')\n",
    "plt.show()\n",
    "\n",
    "print('PlanetScope snowline accuracy')\n",
    "print('----------')\n",
    "print('Points distance: ' + str(np.round(np.nanmedian(results_df['snowline_distance_median']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_distance_median']),2)) + ' m')\n",
    "print('Snowline median elevation: ' + str(np.round(np.nanmedian(results_df['snowline_elev_median_difference']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_elev_median_difference']),2)) + ' m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe641225-4ca9-4c8d-a6c1-e1aa16a0793b",
   "metadata": {},
   "source": [
    "## Landsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b465145-6729-4af8-84ba-857c5f48a3b7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Loop through sites\n",
    "results_df = pd.DataFrame()\n",
    "for i, site_name in enumerate(site_names):    \n",
    "\n",
    "    print(site_name)\n",
    "    print('----------')\n",
    "    \n",
    "    # define path to classified snow images\n",
    "    im_path = base_path + '../study-sites/' + site_name + '/imagery/Landsat/masked/'\n",
    "\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "\n",
    "    # load observed snow line shapefile names\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    sl_obs_fns = sorted(sl_obs_fns) # sort chronologically\n",
    "\n",
    "    # load estimated snowlines\n",
    "    sl_est_fn = glob.glob(im_path + '../snowlines/*' + site_name + '*snowlines.pkl')[0]\n",
    "    sl_ests = pd.read_pickle(sl_est_fn)\n",
    "    sl_ests['datetime'] = sl_ests['datetime'].astype(np.datetime64)\n",
    "    sl_ests = sl_ests.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # AOI\n",
    "    AOI_fn = glob.glob(base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    \n",
    "    # DEM\n",
    "    DEM_fn = glob.glob(base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif')[0]\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "\n",
    "    # initialize variables\n",
    "    sl_obs_elevs = [None]*len(sl_obs_fns) # observed snow elevations\n",
    "    datetimes = [None]*len(sl_obs_fns) # image datetimes\n",
    "\n",
    "    # loop through observed snow lines\n",
    "    for sl_obs_fn in sl_obs_fns:\n",
    "\n",
    "        # -----Load datasets\n",
    "        ### Observed\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # drop None geometry columns\n",
    "        sl_obs = sl_obs.drop(columns=['id']).dropna().reset_index(drop=True)\n",
    "        # reproject observed snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs(str(AOI.crs.to_epsg()))\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:11]\n",
    "        datetime = np.datetime64(date[0:4]+ '-' + date[4:6] + '-' + date[6:8] + ' ' + date[9:11] + ':00:00')\n",
    "        print(date)\n",
    "        \n",
    "        ### Estimated\n",
    "        date_diffs = [np.abs(x-datetime) for x in sl_ests['datetime']]\n",
    "        if np.min(date_diffs)>np.timedelta64('3', 'D'):\n",
    "            print('No data found for this date, continuing...')\n",
    "            continue\n",
    "        sl_est = sl_ests.iloc[np.argmin(date_diffs)]\n",
    "        # check if any snowlines exist\n",
    "        if len(sl_est)==0:\n",
    "            print('No data for this date, continuing...')\n",
    "            continue\n",
    "        # check if snowline is None\n",
    "        # if any(sl_est['snowlines_coords'])==False:\n",
    "        #     print('No snowline detected, continuing...')\n",
    "        #     continue        \n",
    "        # open adjusted image of the same date\n",
    "        im_adj_fn = glob.glob(im_path + '*masked.nc')[0] # define file name\n",
    "        im_adj = xr.open_dataset(im_adj_fn) # open image as xarray.DataArray\n",
    "        im_adj = im_adj.sel(time=sl_est['datetime'], method='nearest')\n",
    "               \n",
    "        # -----Sample elevations at observed snowline points\n",
    "        xsamp = sl_obs_UTM.geometry[0].coords.xy[0]\n",
    "        ysamp = sl_obs_UTM.geometry[0].coords.xy[1]\n",
    "        sl_obs_elev = [DEM.sel(x=x, y=y, method='nearest')['elevation'].data[0] for x,y in list(zip(xsamp, ysamp))]\n",
    "        \n",
    "        # -----Split line depending on distance between points\n",
    "        max_dist = 100 # m\n",
    "        line = sl_obs_UTM.geometry[0]\n",
    "        first_point = Point(line.coords.xy[0][0], line.coords.xy[1][0])\n",
    "        points = [Point(line.coords.xy[0][i], line.coords.xy[1][i]) for i in np.arange(0,len(line.coords.xy[0]))]\n",
    "        isplit = [0] # point indices where to split the line\n",
    "        for i, p in enumerate(points):\n",
    "            if i!=0:\n",
    "                dist = p.distance(points[i-1])\n",
    "                if dist > max_dist:\n",
    "                    isplit.append(i)\n",
    "        isplit.append(len(points)) # add ending point to complete the last line\n",
    "        line_split = [] # initialize split lines\n",
    "        # loop through split indices\n",
    "        if isplit:\n",
    "            for i, p in enumerate(isplit[:-1]):\n",
    "                if isplit[i+1]-isplit[i] > 1: # must have at least two points to make a line\n",
    "                    line_split = line_split + [LineString(points[isplit[i]:isplit[i+1]])]\n",
    "        else:\n",
    "            line_split = line\n",
    "    \n",
    "        # -----Regrid the observed snowlines to equal spacing\n",
    "        dx = 30 # point spacing\n",
    "        points_regrid = []\n",
    "        for line in line_split:\n",
    "            distances = np.arange(0, line.length, dx)\n",
    "            line_points = [line.interpolate(distance) for distance in distances] + [first_point]\n",
    "            # filter points outside the AOI\n",
    "            IAOI = np.where(np.array([p.within(AOI.geometry[0]) for p in line_points], dtype=int) ==1)[0]\n",
    "            points_AOI = [line_points[i] for i in IAOI]\n",
    "            points_regrid = points_regrid + [p for p in points_AOI]\n",
    "\n",
    "        # -----Calculate distance between each observed snowline point and the closest estimated snowline point\n",
    "        distances = np.zeros(len(points_regrid))\n",
    "        for i, p in enumerate(points_regrid):\n",
    "            # find nearest point\n",
    "            nearest_point = nearest_points(sl_est['snowlines_coords'], p)[0]\n",
    "            # calculate distance between points\n",
    "            distances[i] = p.distance(nearest_point)\n",
    "            \n",
    "        # -----Display results\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(np.dstack([im_adj['SR_B4'].data, im_adj['SR_B3'].data, im_adj['SR_B2'].data]), \n",
    "                   extent=(np.min(im_adj.x.data), np.max(im_adj.x.data), np.min(im_adj.y.data), np.max(im_adj.y.data)))\n",
    "        plt.plot([p.coords.xy[0][0] for p in points_regrid], \n",
    "                 [p.coords.xy[1][0] for p in points_regrid], '.c', label='observed')\n",
    "        plt.plot(*sl_est['snowlines_coords'].coords.xy, '.m', label='estimated')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.title(datetime)\n",
    "        plt.show()\n",
    "        \n",
    "        # compile results in df\n",
    "        result_df = pd.DataFrame({'study_site': site_name, \n",
    "                                  'datetime': datetime, \n",
    "                                  'snowline_obs': [points_regrid], \n",
    "                                  'snowline_obs_elev_median': np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_est': [sl_est['snowlines_coords']], \n",
    "                                  'snowline_est_elev_median': sl_est['snowlines_elevs_median'],\n",
    "                                  'snowline_elev_median_difference': sl_est['snowlines_elevs_median'] - np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_distances': [distances],\n",
    "                                  'snowline_distance_median': np.nanmedian(distances)})\n",
    "        \n",
    "        if i==0:\n",
    "            results_df = result_df\n",
    "        else:\n",
    "            # concatenate to results_df\n",
    "            results_df = pd.concat([results_df, result_df])\n",
    "            \n",
    "        print(' ')\n",
    "            \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a864f6e-0480-4ee8-883e-4ea21a0cc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,6))\n",
    "ax[0].boxplot(results_df['snowline_distance_median'])\n",
    "ax[0].set_title('snowline_distance_median')\n",
    "ax[1].boxplot(results_df['snowline_elev_median_difference'])\n",
    "ax[1].set_title('snowline_elev_median_difference')\n",
    "plt.show()\n",
    "\n",
    "print('Landsat snowline accuracy')\n",
    "print('----------')\n",
    "print('Points distance: ' + str(np.round(np.nanmedian(results_df['snowline_distance_median']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_distance_median']),2)) + ' m')\n",
    "print('Snowline median elevation: ' + str(np.round(np.nanmedian(results_df['snowline_elev_median_difference']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_elev_median_difference']),2)) + ' m')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6746a297-3053-4595-89de-f6e60e6d8cf7",
   "metadata": {},
   "source": [
    "## Sentinel-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a227f17-27e8-4c0b-a6a1-d9c6b5a92d7b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -----Loop through sites\n",
    "results_df = pd.DataFrame()\n",
    "for i, site_name in enumerate(site_names):    \n",
    "\n",
    "    print(site_name)\n",
    "    print('----------')\n",
    "    \n",
    "    # define path to classified snow images\n",
    "    im_path = base_path + '../study-sites/' + site_name + '/imagery/Sentinel-2/masked/'\n",
    "\n",
    "    # define path to digitized snow lines\n",
    "    sl_obs_path = base_path + '../snowline-package/' + site_name + '/snowlines/'\n",
    "\n",
    "    # load observed snow line shapefile names\n",
    "    sl_obs_fns = glob.glob(sl_obs_path + '*.shp')\n",
    "    sl_obs_fns = sorted(sl_obs_fns) # sort chronologically\n",
    "\n",
    "    # load estimated snowlines\n",
    "    sl_est_fn = glob.glob(im_path + '../snowlines/*' + site_name + '*snowlines.pkl')[0]\n",
    "    sl_ests = pd.read_pickle(sl_est_fn)\n",
    "    sl_ests['datetime'] = sl_ests['datetime'].astype(np.datetime64)\n",
    "    sl_ests = sl_ests.dropna().reset_index(drop=True)\n",
    "    \n",
    "    # AOI\n",
    "    AOI_fn = glob.glob(base_path + '../study-sites/' + site_name + '/glacier_outlines/' + site_name + '_USGS_*.shp')[0]\n",
    "    AOI = gpd.read_file(AOI_fn)\n",
    "    \n",
    "    # DEM\n",
    "    DEM_fn = glob.glob(base_path + '../study-sites/' + site_name + '/DEMs/' + site_name + '*_DEM*.tif')[0]\n",
    "    DEM = xr.open_dataset(DEM_fn)\n",
    "    DEM = DEM.rename({'band_data': 'elevation'})\n",
    "\n",
    "    # initialize variables\n",
    "    sl_obs_elevs = [None]*len(sl_obs_fns) # observed snow elevations\n",
    "    datetimes = [None]*len(sl_obs_fns) # image datetimes\n",
    "\n",
    "    # loop through observed snow lines\n",
    "    for sl_obs_fn in sl_obs_fns:\n",
    "\n",
    "        # -----Load datasets\n",
    "        ### Observed\n",
    "        sl_obs = gpd.read_file(sl_obs_fn)\n",
    "        # drop None geometry columns\n",
    "        sl_obs = sl_obs.drop(columns=['id']).dropna().reset_index(drop=True)\n",
    "        # reproject observed snow line to UTM\n",
    "        sl_obs_UTM = sl_obs.to_crs(str(AOI.crs.to_epsg()))\n",
    "        # extract date from filename\n",
    "        date = sl_obs_fn.split('/'+site_name+'_')[1][0:11]\n",
    "        datetime = np.datetime64(date[0:4]+ '-' + date[4:6] + '-' + date[6:8] + ' ' + date[9:11] + ':00:00')\n",
    "        print(date)\n",
    "        \n",
    "        ### Estimated\n",
    "        date_diffs = [np.abs(x-datetime) for x in sl_ests['datetime']]\n",
    "        print(np.min(date_diffs))\n",
    "        if np.min(date_diffs)>np.timedelta64('3', 'D'):\n",
    "            print('No data found for this date, continuing...')\n",
    "            continue\n",
    "        sl_est = sl_ests.iloc[np.argmin(date_diffs)]\n",
    "        # check if any snowlines exist\n",
    "        if len(sl_est)==0:\n",
    "            print('No data for this date, continuing...')\n",
    "            continue\n",
    "        # check if snowline is None\n",
    "        # if any(sl_est['snowlines_coords'])==False:\n",
    "        #     print('No snowline detected, continuing...')\n",
    "        #     continue        \n",
    "        # open adjusted image of the same date\n",
    "        im_adj_fn = glob.glob(im_path + '*' + str(sl_est['datetime']).replace('-','').replace(' ','T').replace(':','')\n",
    "                              + '*masked.nc')[0] # define file name\n",
    "        im_adj = xr.open_dataset(im_adj_fn) # open image as xarray.DataArray\n",
    "        im_adj = im_adj.isel(time=0)\n",
    "               \n",
    "        # -----Sample elevations at observed snowline points\n",
    "        xsamp = sl_obs_UTM.geometry[0].coords.xy[0]\n",
    "        ysamp = sl_obs_UTM.geometry[0].coords.xy[1]\n",
    "        sl_obs_elev = [DEM.sel(x=x, y=y, method='nearest')['elevation'].data[0] for x,y in list(zip(xsamp, ysamp))]\n",
    "        \n",
    "        # -----Split line depending on distance between points\n",
    "        max_dist = 100 # m\n",
    "        line = sl_obs_UTM.geometry[0]\n",
    "        first_point = Point(line.coords.xy[0][0], line.coords.xy[1][0])\n",
    "        points = [Point(line.coords.xy[0][i], line.coords.xy[1][i]) for i in np.arange(0,len(line.coords.xy[0]))]\n",
    "        isplit = [0] # point indices where to split the line\n",
    "        for i, p in enumerate(points):\n",
    "            if i!=0:\n",
    "                dist = p.distance(points[i-1])\n",
    "                if dist > max_dist:\n",
    "                    isplit.append(i)\n",
    "        isplit.append(len(points)) # add ending point to complete the last line\n",
    "        line_split = [] # initialize split lines\n",
    "        # loop through split indices\n",
    "        if isplit:\n",
    "            for i, p in enumerate(isplit[:-1]):\n",
    "                if isplit[i+1]-isplit[i] > 1: # must have at least two points to make a line\n",
    "                    line_split = line_split + [LineString(points[isplit[i]:isplit[i+1]])]\n",
    "        else:\n",
    "            line_split = line\n",
    "    \n",
    "        # -----Regrid the observed snowlines to equal spacing\n",
    "        dx = 30 # point spacing\n",
    "        points_regrid = []\n",
    "        for line in line_split:\n",
    "            distances = np.arange(0, line.length, dx)\n",
    "            line_points = [line.interpolate(distance) for distance in distances] + [first_point]\n",
    "            # filter points outside the AOI\n",
    "            IAOI = np.where(np.array([p.within(AOI.geometry[0]) for p in line_points], dtype=int) ==1)[0]\n",
    "            points_AOI = [line_points[i] for i in IAOI]\n",
    "            points_regrid = points_regrid + [p for p in points_AOI]\n",
    "\n",
    "        # -----Calculate distance between each observed snowline point and the closest estimated snowline point\n",
    "        distances = np.zeros(len(points_regrid))\n",
    "        for i, p in enumerate(points_regrid):\n",
    "            # find nearest point\n",
    "            nearest_point = nearest_points(sl_est['snowlines_coords'], p)[0]\n",
    "            # calculate distance between points\n",
    "            distances[i] = p.distance(nearest_point)\n",
    "            \n",
    "        # -----Display results\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.imshow(np.dstack([im_adj['B4'].data, im_adj['B3'].data, im_adj['B2'].data]), \n",
    "                   extent=(np.min(im_adj.x.data), np.max(im_adj.x.data), np.min(im_adj.y.data), np.max(im_adj.y.data)))\n",
    "        plt.plot([p.coords.xy[0][0] for p in points_regrid], \n",
    "                 [p.coords.xy[1][0] for p in points_regrid], '.c', label='observed')\n",
    "        plt.plot(*sl_est['snowlines_coords'].coords.xy, '.m', label='estimated')\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.grid()\n",
    "        plt.title(sl_est['datetime'])\n",
    "        plt.show()\n",
    "        \n",
    "        # compile results in df\n",
    "        result_df = pd.DataFrame({'study_site': site_name, \n",
    "                                  'datetime': datetime, \n",
    "                                  'snowline_obs': [points_regrid], \n",
    "                                  'snowline_obs_elev_median': np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_est': [sl_est['snowlines_coords']], \n",
    "                                  'snowline_est_elev_median': sl_est['snowlines_elevs_median'],\n",
    "                                  'snowline_elev_median_difference': sl_est['snowlines_elevs_median'] - np.nanmedian(sl_obs_elev),\n",
    "                                  'snowline_distances': [distances],\n",
    "                                  'snowline_distance_median': np.nanmedian(distances)})\n",
    "        \n",
    "        if i==0:\n",
    "            results_df = result_df\n",
    "        else:\n",
    "            # concatenate to results_df\n",
    "            results_df = pd.concat([results_df, result_df])\n",
    "            \n",
    "        print(' ')\n",
    "            \n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a598e62-39fb-47e5-a746-0bc1dcb88005",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(10,6))\n",
    "ax[0].boxplot(results_df['snowline_distance_median'])\n",
    "ax[0].set_title('snowline_distance_median')\n",
    "ax[1].boxplot(results_df['snowline_elev_median_difference'])\n",
    "ax[1].set_title('snowline_elev_median_difference')\n",
    "plt.show()\n",
    "\n",
    "print('Sentinel-2 snowline accuracy')\n",
    "print('----------')\n",
    "print('Points distance: ' + str(np.round(np.nanmedian(results_df['snowline_distance_median']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_distance_median']),2)) + ' m')\n",
    "print('Snowline median elevation: ' + str(np.round(np.nanmedian(results_df['snowline_elev_median_difference']),2)) \n",
    "      + ' +/- ' + str(np.round(np.nanstd(results_df['snowline_elev_median_difference']),2)) + ' m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e154aa-ac3d-4e2d-b72d-7622d78578d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "planet-snow",
   "language": "python",
   "name": "planet-snow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
